/*
// Copyright (C) 2018-2021 Intel Corporation
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
*/

#pragma once
#include "input_data.h"
#include "results.h"
#include "utils/config_factory.h"
#include <utils/ocv_common.hpp>

class ModelBase {
public:
    ModelBase(const std::string& modelFileName)
        : modelFileName(modelFileName)
    {}

    virtual ~ModelBase() {}

    virtual std::shared_ptr<InternalModelData> preprocess(const InputData& inputData, InferenceEngine::InferRequest::Ptr& request) = 0;
    virtual std::unique_ptr<ResultBase> postprocess(InferenceResult& infResult) = 0;
    virtual void onLoadCompleted(const std::vector<InferenceEngine::InferRequest::Ptr>& requests) {}
    const std::vector<std::string>& getOutputsNames() const { return outputsNames; }
    const std::vector<std::string>& getInputsNames() const { return inputsNames; }

    virtual InferenceEngine::ExecutableNetwork loadExecutableNetwork(const CnnConfig& cnnConfig, InferenceEngine::Core& core);

    std::string getModelFileName() { return modelFileName; }

    void SetInputsPreprocessing(bool reverseInputChannels, const std::string &meanValues, const std::string &scaleValues) {
        this->inputTransform = InputTransform(reverseInputChannels, meanValues, scaleValues);
    }

    void setBatchOne(InferenceEngine::CNNNetwork & cnnNetwork) {
        auto shapes = cnnNetwork.getInputShapes();
        for (auto& shape : shapes)
            shape.second[0] = 1;
        cnnNetwork.reshape(shapes);
    }

protected:
    InferenceEngine::CNNNetwork prepareNetwork(InferenceEngine::Core& core);
    virtual void prepareInputsOutputs(InferenceEngine::CNNNetwork& cnnNetwork) = 0;

    InputTransform inputTransform = InputTransform();
    std::vector<std::string> inputsNames;
    std::vector<std::string> outputsNames;
    InferenceEngine::ExecutableNetwork execNetwork;
    std::string modelFileName;
    CnnConfig cnnConfig = {};
};

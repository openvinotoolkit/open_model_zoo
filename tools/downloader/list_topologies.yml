# Copyright (c) 2018 Intel Corporation

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#      http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

topologies:
  - name: "densenet-121"
    description: >-
      The `densenet-121` model is one of the DenseNet <https://arxiv.org/pdf/1608.06993>
      group of models designed to perform image classification. Originally trained
      on Torch, the authors converted them into Caffe\* format. All the DenseNet models
      have been pretrained on the ImageNet image database. For details about this
      family of models, check out the repository <https://github.com/shicai/DenseNet-Caffe>.

      The model input is a blob that consists of a single image of 1x3x224x224 in
      BGR order. The BGR mean values need to be subtracted as follows: [103.94, 116.78,
      123.68] before passing the image blob into the network. In addition, values
      must be divided by 0.017.

      The model output for `densenet-121` is the typical object classifier output
      for the 1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: densenet-121.prototxt
        sha256: baeed2a423794c2c8dc1a80ad96e961112224fa1d319d535735ba93a2b535170
        source: https://raw.githubusercontent.com/shicai/DenseNet-Caffe/a68651c0b91d8dcb7c0ecd39d1fc76da523baf8a/DenseNet_121.prototxt
      - name: densenet-121.caffemodel
        size: 32303870
        sha256: c6a6ec988d76c468c3f67501a23a39ec7bf6ebe6729fd99496a15d0e845478b2
        source:
          $type: google_drive
          id: 0B7ubpZO7HnlCcHlfNmJkU2VPelE
    output: "classification/densenet/121/caffe/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[103.94,116.78,123.68]
      - --scale_values=data[58.8235294117647]
      - --output=fc6
      - --input_model=$dl_dir/densenet-121.caffemodel
      - --input_proto=$dl_dir/densenet-121.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/liuzhuang13/DenseNet/master/LICENSE

  - name: "densenet-161"
    description: >-
      The `densenet-161` model is one of the DenseNet <https://arxiv.org/pdf/1608.06993>
      group of models designed to perform image classification. The main difference
      with the `densenet-121` model is the size and accuracy of the model. The `densenet-161`
      is much larger at 100MB in size vs the `densenet-121` model's roughly 31MB size.
      Originally trained on Torch, the authors converted them into Caffe* format.
      All the DenseNet models have been pretrained on the ImageNet image database.
      For details about this family of models, check out the repository <https://github.com/shicai/DenseNet-Caffe>.

      The model input is a blob that consists of a single image of 1x3x224x224 in
      BGR order. The BGR mean values need to be subtracted as follows: [103.94, 116.78,
      123.68] before passing the image blob into the network. In addition, values
      must be divided by 0.017.

      The model output for `densenet-161` is the typical object classifier output
      for the 1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: densenet-161.prototxt
        sha256: a193e029d66112b077ed29e8b8d36d0bae0593a7f3c64125a433937b5f035b69
        source: https://raw.githubusercontent.com/shicai/DenseNet-Caffe/a68651c0b91d8dcb7c0ecd39d1fc76da523baf8a/DenseNet_161.prototxt
      - name: densenet-161.caffemodel
        size: 115676075
        sha256: e124d9a8f2284f4ab160569139217f709f21be6fc132c865b6a55cb8cae7d6b5
        source:
          $type: google_drive
          id: 0B7ubpZO7HnlCa0phRGJIRERoTXM
    output: "classification/densenet/161/caffe"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[103.94,116.78,123.68]
      - --scale_values=data[58.8235294117647]
      - --output=fc6
      - --input_model=$dl_dir/densenet-161.caffemodel
      - --input_proto=$dl_dir/densenet-161.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/liuzhuang13/DenseNet/master/LICENSE

  - name: "densenet-169"
    description: >-
      The `densenet-169` model is one of the DenseNet <https://arxiv.org/pdf/1608.06993>
      group of models designed to perform image classification. The main difference
      with the `densenet-121` model is the size and accuracy of the model. The `densenet-169`
      is larger at just about 55MB in size vs the `densenet-121` model's roughly 31MB
      size. Originally trained on Torch, the authors converted them into Caffe* format.
      All the DenseNet models have been pretrained on the ImageNet image database.
      For details about this family of models, check out the repository <https://github.com/shicai/DenseNet-Caffe>.

      The model input is a blob that consists of a single image of 1x3x224x224 in
      BGR order. The BGR mean values need to be subtracted as follows: [103.94, 116.78,
      123.68] before passing the image blob into the network. In addition, values
      must be divided by 0.017.

      The model output for `densenet-169` is the typical object classifier output
      for the 1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: densenet-169.prototxt
        sha256: dfb577c17d67327be70dba8f2810dbeec4f7edb836779c8055ec8f408b0a2cbc
        source: https://raw.githubusercontent.com/shicai/DenseNet-Caffe/a68651c0b91d8dcb7c0ecd39d1fc76da523baf8a/DenseNet_169.prototxt
      - name: densenet-169.caffemodel
        size: 57307526
        sha256: 8d45f2ab15f6329e2f80004692c58129cc4875ffe43ddf59433ebc2216189f15
        source:
          $type: google_drive
          id: 0B7ubpZO7HnlCRWVVdUJjVVAyQXc
    output: "classification/densenet/169/caffe"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[103.94,116.78,123.68]
      - --scale_values=data[58.8235294117647]
      - --output=fc6
      - --input_model=$dl_dir/densenet-169.caffemodel
      - --input_proto=$dl_dir/densenet-169.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/liuzhuang13/DenseNet/master/LICENSE

  - name: "densenet-201"
    description: >-
      The `densenet-201` model is also one of the DenseNet <https://arxiv.org/pdf/1608.06993>
      group of models designed to perform image classification. The main difference
      with the `densenet-121` model is the size and accuracy of the model. The `densenet-201`
      is larger at over 77MB in size vs the `densenet-121` model's roughly 31MB size.
      Originally trained on Torch, the authors converted them into Caffe\* format.
      All the DenseNet models have been pretrained on the ImageNet image database.
      For details about this family of models, check out the repository <https://github.com/shicai/DenseNet-Caffe>.

      The model input is a blob that consists of a single image of 1x3x224x224 in
      BGR order. The BGR mean values need to be subtracted as follows: [103.94, 116.78,
      123.68] before passing the image blob into the network. In addition, values
      must be divided by 0.017.

      The model output for `densenet-201` is the typical object classifier output
      for the 1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: densenet-201.prototxt
        sha256: 8edf61f867491315bc3780a41f74392c2a31042d20932eb145424a2dc8c6f8f7
        source: https://raw.githubusercontent.com/shicai/DenseNet-Caffe/a68651c0b91d8dcb7c0ecd39d1fc76da523baf8a/DenseNet_201.prototxt
      - name: densenet-201.caffemodel
        size: 81062969
        sha256: ba464965293d4dd5557085d57ec810bf353de362dd90e1b8293e6f0707978e4a
        source:
          $type: google_drive
          id: 0B7ubpZO7HnlCV3pud2oyR3lNMWs
    output: "classification/densenet/201/caffe"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[103.94,116.78,123.68]
      - --scale_values=data[58.8235294117647]
      - --output=fc6
      - --input_model=$dl_dir/densenet-201.caffemodel
      - --input_proto=$dl_dir/densenet-201.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/liuzhuang13/DenseNet/master/LICENSE

  - name: "squeezenet1.0"
    description: >-
      The `squeezenet1.0` model is one of the SqueezeNet <https://arxiv.org/pdf/1602.07360>
      topology models, is designed to perform image classification. The SqueezeNet
      models have been pre-trained on the ImageNet image database. For details about
      this family of models, check out the repository <https://github.com/DeepScale/SqueezeNet>.

      The model input is a blob that consists of a single image of 1x3x227x227 in
      BGR order. The BGR mean values need to be subtracted as follows: [104, 117,
      123] before passing the image blob into the network.

      The model output for `squeezenet1.0` is the typical object classifier output
      for the 1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: squeezenet1.0.prototxt
        sha256: 6e4ecef2a27347e226a5ef8be31d6d1b9d19f5a40afa1986ec259fd5fa3bd91c
        source: https://raw.githubusercontent.com/DeepScale/SqueezeNet/a47b6f13d30985279789d08053d37013d67d131b/SqueezeNet_v1.0/deploy.prototxt
      - name: squeezenet1.0.caffemodel
        sha256: 9ff8035aada1f9ffa880b35252680d971434b141ec9fbacbe88309f0f9a675ce
        source: https://github.com/DeepScale/SqueezeNet/raw/a47b6f13d30985279789d08053d37013d67d131b/SqueezeNet_v1.0/squeezenet_v1.0.caffemodel
    output: "classification/squeezenet/1.0/caffe"
    postprocessing:
      - $type: regex_replace
        file: squeezenet1.0.prototxt
        pattern: 'dim: 10'
        replacement: 'dim: 1'
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,227,227]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=prob
      - --input_model=$dl_dir/squeezenet1.0.caffemodel
      - --input_proto=$dl_dir/squeezenet1.0.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/DeepScale/SqueezeNet/master/LICENSE

  - name: "squeezenet1.1"
    description: >-
      The `squeezenet1.1` updated version of the SqueezeNet <https://arxiv.org/pdf/1602.07360>
      topology. It is designed to perform image classification.  It requires 2.4x
      less computation than SqueezeNet v1.0 <../squeezenet1.0/squeezenet1.0.md> without
      diminishing accuracy. The SqueezeNet models have been pre-trained on the ImageNet
      image database. For details about this family of models, check out the repository
      <https://github.com/DeepScale/SqueezeNet>.

      The model input is a blob that consists of a single image of 1x3x227x227 in
      BGR order. The BGR mean values need to be subtracted as follows: [104, 117,
      123] before passing the image blob into the network.

      The model output for `squeezenet1.1` is the typical object classifier output
      for the 1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: squeezenet1.1.prototxt
        sha256: d041bfb2ab4b32fda4ff6c6966684132f2924e329916aa5bfe9285c6b23e3d1c
        source: https://raw.githubusercontent.com/DeepScale/SqueezeNet/a47b6f13d30985279789d08053d37013d67d131b/SqueezeNet_v1.1/deploy.prototxt
      - name: squeezenet1.1.caffemodel
        sha256: 72b912ace512e8621f8ff168a7d72af55910d3c7c9445af8dfbff4c2ee960142
        source: https://github.com/DeepScale/SqueezeNet/raw/a47b6f13d30985279789d08053d37013d67d131b/SqueezeNet_v1.1/squeezenet_v1.1.caffemodel
    output: "classification/squeezenet/1.1/caffe"
    postprocessing:
      - $type: regex_replace
        file: squeezenet1.1.prototxt
        pattern: 'dim: 10'
        replacement: 'dim: 1'
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,227,227]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=prob
      - --input_model=$dl_dir/squeezenet1.1.caffemodel
      - --input_proto=$dl_dir/squeezenet1.1.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/DeepScale/SqueezeNet/master/LICENSE

  - name: "mtcnn-p"
    description: >-
      The `mtcnn-p` model is one of the mtcnn <https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf>
      group of models designed to perform face detection. Short for "Multi-task Cascaded
      Convolutional Neural Network", it is implemented using the Caffe\* framework.
      The "p" designation indicates that this model is the "proposal" network intended
      to find the initial set of faces. For details about this family of models, check
      out the repository <https://github.com/DuinoDu/mtcnn>.

      The model input is an image containing the data to be analyzed. The mean values
      need to be subtracted as follows: [127.5, 127.5, 127.5] before passing the image
      blob into the network. In addition, values must be divided by 0.0078125.

      The model output is a blob with a vector containing the first pass of face data.
      If there are no faces detected, no further processing is needed. Otherwise,
      you will typically use this output as input to the `mtcnn-r` model.
    task_type: "detection"
    files:
      - name: mtcnn-p.prototxt
        sha256: adc1756d8515d3ca3a6a186c0fadab66fcae04bd8d3c6388e2fe8797a626dde4
        source: https://raw.githubusercontent.com/DuinoDu/mtcnn/db5bd8f02023f8d37913140fd2bf2749c2dbf266/model/det1.prototxt
      - name: mtcnn-p.caffemodel
        sha256: d6085e7f48ba7e6b6f1b58964595f6bce5b97bcc4866751f7b4bdc98f920c096
        source: https://github.com/DuinoDu/mtcnn/raw/db5bd8f02023f8d37913140fd2bf2749c2dbf266/model/det1.caffemodel
    output: "object_detection/common/mtcnn/p/caffe"
    postprocessing:
      - $type: regex_replace
        file: mtcnn-p.prototxt
        pattern: 'dim: 12'
        replacement: 'dim: 720'
        count: 1
      - $type: regex_replace
        file: mtcnn-p.prototxt
        pattern: 'dim: 12'
        replacement: 'dim: 1280'
        count: 1
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,720,1280]
      - --input=data
      - --mean_values=data[127.5,127.5,127.5]
      - --scale_values=data[128.0]
      - --output=conv4-2,prob1
      - --input_model=$dl_dir/mtcnn-p.caffemodel
      - --input_proto=$dl_dir/mtcnn-p.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/DuinoDu/mtcnn/master/LICENSE

  - name: "mtcnn-r"
    description: >-
      The `mtcnn-r` model is one of the mtcnn <https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf>
      group of models designed to perform face detection. Short for "Multi-task Cascaded
      Convolutional Neural Network", it is implemented using the Caffe\* framework.
      The "r" designation indicates that this model is the "refine" network intended
      to refine the data returned as output from the "proposal" `mtcnn-p` network.
      For details about this family of models, check out the repository <https://github.com/DuinoDu/mtcnn>.

      The model input is a blob with a vector containing the first pass of face data,
      as returned by the `mtcnn-p` model. The mean values need to be subtracted as
      follows: [127.5, 127.5, 127.5] before passing the image blob into the network.
      In addition, values must be divided by 0.0078125.

      The model output is a blob with a vector containing the refined face data. If
      there are no faces detected by the refine pass, no further processing is needed.
      Otherwise, you will typically use this output as input to the `mtcnn-o` model.
    task_type: "detection"
    files:
      - name: mtcnn-r.prototxt
        sha256: 077686e89e606354f425366afdb2018777d93c6450b50e2c12301f8a97f6bb47
        source: https://raw.githubusercontent.com/DuinoDu/mtcnn/db5bd8f02023f8d37913140fd2bf2749c2dbf266/model/det2.prototxt
      - name: mtcnn-r.caffemodel
        sha256: 39b20f7a57bb8176cc9466cea4dfd52da6a6f876de60c7ab222a309f2d0ca08c
        source: https://github.com/DuinoDu/mtcnn/raw/db5bd8f02023f8d37913140fd2bf2749c2dbf266/model/det2.caffemodel
    output: "object_detection/common/mtcnn/r/caffe"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,24,24]
      - --input=data
      - --mean_values=data[127.5,127.5,127.5]
      - --scale_values=data[128.0]
      - --output=conv5-2,prob1
      - --input_model=$dl_dir/mtcnn-r.caffemodel
      - --input_proto=$dl_dir/mtcnn-r.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/DuinoDu/mtcnn/master/LICENSE

  - name: "mtcnn-o"
    description: >-
      The `mtcnn-o` model is the third of the mtcnn <https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf>
      group of models designed to perform face detection. Short for "Multi-task Cascaded
      Convolutional Neural Network", it is implemented using the Caffe\* framework.
      The "o" designation indicates that this model is the "output" network intended
      to take the data returned from the "refine" `mtcnn-r` network, and transform
      it into the final output data.  For details about this family of models, check
      out the repository <https://github.com/DuinoDu/mtcnn>.

      The model input is a blob with a vector containing the refined face data, as
      returned by the `mtcnn-r` model. The mean values need to be subtracted as follows:
      [127.5, 127.5, 127.5] before passing the image blob into the network. In addition,
      values must be divided by 0.0078125.

      The model output is a blob with a vector containing the output face data.
    task_type: "detection"
    files:
      - name: mtcnn-o.prototxt
        sha256: a8385a3aad241acf5902b79466f9a359ea9f03a3b6dcbe1e1efa050908cf7d04
        source: https://raw.githubusercontent.com/DuinoDu/mtcnn/db5bd8f02023f8d37913140fd2bf2749c2dbf266/model/det3.prototxt
      - name: mtcnn-o.caffemodel
        sha256: 9d6098829a4d6d318f37cec42142465637fafe4c673f2e93b69495bf7ca23d2d
        source: https://github.com/DuinoDu/mtcnn/raw/db5bd8f02023f8d37913140fd2bf2749c2dbf266/model/det3.caffemodel
    output: "object_detection/common/mtcnn/o/caffe"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,48,48]
      - --input=data
      - --mean_values=data[127.5,127.5,127.5]
      - --scale_values=data[128.0]
      - --output=conv6-2,conv6-3,prob1
      - --input_model=$dl_dir/mtcnn-o.caffemodel
      - --input_proto=$dl_dir/mtcnn-o.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/DuinoDu/mtcnn/master/LICENSE

  - name: "mask_rcnn_inception_resnet_v2_atrous_coco"
    description: >-
      Mask R-CNN Inception Resnet V2 Atrous trained on COCO dataset.
      Used for object instance segmentation. For details see paper 
      <https://arxiv.org/pdf/1703.06870.pdf>.
    task_type: "instance_segmentation"
    files:
      - name: mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz
        sha256: 816afc8987c2152cbd0e24af3a6fb82086cea0645a38778884bd166c0d016bb5
        source: http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz
    output: "instance_segmentation/common/mask_rcnn/mask_rcnn_inception_resnet_v2_atrous_coco/tf"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,800,800,3]
      - --input=image_tensor
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/mask_rcnn_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/pipeline.config
      - --input_model=$dl_dir/mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/frozen_inference_graph.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "mask_rcnn_inception_v2_coco"
    description: >-
      Mask R-CNN Inception V2 trained on COCO dataset.
      Used for object instance segmentation. For details see paper
      <https://arxiv.org/pdf/1703.06870.pdf>.
    task_type: "instance_segmentation"
    files:
      - name: mask_rcnn_inception_v2_coco_2018_01_28.tar.gz
        sha256: 4f57861c2ff1c87e92495789ee266e41a7dc79a038521d93a153be403b0b601f
        source: http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz
    output: "instance_segmentation/common/mask_rcnn/mask_rcnn_inception_v2_coco/tf"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: mask_rcnn_inception_v2_coco_2018_01_28.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,800,800,3]
      - --input=image_tensor
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/mask_rcnn_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/mask_rcnn_inception_v2_coco_2018_01_28/pipeline.config
      - --input_model=$dl_dir/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "mask_rcnn_resnet50_atrous_coco"
    description: >-
      Mask R-CNN ResNet50 Atrous trained on COCO dataset.
      Used for object instance segmentation. For details see paper
      <https://arxiv.org/pdf/1703.06870.pdf>.
    task_type: "instance_segmentation"
    files:
      - name: mask_rcnn_resnet50_atrous_coco_2018_01_28.tar.gz
        sha256: f3741f099bdb414e172cc8cc41370213a41afd04d7aa970f7854f09a75172481
        source: http://download.tensorflow.org/models/object_detection/mask_rcnn_resnet50_atrous_coco_2018_01_28.tar.gz
    output: "instance_segmentation/common/mask_rcnn/mask_rcnn_resnet50_atrous_coco/tf"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: mask_rcnn_resnet50_atrous_coco_2018_01_28.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,800,800,3]
      - --input=image_tensor
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/mask_rcnn_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/mask_rcnn_resnet50_atrous_coco_2018_01_28/pipeline.config
      - --input_model=$dl_dir/mask_rcnn_resnet50_atrous_coco_2018_01_28/frozen_inference_graph.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "mask_rcnn_resnet101_atrous_coco"
    description: >-
      Mask R-CNN ResNet101 Atrous trained on COCO dataset.
      Used for object instance segmentation. For details see paper
      <https://arxiv.org/pdf/1703.06870.pdf>.
    task_type: "instance_segmentation"
    files:
      - name: mask_rcnn_resnet101_atrous_coco_2018_01_28.tar.gz
        sha256: 67ac8d5f0974753e9a5b04d36376e20b3be55b5dcd6ce43bc25aed6c5583709d
        source: http://download.tensorflow.org/models/object_detection/mask_rcnn_resnet101_atrous_coco_2018_01_28.tar.gz
    output: "instance_segmentation/common/mask_rcnn/mask_rcnn_resnet101_atrous_coco/tf"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: mask_rcnn_resnet101_atrous_coco_2018_01_28.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,800,800,3]
      - --input=image_tensor
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/mask_rcnn_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/mask_rcnn_resnet101_atrous_coco_2018_01_28/pipeline.config
      - --input_model=$dl_dir/mask_rcnn_resnet101_atrous_coco_2018_01_28/frozen_inference_graph.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "ssdlite_mobilenet_v2"
    description: >-
      MobileNetV2: Inverted Residuals and Linear Bottlenecks. Used for object detection.
      For details see paper <https://arxiv.org/pdf/1801.04381.pdf>.
    task_type: "detection"
    files:
      - name: ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz
        sha256: 542445cce834dbfbb7df1991425d475e85a2d7ec68c60a4f262bb18aac10c8b2
        source: http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz
    output: "object_detection/common/ssd_mobilenet/ssd_mobilenet_v2_ssdlite/tf/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,300,300,3]
      - --input=image_tensor
      - --output=detection_scores,detection_boxes,num_detections
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/ssd_v2_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/ssdlite_mobilenet_v2_coco_2018_05_09/pipeline.config
      - --input_model=$dl_dir/ssdlite_mobilenet_v2_coco_2018_05_09/frozen_inference_graph.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "ssd_mobilenet_v1_fpn_coco"
    description: >-
      MobileNetV1 FPN. Used for object detection. For details see paper
      <https://arxiv.org/pdf/1807.03284.pdf>.
    task_type: "detection"
    files:
      - name: ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz
        sha256: e8886ece7f3a0993678440305a98f5be649a90b314c95ca94565c23ed20b1fb0
        source: http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz
    output: "object_detection/common/ssd_mobilenet/ssd_mobilenet_v1_fpn_coco/tf/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,640,640,3]
      - --input=image_tensor
      - --output=detection_scores,detection_boxes,num_detections
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/ssd_v2_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/pipeline.config
      - --input_model=$dl_dir/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/frozen_inference_graph.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "mobilenet-ssd"
    description: >-
      The `mobilenet-ssd` model is a Single-Shot multibox Detection (SSD) network
      intended to perform object detection. This model is implemented using the Caffe\*
      framework. For details about this model, check out the repository <https://github.com/chuanqi305/MobileNet-SSD>.

      The model input is a blob that consists of a single image of 1x3x300x300 in
      BGR order, also like the `densenet-121` model. The BGR mean values need to be
      subtracted as follows: [127.5, 127.5, 127.5] before passing the image blob into
      the network. In addition, values must be divided by 0.007843.

      The model output is a typical vector containing the tracked object data, as
      previously described.
    task_type: "detection"
    files:
      - name: mobilenet-ssd.prototxt
        sha256: e781559c4f5beaec2a486ccd952af5b6fa408e9498761bf5f4fb80b4e9f0d25e
        source: https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/ba00fc987b3eb0ba87bb99e89bf0298a2fd10765/MobileNetSSD_deploy.prototxt
      - name: mobilenet-ssd.caffemodel
        size: 23147564
        sha256: 761c86fbae3d8361dd454f7c740a964f62975ed32f4324b8b85994edec30f6af
        source:
          $type: google_drive
          id: 0B3gersZ2cHIxRm5PMWRoTkdHdHc
    output: "object_detection/common/mobilenet-ssd/caffe"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,300,300]
      - --input=data
      - --mean_values=data[127.5,127.5,127.5]
      - --scale_values=data[127.50223128904757]
      - --output=detection_out
      - --input_model=$dl_dir/mobilenet-ssd.caffemodel
      - --input_proto=$dl_dir/mobilenet-ssd.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/LICENSE

  - name: "vgg19"
    description: >-
      The `vgg19` model is one of the vgg <https://arxiv.org/pdf/1409.1556.pdf> models
      designed to perform image classification in Caffe\* format.

      The model input is a blob that consists of a single image of 1x3x224x224 in
      BGR order. The BGR mean values need to be subtracted as follows: [103.939, 116.779,
      123.68] before passing the image blob into the network.

      The model output for `vgg19` is the typical object classifier output for the
      1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: vgg19.prototxt
        sha256: e7c9da46d837dd91049ddab46a57933a488e3d8a42162cdef51ab1edeff99725
        source: https://gist.githubusercontent.com/ksimonyan/3785162f95cd2d5fee77/raw/f02f8769e64494bcd3d7e97d5d747ac275825721/VGG_ILSVRC_19_layers_deploy.prototxt
      - name: vgg19.caffemodel
        sha256: 31b4c627c40c6ee151325f079b7ac557fddbd1f79af932888796127a4f4f6954
        source: http://www.robots.ox.ac.uk/~vgg/software/very_deep/caffe/VGG_ILSVRC_19_layers.caffemodel
    output: "classification/vgg/19/caffe"
    postprocessing:
      - $type: regex_replace
        file: vgg19.prototxt
        pattern: 'dim: 10'
        replacement: 'dim: 1'
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[103.939,116.779,123.68]
      - --output=prob
      - --input_model=$dl_dir/vgg19.caffemodel
      - --input_proto=$dl_dir/vgg19.prototxt
    framework: caffe
    license: https://creativecommons.org/licenses/by/4.0/legalcode.txt

  - name: "vgg16"
    description: >-
      The `vgg16` model is one of the vgg <https://arxiv.org/pdf/1409.1556.pdf> models
      designed to perform image classification in Caffe\*format.

      The model input is a blob that consists of a single image of "1x3x224x224" in
      BGR order. The BGR mean values need to be subtracted as follows: [103.939, 116.779,
      123.68] before passing the image blob into the network.

      The model output for `vgg16` is the typical object classifier output for the
      1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: vgg16.prototxt
        sha256: 9fdb04e3f5b9224af473e82441b05b76368dfa6dc841e80655303823e9770962
        source: https://gist.githubusercontent.com/ksimonyan/211839e770f7b538e2d8/raw/0067c9b32f60362c74f4c445a080beed06b07eb3/VGG_ILSVRC_16_layers_deploy.prototxt
      - name: vgg16.caffemodel
        sha256: a6196bc498e45ea4cb2637114ae8db9410cf1556fd60a55ae93272371beba197
        source: http://www.robots.ox.ac.uk/~vgg/software/very_deep/caffe/VGG_ILSVRC_16_layers.caffemodel
    output: "classification/vgg/16/caffe"
    postprocessing:
      - $type: regex_replace
        file: vgg16.prototxt
        pattern: 'dim: 10'
        replacement: 'dim: 1'
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[103.939,116.779,123.68]
      - --output=prob
      - --input_model=$dl_dir/vgg16.caffemodel
      - --input_proto=$dl_dir/vgg16.prototxt
    framework: caffe
    license: https://creativecommons.org/licenses/by/4.0/legalcode.txt

  - name: "ssd512"
    description: >-
      The `ssd512` model is a Single-Shot multibox Detection <SSD> <https://arxiv.org/pdf/1512.02325.pdf>
      network intended to perform face detection. This model is implemented using
      the Caffe\*framework. For details about this model, check out the repository
      <https://github.com/weiliu89/caffe/tree/ssd>.

      The model input is a blob that consists of a single image of 1x3x512x512 in
      BGR order. The BGR mean values need to be subtracted as follows: [104.0,117.0,123.0]
      before passing the image blob into the network.

      The model output is a typical vector containing the tracked object data, as
      previously described.
    task_type: "detection"
    files:
      - name: ssd512.tar.gz
        size: 100991061
        sha256: 2d98a6ddd5b4cb0ba59a37fe5d50020457cfe104d45873c3ea43d1e6dcddd12d
        source:
          $type: google_drive
          id: 0BzKzrI_SkD1_MjFjNTlnempHNWs
    output: "object_detection/common/ssd/512/caffe"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: ssd512.tar.gz
      - $type: regex_replace
        file: models/VGGNet/VOC0712Plus/SSD_512x512/deploy.prototxt
        pattern: ' +save_output_param \{.*\n.*\n +\}\n'
        replacement: ''
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,512,512]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=detection_out
      - --input_model=$dl_dir/models/VGGNet/VOC0712Plus/SSD_512x512/VGG_VOC0712Plus_SSD_512x512_iter_240000.caffemodel
      - --input_proto=$dl_dir/models/VGGNet/VOC0712Plus/SSD_512x512/deploy.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/weiliu89/caffe/ssd/LICENSE

  - name: "ssd300"
    description: >-
      The "ssd300" model is a Single-Shot multibox Detection <SSD> <https://arxiv.org/pdf/1512.02325.pdf>
      network intended to perform face detection. This model is implemented using
      the Caffe\* framework. For details about this model, check out the repository
      <https://github.com/weiliu89/caffe/tree/ssd>.

      The model input is a blob that consists of a single image of 1x3x300x300 in
      BGR order.  The BGR mean values need to be subtracted as follows: [104.0,117.0,123.0]
      before passing the image blob into the network.

      The model output is a typical vector containing the tracked object data, as
      previously described.
    task_type: "detection"
    files:
      - name: ssd300.tar.gz
        size: 97789219
        sha256: e3eb9794a33eb77e6798f396df453123c249a1df554e42a3302eb4aa20a8f2ee
        source:
          $type: google_drive
          id: 0BzKzrI_SkD1_TkFPTEQ1Z091SUE
    output: "object_detection/common/ssd/300/caffe"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: ssd300.tar.gz
      - $type: regex_replace
        file: models/VGGNet/VOC0712Plus/SSD_300x300_ft/deploy.prototxt
        pattern: ' +save_output_param \{.*\n.*\n +\}\n'
        replacement: ''
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,300,300]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=detection_out
      - --input_model=$dl_dir/models/VGGNet/VOC0712Plus/SSD_300x300_ft/VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.caffemodel
      - --input_proto=$dl_dir/models/VGGNet/VOC0712Plus/SSD_300x300_ft/deploy.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/weiliu89/caffe/ssd/LICENSE

  - name: "inception-resnet-v2"
    description: >-
      The `inception-resnet-v2` model is one of the Inception <https://arxiv.org/pdf/1602.07261.pdf>
      family of models designed to perform image classification.1 Like the other Inception
      models, the `inception-resnet-v2` model has been pretrained on the ImageNet
      image database. For details about this family of models, check out the paper.

      The model input is a blob that consists of a single image of 1x3x299x299 in
      BGR order. The BGR mean values need to be subtracted as follows: [128.0,128.0,128.0]
      before passing the image blob into the network. In addition, values must be
      divided by 0.0078125.

      The model output for `inception-resnet-v2` is the typical object classifier
      output for the 1000 different classifications matching those in the ImageNet
      database.
    task_type: "classification"
    files:
      - name: inception-resnet-v2.prototxt
        size: 192362
        sha256: 8d53ee1f4112716e3e53d65ddc1936eeb6ca8f26d49cdb1129aba3bb78bdc209
        source:
          $type: google_drive
          id: 0B9mkjlmP0d7zUXhsMmI4cWR6MmM
      - name: inception-resnet-v2.caffemodel
        size: 223511172
        sha256: 1027d403ba8bf6211ca0d25f4b9ec6d4357d1407a812835b741004d5ad308b92
        source:
          $type: google_drive
          id: 0B9mkjlmP0d7zNmY5eXZhLUhzQVE
    output: "classification/inception-resnet/v2/caffe"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,299,299]
      - --input=data
      - --mean_values=data[128.0,128.0,128.0]
      - --scale_values=data[128.0]
      - --output=prob
      - --input_model=$dl_dir/inception-resnet-v2.caffemodel
      - --input_proto=$dl_dir/inception-resnet-v2.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/soeaver/caffe-model/master/LICENSE

  - name: "googlenet-v1"
    description: >-
      The `googlenet-v1` model is the first of the Inception <https://arxiv.org/pdf/1602.07261.pdf>
      family of models designed to perform image classification. Like the other Inception
      models, the `googlenet-v1` model has been pretrained on the ImageNet image database.
      For details about this family of models, check out the paper.

      The model input is a blob that consists of a single image of 1x3x224x224 in
      BGR order.  The BGR mean values need to be subtracted as follows: [104.0,117.0,123.0]
      before passing the image blob into the network.

      The model output for `googlenet-v1` is the typical object classifier output
      for the 1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: googlenet-v1.prototxt
        sha256: fa36cd4112a3240a29600a5aa35333f31bec33daa1a6085b0af308a9f50f0c50
        source: https://raw.githubusercontent.com/BVLC/caffe/88c96189bcbf3853b93e2b65c7b5e4948f9d5f67/models/bvlc_googlenet/deploy.prototxt
      - name: googlenet-v1.caffemodel
        sha256: 6f7101e3a2183738a7125a0c5021ba82a1feb4228c5ca0924d991b6daf6f6fad
        source: http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel
    output: "classification/googlenet/v1/caffe"
    postprocessing:
      - $type: regex_replace
        file: googlenet-v1.prototxt
        pattern: 'dim: 10'
        replacement: 'dim: 1'
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=prob
      - --input_model=$dl_dir/googlenet-v1.caffemodel
      - --input_proto=$dl_dir/googlenet-v1.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/BVLC/caffe/master/LICENSE

  - name: "googlenet-v2"
    description: >-
      The `googlenet-v2` model is the second of the Inception <https://arxiv.org/pdf/1602.07261.pdf>
      family of models designed to perform image classification. Like the other Inception
      models, the `googlenet-v2` model has been pretrained on the ImageNet image database.
      For details about this family of models, check out the paper.

      The model input is a blob that consists of a single image of 1x3x224x224 in
      BGR order. The BGR mean values need to be subtracted as follows: [104.0,117.0,123.0]
      before passing the image blob into the network.

      The model output for `googlenet-v2` is the typical object classifier output
      for the 1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: googlenet-v2.prototxt
        sha256: 18c77f01cca83c4cee973bfd8739968210dd6a1e5af1b857faaec230c5aa7d5a
        source: https://raw.githubusercontent.com/lim0606/caffe-googlenet-bn/d19caf526b7d8cad873ff91ba4cea602eadd58b3/deploy.prototxt
      - name: googlenet-v2.caffemodel
        sha256: c6581a8e60e5ae8962183ff019986fc9dfacc5e5bd5247d76a0ff7fae8e0409a
        source: https://github.com/lim0606/caffe-googlenet-bn/raw/d19caf526b7d8cad873ff91ba4cea602eadd58b3/snapshots/googlenet_bn_stepsize_6400_iter_1200000.caffemodel
    output: "classification/googlenet/v2/caffe"
    postprocessing:
      - $type: regex_replace
        file: googlenet-v2.prototxt
        pattern: 'dim: 10'
        replacement: 'dim: 1'
      - $type: regex_replace
        file: googlenet-v2.prototxt
        pattern: 'layers \{'
        replacement: 'layer {'
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=prob
      - --input_model=$dl_dir/googlenet-v2.caffemodel
      - --input_proto=$dl_dir/googlenet-v2.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/lim0606/caffe-googlenet-bn/master/README.md

  - name: "googlenet-v4"
    description: >-
      The `googlenet-v4` model is the most recent of the Inception <https://arxiv.org/pdf/1602.07261.pdf>
      family of models designed to perform image classification. Like the other Inception
      models, the `googlenet-v4` model has been pretrained on the ImageNet image database.
      For details about this family of models, check out the paper.

      The model input is a blob that consists of a single image of 1x3x299x299 in
      BGR order. The BGR mean values need to be subtracted as follows: [128.0,128.0,128.0]
      before passing the image blob into the network. In addition, values must be
      divided by 0.0078125.

      The model output for `googlenet-v4` is the typical object classifier output
      for the 1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: googlenet-v4.prototxt
        size: 86534
        sha256: 2213d8729839cd015c4b0335d91da1cf4a034627fadedcdb5bf8ac347c4896d9
        source:
          $type: google_drive
          id: 0B9mkjlmP0d7zWEJsRl9zeTQ1NzA
      - name: googlenet-v4.caffemodel
        size: 170777072
        sha256: 6ff248c1215a9fc14ac7ccd44b03da35e41e50bde054ba201bd9c737522996c3
        source:
          $type: google_drive
          id: 0B9mkjlmP0d7zeG1HREVMR2F3WmM
    output: "classification/googlenet/v4/caffe"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,299,299]
      - --input=data
      - --mean_values=data[128.0,128.0,128.0]
      - --scale_values=data[128.0]
      - --output=prob
      - --input_model=$dl_dir/googlenet-v4.caffemodel
      - --input_proto=$dl_dir/googlenet-v4.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/soeaver/caffe-model/master/LICENSE

  - name: "alexnet"
    description: >-
      The `alexnet` model is designed to perform image classification. Just like other
      common classification models, the `alexnet` model has been pretrained on the
      ImageNet image database. For details about this model, check out the paper <http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf>.

      The model input is a blob that consists of a single image of 1x3x227x227 in
      BGR order. The BGR mean values need to be subtracted as follows: [104, 117,
      123] before passing the image blob into the network.

      The model output for `alexnet` is the usual object classifier output for the
      1000 different classifications matching those in the ImageNet database.
    task_type: "classification"
    files:
      - name: alexnet.prototxt
        sha256: b564ba76416b4ac1e062c6621cbd80d9c19304ba152d9d791c75870f3182c4fa
        source: https://raw.githubusercontent.com/BVLC/caffe/88c96189bcbf3853b93e2b65c7b5e4948f9d5f67/models/bvlc_alexnet/deploy.prototxt
      - name: alexnet.caffemodel
        sha256: 4bff209a9837298157915ef50a4831a59636a6ca1a6b8ebacd990c3a5f3053e0
        source: http://dl.caffe.berkeleyvision.org/bvlc_alexnet.caffemodel
    output: "classification/alexnet/caffe"
    postprocessing:
      - $type: regex_replace
        file: alexnet.prototxt
        pattern: 'dim: 10'
        replacement: 'dim: 1'
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,227,227]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=prob
      - --input_model=$dl_dir/alexnet.caffemodel
      - --input_proto=$dl_dir/alexnet.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_alexnet/readme.md

  - name: "ssd_mobilenet_v2_coco"
    description: >-
      The `ssd_mobilenet_v2_coco` model is a Single-Shot multibox Detection <SSD>
      <https://arxiv.org/pdf/1801.04381.pdf> network intended to perform object detection.
      The difference between this model and the `mobilenet-ssd` is that the while
      `mobilenet-ssd` detects faces only, the `ssd_mobilenet_v2_coco` model detects
      objects, as it has been trained from the Common Objects in Context (COCO) image
      dataset.

      The model input is a blob that consists of a single image of 1x3x300x300 in
      RGB order.

      The model output is a typical vector containing the tracked object data, as
      previously described. Note that the "class_id" data is now significant and should
      be used to determine the classification for any detected object.
    task_type: "detection"
    files:
      - name: ssd_mobilenet_v2_coco.tar.gz
        sha256: b9380178b2e35333f1a735e39745928488bdabeb9ed20bc6fa07af8172cb5adc
        source: http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz
    output: "object_detection/common/ssd_mobilenet_v2_coco/tf"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: ssd_mobilenet_v2_coco.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,300,300,3]
      - --input=image_tensor
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/ssd_v2_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/ssd_mobilenet_v2_coco_2018_03_29/pipeline.config
      - --output=detection_classes,detection_scores,detection_boxes,num_detections
      - --input_model=$dl_dir/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "resnet-50"
    description: >-
      ResNet-50 <https://arxiv.org/pdf/1512.03385.pdf>
    task_type: "classification"
    files:
      - name: resnet-50.prototxt
        size: 32500
        sha256: 2f8fb64f68c6bcda94eb2640f80aed94efb91664122e72a6b7587012cc57dedc
        source: https://onedrive.live.com/download?cid=4006CBB8476FF777&resid=4006CBB8476FF777%2117891&authkey=AAFW2-FVoxeVRck
      - name: resnet-50.caffemodel
        size: 102462397
        sha256: 44ee2b08816cede2b7aaa047888df07dcab52f73399aa1c8bef05a17bfdd4888
        source: https://onedrive.live.com/download?cid=4006CBB8476FF777&resid=4006CBB8476FF777%2117895&authkey=AAFW2-FVoxeVRck
    output: "classification/resnet/v1/50/caffe/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --mean_values=data[104.0,117.0,123.0]
      - --input=data
      - --output=prob
      - --input_model=$dl_dir/resnet-50.caffemodel
      - --input_proto=$dl_dir/resnet-50.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/KaimingHe/deep-residual-networks/master/LICENSE

  - name: "resnet-101"
    description: >-
      ResNet-101 <https://arxiv.org/pdf/1512.03385.pdf>
    task_type: "classification"
    files:
      - name: resnet-101.prototxt
        size: 65439
        sha256: 5df4375748076544e6cc4bfde7885e633312b5ed529d65cc2ff6573a819ea972
        source: https://onedrive.live.com/download?cid=4006CBB8476FF777&resid=4006CBB8476FF777%2117892&authkey=AAFW2-FVoxeVRck
      - name: resnet-101.caffemodel
        size: 178662602
        sha256: 2847d93346d7928ec1f257f49f60ea53e9075c15265c494469610e67ffb7f2e2
        source: https://onedrive.live.com/download?cid=4006CBB8476FF777&resid=4006CBB8476FF777%2117896&authkey=AAFW2-FVoxeVRck
    output: "classification/resnet/v1/101/caffe/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --mean_values=data[104.0,117.0,123.0]
      - --input=data
      - --output=prob
      - --input_model=$dl_dir/resnet-101.caffemodel
      - --input_proto=$dl_dir/resnet-101.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/KaimingHe/deep-residual-networks/master/LICENSE

  - name: "resnet-152"
    description: >-
      ResNet-152 <https://arxiv.org/pdf/1512.03385.pdf>
    task_type: "classification"
    files:
      - name: resnet-152.prototxt
        size: 98034
        sha256: 9e0fc0df6ac038048a87c63d56fd534471b6b4f39d55651beaf201763e028489
        source: https://onedrive.live.com/download?cid=4006CBB8476FF777&resid=4006CBB8476FF777%2117893&authkey=AAFW2-FVoxeVRck
      - name: resnet-152.caffemodel
        size: 241444171
        sha256: 6253c4c4132c0b25c112b166629aa57dcaeec044a4c68ac9f003b6c801329d55
        source: https://onedrive.live.com/download?cid=4006CBB8476FF777&resid=4006CBB8476FF777%2117897&authkey=AAFW2-FVoxeVRck
    output: "classification/resnet/v1/152/caffe/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --mean_values=data[104.0,117.0,123.0]
      - --input=data
      - --output=prob
      - --input_model=$dl_dir/resnet-152.caffemodel
      - --input_proto=$dl_dir/resnet-152.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/KaimingHe/deep-residual-networks/master/LICENSE

  - name: "googlenet-v3"
    description: >-
      The `googlenet-v3` model is the first of the Inception family of models designed
      to perform image classification. Like the other Inception models. For details
      about this family of models, check out the paper <https://arxiv.org/pdf/1602.07261.pdf>.
    task_type: "classification"
    files:
      - name: googlenet-v3.tar.gz
        sha256: 7045b72a954af4dce36346f478610acdccbf149168fa25c78e54e32f0c723d6d
        source: https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz
    output: "classification/googlenet/v3/tf/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: googlenet-v3.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,299,299,3]
      - --input=input
      - --mean_values=input[127.5,127.5,127.5]
      - --scale_values=input[127.50000414375013]
      - --output=InceptionV3/Predictions/Softmax
      - --input_model=$dl_dir/inception_v3_2016_08_28_frozen.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "se-inception"
    description: >-
      BN-Inception with Squeeze-and-Excitation blocks <https://arxiv.org/pdf/1709.01507.pdf>
    task_type: "classification"
    files:
      - name: se-inception.prototxt
        sha256: 57813dfc27113ce1bc714b069d574f80643ad58480e6f35bdf1dec690075c6b3
        source: https://raw.githubusercontent.com/hujie-frank/SENet/369374b0678907a0e45c6f267256c7c34203177e/models/SE-BN-Inception.prototxt
      - name: se-inception.caffemodel
        size: 47855246
        sha256: 0660aa2b867f7353794d3ac02081d9178ac0709e8d8d75c29290dba4bc10ce03
        source:
          $type: google_drive
          id: 0BwHV3BlNKkWlTWRRbDZYbVB2WWc
    output: "classification/se-networks/se-inception/caffe/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=prob
      - --input_model=$dl_dir/se-inception.caffemodel
      - --input_proto=$dl_dir/se-inception.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/hujie-frank/SENet/master/LICENSE

  - name: "se-resnet-101"
    description: >-
      ResNet-101 with Squeeze-and-Excitation blocks <https://arxiv.org/pdf/1709.01507.pdf>
    task_type: "classification"
    files:
      - name: se-resnet-101.prototxt
        sha256: c97375db60ad04e1196966c7149bd5cc98fbb9a34bdde511c26c922ba791903d
        source: https://raw.githubusercontent.com/hujie-frank/SENet/369374b0678907a0e45c6f267256c7c34203177e/models/SE-ResNet-101.prototxt
      - name: se-resnet-101.caffemodel
        size: 197806200
        sha256: 09777ce1202087954ee34ae2566cf611d03d2d8195ced0fe51b612ebf951d729
        source:
          $type: google_drive
          id: 0BwHV3BlNKkWlTEg4YmcwQ0FoZFU
    output: "classification/se-networks/se-resnet-101/caffe/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=prob
      - --input_model=$dl_dir/se-resnet-101.caffemodel
      - --input_proto=$dl_dir/se-resnet-101.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/hujie-frank/SENet/master/LICENSE

  - name: "se-resnet-152"
    description: >-
      ResNet-152 with Squeeze-and-Excitation blocks <https://arxiv.org/pdf/1709.01507.pdf>
    task_type: "classification"
    files:
      - name: se-resnet-152.prototxt
        sha256: 9cfe789f971c3418e50e435f494d6479a5a0f263a07bf9c13e434a0e5919b2f2
        source: https://raw.githubusercontent.com/hujie-frank/SENet/369374b0678907a0e45c6f267256c7c34203177e/models/SE-ResNet-152.prototxt
      - name: se-resnet-152.caffemodel
        size: 268009578
        sha256: bbe7fc5b5068b7cd4b12ce1bb78f61bd3f48238a372e70ab9c0724afa778e5d1
        source:
          $type: google_drive
          id: 0BwHV3BlNKkWlcFE0Q2NTcWl3WUE
    output: "classification/se-networks/se-resnet-152/caffe/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=prob
      - --input_model=$dl_dir/se-resnet-152.caffemodel
      - --input_proto=$dl_dir/se-resnet-152.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/hujie-frank/SENet/master/LICENSE

  - name: "se-resnet-50"
    description: >-
      ResNet-50 with Squeeze-and-Excitation blocks <https://arxiv.org/pdf/1709.01507.pdf>
    task_type: "classification"
    files:
      - name: se-resnet-50.prototxt
        sha256: eebbe3c64201f34492caf501498f6031152edbd4a44ed106de69441060ff117c
        source: https://raw.githubusercontent.com/hujie-frank/SENet/369374b0678907a0e45c6f267256c7c34203177e/models/SE-ResNet-50.prototxt
      - name: se-resnet-50.caffemodel
        size: 112602669
        sha256: 72880fde3bd29b324bb302c80f49a098b8970597494c56525fd410a8d2ed5993
        source:
          $type: google_drive
          id: 0BwHV3BlNKkWlS2QwZHFzM3RjNzg
    output: "classification/se-networks/se-resnet-50/caffe"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=prob
      - --input_model=$dl_dir/se-resnet-50.caffemodel
      - --input_proto=$dl_dir/se-resnet-50.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/hujie-frank/SENet/master/LICENSE

  - name: "se-resnext-50"
    description: >-
      ResNext-50 with Squeeze-and-Excitation blocks <https://arxiv.org/pdf/1709.01507.pdf>
    task_type: "classification"
    files:
      - name: se-resnext-50.prototxt
        sha256: a44865802483b8e20fcc712540c4995ef27c3dc809d9235f5882a13ef5c16e67
        source: https://raw.githubusercontent.com/hujie-frank/SENet/369374b0678907a0e45c6f267256c7c34203177e/models/SE-ResNeXt-50.prototxt
      - name: se-resnext-50.caffemodel
        size: 110550637
        sha256: f12c6b53c2dcd0f38f388d3d5f98cbfc039357e84842e661f28a49719dd52219
        source:
          $type: google_drive
          id: 0BwHV3BlNKkWlQ2Z0Q204V1RITjA
    output: "classification/se-networks/se-resnext-50/caffe/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=prob
      - --input_model=$dl_dir/se-resnext-50.caffemodel
      - --input_proto=$dl_dir/se-resnext-50.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/hujie-frank/SENet/master/LICENSE

  - name: "se-resnext-101"
    description: >-
      ResNext-101 with Squeeze-and-Excitation blocks <https://arxiv.org/pdf/1709.01507.pdf>
    task_type: "classification"
    files:
      - name: se-resnext-101.prototxt
        sha256: 8a23f1488f5dad2bc4e11b3e7733bc95783301d8c426677989fb11eb7ea2de8b
        source: https://raw.githubusercontent.com/hujie-frank/SENet/369374b0678907a0e45c6f267256c7c34203177e/models/SE-ResNeXt-101.prototxt
      - name: se-resnext-101.caffemodel
        size: 196447403
        sha256: 78dc95c9b768fdb32a0a3981a686edaf655df82973b051d818bae523c9a93c90
        source:
          $type: google_drive
          id: 0BwHV3BlNKkWleklsNzBiZlprblk
    output: "classification/se-networks/se-resnext-101/caffe"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[104.0,117.0,123.0]
      - --output=prob
      - --input_model=$dl_dir/se-resnext-101.caffemodel
      - --input_proto=$dl_dir/se-resnext-101.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/hujie-frank/SENet/master/LICENSE

  - name: "Sphereface"
    description: >-
      Deep face recognition under open-set protocol <https://arxiv.org/pdf/1704.08063.pdf>
    task_type: "face_recognition"
    files:
      - name: Sphereface.prototxt
        sha256: 7cf5808fd0561db20daae862b83677b7437e788420fae68ab8d97c935e67d82c
        source: https://raw.githubusercontent.com/wy1iu/sphereface/7f9acb157c78a99dbefd041fce9f188400bbb4e5/train/code/sphereface_deploy.prototxt
      - name: Sphereface.caffemodel
        size: 90688218
        sha256: 092d8fb00291d80ed7e43f7c9323693581cd75e734be3c52764525043288a20d
        source:
          $type: google_drive
          id: 0B_geeR2lTMegb2F6dmlmOXhWaVk
    output: "face_recognition/sphereface/caffe/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,112,96]
      - --input=data
      - --mean_values=data[127.5,127.5,127.5]
      - --scale_values=data[128.0]
      - --output=fc5
      - --input_model=$dl_dir/Sphereface.caffemodel
      - --input_proto=$dl_dir/Sphereface.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/wy1iu/sphereface/master/LICENSE

  - name: "license-plate-recognition-barrier-0007"
    description: "TensorFlow LPRNet"
    task_type: "optical_character_recognition"
    files:
      - name: license-plate-recognition-barrier-0007.tar.gz
        sha256: 6c0b8651f0eead6de43e07491fd41809a4a7da141f1b5002dfd8dd207bdb1018
        source: https://download.01.org/openvinotoolkit/training_toolbox_tensorflow/models/lpr/chinese_lp/license-plate-recognition-barrier-0007.tar.gz
    output: "optical_character_recognition/license_plate_recognition/tf/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: license-plate-recognition-barrier-0007.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,24,94,3]
      - --input=input
      - --scale_values=input[254.99997577500233]
      - --output=d_predictions
      - --input_model=$dl_dir/license-plate-recognition-barrier-0007/graph.pb.frozen
    framework: tf
    license: https://raw.githubusercontent.com/opencv/training_toolbox_tensorflow/develop/LICENSE

  - name: "face-detection-retail-0044"
    description: "Face Detection (SqNet1.0modif+single scale) with BatchNormalization trained with negatives"
    task_type: "detection"
    files:
      - name: face-detection-retail-0044.prototxt
        sha256: 89ea5bb9c293ebabb56b9f6dfb4cfc6c46cd146cdce307a2f5a2755bf904fc79
        source: https://raw.githubusercontent.com/opencv/training_toolbox_caffe/63ccbbc328f0c1f414f459c284293b3929b09339/models/face_detection/deploy.prototxt
      - name: face-detection-retail-0044.caffemodel
        sha256: 10f68b73f3b68db89fab151be51fc90a0bc1e2a18a87ac642e88aa9e94d53f8f
        source: https://github.com/opencv/training_toolbox_caffe/raw/63ccbbc328f0c1f414f459c284293b3929b09339/models/face_detection/face-detection-retail-0044.caffemodel
    output: "Retail/object_detection/face/sqnet1.0modif-ssd/0044/caffe/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,300,300]
      - --input=data
      - --input_model=$dl_dir/face-detection-retail-0044.caffemodel
      - --input_proto=$dl_dir/face-detection-retail-0044.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/opencv/training_toolbox_caffe/develop/LICENSE

  - name: "mobilenet-v1-1.0-224"
    description: >-
      `mobilenet-v1-1.0-224` is one of MobileNet V1 architecture <https://arxiv.org/abs/1704.04861>
      with the width multiplier 1.0 and resolution 224. It is small, low-latency,
      low-power models parameterized to meet the resource constraints of a variety
      of use cases. They can be built upon for classification, detection, embeddings
      and segmentation similar to how other popular large scale models are used.
    task_type: "classification"
    files:
      - name: mobilenet-v1-1.0-224.prototxt
        sha256: 8e6a26b8f2c7cf7a066d571660cfd8a1544a5a25399df33ad499f3d733f16729
        source: https://raw.githubusercontent.com/shicai/MobileNet-Caffe/26a8b8c0afb6114a07c1c9e4f550e4e0dd8cced1/mobilenet_deploy.prototxt
      - name: mobilenet-v1-1.0-224.caffemodel
        sha256: 8d6edcd3dbd1356f2f19dd220c362c2ba8f44233a9b6c12ca6d0351cb0c446b6
        source: https://github.com/shicai/MobileNet-Caffe/raw/26a8b8c0afb6114a07c1c9e4f550e4e0dd8cced1/mobilenet.caffemodel
    output: "classification/mobilenet/v1/1.0/224/cf/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[103.94,116.78,123.68]
      - --scale_values=data[58.8235294117647]
      - --output=prob
      - --input_model=$dl_dir/mobilenet-v1-1.0-224.caffemodel
      - --input_proto=$dl_dir/mobilenet-v1-1.0-224.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/shicai/MobileNet-Caffe/26a8b8c0afb6114a07c1c9e4f550e4e0dd8cced1/LICENSE

  - name: "mobilenet-v2"
    description: >-
      MobileNet V2 <https://arxiv.org/pdf/1801.04381.pdf>
    task_type: "classification"
    files:
      - name: mobilenet-v2.prototxt
        sha256: 06a0820a5edc6d2c24e83e0b95824d0dae464ced3d5db82f51e461098a03b887
        source: https://raw.githubusercontent.com/shicai/MobileNet-Caffe/26a8b8c0afb6114a07c1c9e4f550e4e0dd8cced1/mobilenet_v2_deploy.prototxt
      - name: mobilenet-v2.caffemodel
        sha256: a3124ce7abd258c7f35a2c586576bee8116934fa2a8556e4e528041859dd753f
        source: https://github.com/shicai/MobileNet-Caffe/raw/26a8b8c0afb6114a07c1c9e4f550e4e0dd8cced1/mobilenet_v2.caffemodel
    output: "classification/mobilenet/v2/cf/"
    model_optimizer_args:
      - --framework=caffe
      - --data_type=FP32
      - --input_shape=[1,3,224,224]
      - --input=data
      - --mean_values=data[103.94,116.78,123.68]
      - --scale_values=data[58.8235294117647]
      - --output=prob
      - --input_model=$dl_dir/mobilenet-v2.caffemodel
      - --input_proto=$dl_dir/mobilenet-v2.prototxt
    framework: caffe
    license: https://raw.githubusercontent.com/shicai/MobileNet-Caffe/26a8b8c0afb6114a07c1c9e4f550e4e0dd8cced1/LICENSE

  - name: "faster_rcnn_inception_v2_coco"
    description: >-
      Faster R-CNN with Inception v2. Used for object detection. For details see paper
      <https://arxiv.org/pdf/1801.04381.pdf>.
    task_type: "detection"
    files:
      - name: faster_rcnn_inception_v2_coco.tar.gz
        sha256: db3295e9a52d406540e84bdd056edeedbf938782a7bc4af7918aaa5dc30f0df5
        source: http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz
    output: "object_detection/common/faster_rcnn/faster_rcnn_inception_v2_coco/tf/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: faster_rcnn_inception_v2_coco.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,600,600,3]
      - --input=image_tensor
      - --output=detection_scores,detection_boxes,num_detections
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/faster_rcnn_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config
      - --input_model=$dl_dir/faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "deeplabv3"
    description: >-
      DeepLab is a state-of-art deep learning model for semantic image segmentation.
      For details see paper <https://arxiv.org/pdf/1706.05587.pdf>
    task_type: "semantic_segmentation"
    files:
      - name: deeplabv3.tar.gz
        sha256: cd506941e4f88fd053903913761df2e76ea00c01079cecfd35855304a4a5fb48
        source: http://download.tensorflow.org/models/deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz
    output: "semantic_segmentation/deeplab/v3/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: deeplabv3.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --input_shape=[1,513,513,3]
      - --input=1:mul_1
      - --output=ArgMax
      - --input_model=$dl_dir/deeplabv3_mnv2_pascal_train_aug/frozen_inference_graph.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "ctpn"
    description: >-
      Detecting Text in Natural Image with Connectionist Text Proposal Network. For
      details see paper <https://arxiv.org/pdf/1609.03605.pdf>.
    task_type: "detection"
    files:
      - name: ctpn.pb
        sha256: 09b3a0cc57eb826dd6b6fa95a03e078ad435b7b5fb0186dad2abdb98a4fdf64a
        source: https://github.com/eragonruan/text-detection-ctpn/releases/download/untagged-48d74c6337a71b6b5f87/ctpn.pb
    output: "text_detection/ctpn/tf/"
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --input_shape=[1,600,600,3]
      - --input=Placeholder
      - --mean_values=Placeholder[102.9801,115.9465,122.7717]
      - --output=Reshape_2,rpn_bbox_pred/Reshape_1
      - --input_model=$dl_dir/ctpn.pb
    framework: tf
    license: https://raw.githubusercontent.com/eragonruan/text-detection-ctpn/banjin-dev/LICENSE

  - name: "ssd_mobilenet_v1_coco"
    description: >-
      The `ssd_mobilenet_v1_coco` model is a Single-Shot multibox Detection <SSD>
      <https://arxiv.org/pdf/1801.04381.pdf> network intended to perform object detection.
      The difference bewteen this model and the `mobilenet-ssd` is that there the
      `mobilenet-ssd` can only detect face, the `ssd_mobilenet_v1_coco` model can
      detect objects.
    task_type: "detection"
    files:
      - name: ssd_mobilenet_v1_coco.tar.gz
        sha256: 8788f89108519fd1102b8a5c2ac861cf6d86603571b6ce5bbd1c245b7fe005e3
        source: http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz
    output: "object_detection/common/ssd_mobilenet/ssd_mobilenet_v1_coco/tf/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: ssd_mobilenet_v1_coco.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,300,300,3]
      - --input=image_tensor
      - --output=detection_scores,detection_boxes,num_detections
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/ssd_v2_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config
      - --input_model=$dl_dir/ssd_mobilenet_v1_coco_2018_01_28/frozen_inference_graph.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "faster_rcnn_resnet101_coco"
    description: >-
      Faster R-CNN Resnet-101 model. Used for object detection. For details see paper
      <https://arxiv.org/pdf/1801.04381.pdf>.
    task_type: "detection"
    files:
      - name: faster_rcnn_resnet101_coco.tar.gz
        sha256: ef3b36b3bc3c4057362a62e40b89dbdbef3dbb0c91f2f7df43967920d24821e5
        source: http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz
    output: "object_detection/common/faster_rcnn/faster_rcnn_resnet101_coco/tf/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: faster_rcnn_resnet101_coco.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,600,600,3]
      - --input=image_tensor
      - --output=detection_scores,detection_boxes,num_detections
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/faster_rcnn_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/faster_rcnn_resnet101_coco_2018_01_28/pipeline.config
      - --input_model=$dl_dir/faster_rcnn_resnet101_coco_2018_01_28/frozen_inference_graph.pb
    framework: tf
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "mobilenet-v2-1.4-224"
    description: >-
      `mobilenet-v2-1.4-224` is one of MobileNets - small, low-latency, low-power
      models parameterized to meet the resource constraints of a variety of use cases.
      They can be built upon for classification, detection, embeddings and segmentation
      similar to how other popular large scale models are used. For details see paper
      <https://arxiv.org/abs/1704.04861>
    task_type: "classification"
    files:
      - name: mobilenet-v2-1.4-224.tar.gz
        sha256: a20d0c8d698502dc6a620528871c97a588885df7737556243a3412b39fce85e0
        source: https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.4_224.tgz
    output: "classification/mobilenet/v2/tf/mobilenet_v2_1.4_224/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: mobilenet-v2-1.4-224.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,224,224,3]
      - --input=input
      - --mean_values=input[127.5,127.5,127.5]
      - --scale_values=input[127.00001206500114]
      - --output=MobilenetV2/Predictions/Reshape_1
      - --input_model=$dl_dir/mobilenet_v2_1.4_224_frozen.pb
    framework: "tf"
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "mobilenet-v2-1.0-224"
    description: >-
      `mobilenet-v2-1.0-224` is one of MobileNets - small, low-latency, low-power
      models parameterized to meet the resource constraints of a variety of use cases.
      They can be built upon for classification, detection, embeddings and segmentation
      similar to how other popular large scale models are used. For details see paper
      <https://arxiv.org/abs/1704.04861>.
    task_type: "classification"
    files:
      - name: mobilenet_v2_1.0_224.tgz
        sha256: 318084bc1b63d6d7b854553e09cdf77078b1c0168be27c59a0d44253b5ed49dc
        source: https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz
    output: "classification/mobilenet/v2/tf/mobilenet_v2_1.0_224/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: mobilenet_v2_1.0_224.tgz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,224,224,3]
      - --input=input
      - --mean_values=input[127.5,127.5,127.5]
      - --scale_values=input[127.00001206500114]
      - --output=MobilenetV2/Predictions/Reshape_1
      - --input_model=$dl_dir/mobilenet_v2_1.0_224_frozen.pb
    framework: "tf"
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "brain-tumor-segmentation-0001"
    description: >-
      This model was created for participation in the Brain Tumor Segmentation Challenge
      <https://www.med.upenn.edu/sbia/brats2018.html> (BraTS) 2018.   The model is
      based on the corresponding paper <https://arxiv.org/abs/1810.04008>, where authors
      present deep cascaded approach for automatic brain tumor segmentation. The paper
      describes modifications to 3D UNet architecture and specific augmentation strategy
      to efficiently handle multimodal MRI input. Besides this, the approach to enhance
      segmentation quality with context obtained from models of the same topology
      operating on downscaled data is introduced.   Each input modality has its own
      encoder which are later fused together to produce single output segmentation.
    task_type: "semantic_segmentation"
    files:
      - name: brain-tumor-segmentation-0001-symbol.json
        size: 100106
        sha256: 2e75c659c6cab619bda9d5f039619eb12d71949c9c171b247faebe63d2ea7a39
        source:
          $type: google_drive
          id: 1HaExnmHtF2nl2PkcLfKJDzA_7IMmLyKJ
      - name: brain-tumor-segmentation-0001-0000.params
        size: 152788159
        sha256: d73acc63151f96341184ce54dd59c8285ee7cbb744a8ca9ffd7d3e181ffae417
        source:
          $type: google_drive
          id: 1T2ldCISt5N2TEUfv6ggRB1dw0cucTqT2
    output: "semantic_segmentation/cascaded_unet/brats2018/mxnet"
    model_optimizer_args:
      - --framework=mxnet
      - --data_type=FP32
      - --input_shape=[1,4,128,128,128]
      - --input=data_crop
      - --output=blockgrad7
      - --input_model=$dl_dir/brain-tumor-segmentation-0001-0000.params
    framework: mxnet
    license: https://raw.githubusercontent.com/lachinov/brats2018-graphlabunn/master/LICENSE

  - name: "mobilenet-v1-1.0-224-tf"
    description: >-
      `mobilenet-v1-1.0-224` is one of MobileNets - small, low-latency, low-power
      models parameterized to meet the resource constraints of a variety of use cases.
      They can be built upon for classification, detection, embeddings and segmentation
      similar to how other popular large scale models are used. For details see paper
      <https://arxiv.org/abs/1704.04861>
    task_type: "classification"
    files:
      - name: mobilenet_v1_1.0_224.tgz
        sha256: 2fadeabb9968ec6833bee903900dda6e61b3947200535874ce2fe42a8493abc0
        source: http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_224.tgz
    output: "classification/mobilenet/v1/1.0/224/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: mobilenet_v1_1.0_224.tgz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,224,224,3]
      - --input=input
      - --mean_values=input[127.5,127.5,127.5]
      - --scale_values=input[127.50000414375013]
      - --output=MobilenetV1/Predictions/Reshape_1
      - --input_model=$dl_dir/mobilenet_v1_1.0_224_frozen.pb
    framework: "tf"
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "mobilenet-v1-0.50-224"
    description: >-
      `mobilenet-v1-0.50-224` is one of MobileNets - small, low-latency, low-power
      models parameterized to meet the resource constraints of a variety of use cases.
      They can be built upon for classification, detection, embeddings and segmentation
      similar to how other popular large scale models are used. For details see paper
      <https://arxiv.org/abs/1704.04861>
    task_type: "classification"
    files:
      - name: mobilenet_v1_0.5_224.tgz
        sha256: 98cf7a39552f73920cb99617cfa9b88d5732a87abf9ec14f7cc7f3ade1db0aaa
        source: http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.5_224.tgz
    output: "classification/mobilenet/v1/0.50/224/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: mobilenet_v1_0.5_224.tgz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,224,224,3]
      - --input=input
      - --mean_values=input[127.5,127.5,127.5]
      - --scale_values=input[127.50000414375013]
      - --output=MobilenetV1/Predictions/Reshape_1
      - --input_model=$dl_dir/mobilenet_v1_0.5_224_frozen.pb
    framework: "tf"
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "mobilenet-v1-0.50-160"
    description: >-
      `mobilenet-v1-0.50-160` is one of MobileNets - small, low-latency, low-power
      models parameterized to meet the resource constraints of a variety of use cases.
      They can be built upon for classification, detection, embeddings and segmentation
      similar to how other popular large scale models are used. For details see paper
      <https://arxiv.org/abs/1704.04861>
    task_type: "classification"
    files:
      - name: mobilenet_v1_0.5_160.tgz
        sha256: 6bbc9dd7892433e49b4b6ff6af2952183eaa6c1c0cb862868465377a29c77b0d
        source: http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.5_160.tgz
    output: "classification/mobilenet/v1/0.50/160/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: mobilenet_v1_0.5_160.tgz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,160,160,3]
      - --input=input
      - --mean_values=input[127.5,127.5,127.5]
      - --scale_values=input[127.50000414375013]
      - --output=MobilenetV1/Predictions/Reshape_1
      - --input_model=$dl_dir/mobilenet_v1_0.5_160_frozen.pb
    framework: "tf"
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "mobilenet-v1-0.25-128"
    description: >-
      `mobilenet-v1-0.25-128` is one of MobileNets - small, low-latency, low-power
      models parameterized to meet the resource constraints of a variety of use cases.
      They can be built upon for classification, detection, embeddings and segmentation
      similar to how other popular large scale models are used. For details see paper
      <https://arxiv.org/abs/1704.04861>
    task_type: "classification"
    files:
      - name: mobilenet_v1_0.25_128.tgz
        sha256: 879ddc3e0857f3611b5cf248e36de2288c7a11ea8c2ed8a8bdded635e6010dfe
        source: http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_0.25_128.tgz
    output: "classification/mobilenet/v1/0.25/128/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: mobilenet_v1_0.25_128.tgz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,128,128,3]
      - --input=input
      - --mean_values=input[127.5,127.5,127.5]
      - --scale_values=input[127.50000414375013]
      - --output=MobilenetV1/Predictions/Reshape_1
      - --input_model=$dl_dir/mobilenet_v1_0.25_128_frozen.pb
    framework: "tf"
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "faster_rcnn_resnet50_coco"
    description: >-
      Faster R-CNN Resnet-50 model. Used for object detection. For details see paper
      <https://arxiv.org/pdf/1801.04381.pdf>.
    task_type: "detection"
    files:
      - name: faster_rcnn_resnet50_coco_2018_01_28.tar.gz
        sha256: 0f898f96d6c416de192c516fb6fa773ae9f5ee253eb2ab4015445fbd6eb0ab76
        source: http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz
    output: "object_detection/common/faster_rcnn/faster_rcnn_resnet50_coco/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: faster_rcnn_resnet50_coco_2018_01_28.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,600,600,3]
      - --input=image_tensor
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/faster_rcnn_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/faster_rcnn_resnet50_coco_2018_01_28/pipeline.config
      - --output=detection_scores,detection_boxes,num_detections
      - --input_model=$dl_dir/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb
    framework: "tf"
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "faster_rcnn_inception_resnet_v2_atrous_coco"
    description: >-
      Faster R-CNN with Inception Resnet v2 Atrous version. Used for object detection.
      For details see paper <https://arxiv.org/pdf/1801.04381.pdf>.
    task_type: "detection"
    files:
      - name: faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz
        sha256: d615532f464532620d742be6564bddaaaba3e5f9670c245c6309eb7842876c62
        source: http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz
    output: "object_detection/common/faster_rcnn/faster_rcnn_inception_resnet_v2_atrous_coco/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,600,600,3]
      - --input=image_tensor
      - --tensorflow_use_custom_operations_config=$mo_dir/extensions/front/tf/faster_rcnn_support.json
      - --tensorflow_object_detection_api_pipeline_config=$dl_dir/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/pipeline.config
      - --output=detection_scores,detection_boxes,num_detections
      - --input_model=$dl_dir/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/frozen_inference_graph.pb
    framework: "tf"
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "inception-resnet-v2-tf"
    description: >-
      The `inception-resnet-v2` model is one of the Inception family of models designed
      to perform image classification.1 Like the other Inception models. For details
      about this family of models, check out the paper <https://arxiv.org/pdf/1602.07261.pdf>.
    task_type: "classification"
    files:
      - name: inception_resnet_v2_2018_04_27.tgz
        sha256: fb16b93ff2b2bcda0da5cdfd25a8d5b8b74438943dae738db659bad0d3d48ff1
        source: https://storage.googleapis.com/download.tensorflow.org/models/tflite/model_zoo/upload_20180427/inception_resnet_v2_2018_04_27.tgz
    output: "classification/inception-resnet/v2/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: inception_resnet_v2_2018_04_27.tgz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --reverse_input_channels
      - --input_shape=[1,299,299,3]
      - --input=input
      - --mean_values=input[127.5,127.5,127.5]
      - --scale_values=input[127.50000414375013]
      - --output=InceptionResnetV2/AuxLogits/Logits/BiasAdd
      - --input_model=$dl_dir/inception_resnet_v2.pb
    framework: "tf"
    license: https://raw.githubusercontent.com/tensorflow/models/master/LICENSE

  - name: "densenet-121-tf"
    description: >-
      This is an Tensorflow\* version of `densenet-121` model, one of the DenseNet
      group of models designed to perform image classification. The weights were converted
      from DenseNet-Keras Models. For details see repository <https://github.com/pudae/tensorflow-densenet/>,
      paper <https://arxiv.org/pdf/1608.06993.pdf>
    task_type: "classification"
    files:
      - name: tf-densenet121.tar.gz
        size: 30597420
        sha256: b31ec840358f1d20e1c6364d05ce463cb0bc0480042e663ad54547189501852d
        source:
          $type: google_drive
          id: 0B_fUSpodN0t0eW1sVk1aeWREaDA
    output: "classification/densenet/121/tf/"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: tf-densenet121.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --input_shape=[1,224,224,3]
      - --input=Placeholder
      - --mean_values=Placeholder[123.68,116.78,103.94]
      - --scale_values=Placeholder[58.8235294117647]
      - --output=densenet121/predictions/Reshape_1
      - --input_meta_graph=$dl_dir/tf-densenet121.ckpt.meta
      - --input_checkpoint=$dl_dir/tf-densenet121.ckpt.data-00000-of-00001
    framework: tf
    license: https://raw.githubusercontent.com/pudae/tensorflow-densenet/master/LICENSE

  - name: "densenet-169-tf"
    description: >-
      This is an Tensorflow\* version of `densenet-169` model, one of the DenseNet
      group of models designed to perform image classification. The weights were converted
      from DenseNet-Keras Models. For details see repository <https://github.com/pudae/tensorflow-densenet/>,
      paper <https://arxiv.org/pdf/1608.06993.pdf>
    task_type: "classification"
    files:
      - name: tf-densenet169.tar.gz
        size: 54307314
        sha256: 6f20b51077c49cb87df11d181b055a0aec1d27f969b84b4ed8115dd4933fccd4
        source:
          $type: google_drive
          id: 0B_fUSpodN0t0TDB5Ti1PeTZMM2c
    output: "classification/densenet/169/tf"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: tf-densenet169.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --input_shape=[1,224,224,3]
      - --input=Placeholder
      - --mean_values=Placeholder[123.68,116.78,103.94]
      - --scale_values=Placeholder[58.8235294117647]
      - --output=densenet169/predictions/Reshape_1
      - --input_meta_graph=$dl_dir/tf-densenet169.ckpt.meta
      - --input_checkpoint=$dl_dir/tf-densenet169.ckpt.data-00000-of-00001
    framework: tf
    license: https://raw.githubusercontent.com/pudae/tensorflow-densenet/master/LICENSE

  - name: "densenet-161-tf"
    description: >-
      This is an Tensorflow\* version of `densenet-161` model, one of the DenseNet
      group of models designed to perform image classification. The weights were converted
      from DenseNet-Keras Models. For details see repository <https://github.com/pudae/tensorflow-densenet/>,
      paper <https://arxiv.org/pdf/1608.06993.pdf>
    task_type: "classification"
    files:
      - name: tf-densenet161.tar.gz
        size: 110578586
        sha256: f4745258b9fe2f234711a70e4192368f169bf0c1956087a210b08270dbe96ca7
        source:
          $type: google_drive
          id: 0B_fUSpodN0t0NmZvTnZZa2plaHc
    output: "classification/densenet/161/tf"
    postprocessing:
      - $type: unpack_archive
        format: gztar
        file: tf-densenet161.tar.gz
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --input_shape=[1,224,224,3]
      - --input=Placeholder
      - --mean_values=Placeholder[123.68,116.78,103.94]
      - --scale_values=Placeholder[58.8235294117647]
      - --output=densenet161/predictions/Reshape_1
      - --input_meta_graph=$dl_dir/tf-densenet161.ckpt.meta
      - --input_checkpoint=$dl_dir/tf-densenet161.ckpt.data-00000-of-00001
    framework: tf
    license: https://raw.githubusercontent.com/pudae/tensorflow-densenet/master/LICENSE

  - name: "facenet-20180408-102900"
    description: >-
      FaceNet: A Unified Embedding for Face Recognition and Clustering. For details
      see repository <https://github.com/davidsandberg/facenet/>, paper <https://arxiv.org/pdf/1503.03832.pdf>
    task_type: "face_recognition"
    files:
      - name: 20180408-102900.zip
        size: 195479980
        sha256: 2a32a4d6b797b0e35e065c674dfa2d60e9eb2372aa10728bd0b221abe12490ac
        source:
          $type: google_drive
          id: 1R77HmFADxe87GmoLwzfgMu_HY0IhcyBz
    output: "face_recognition/facenet/CASIA-WebFace/tf/"
    postprocessing:
      - $type: unpack_archive
        format: zip
        file: 20180408-102900.zip
    model_optimizer_args:
      - --framework=tf
      - --data_type=FP32
      - --freeze_placeholder_with_value=phase_train->False
      - --reverse_input_channels
      - --input_shape=[1,160,160,3],[1]
      - --input=image_batch,phase_train
      - --mean_values=image_batch[127.5,127.5,127.5]
      - --scale_values=image_batch[128.0]
      - --output=embeddings
      - --input_model=$dl_dir/20180408-102900/20180408-102900.pb
    framework: tf
    license: https://raw.githubusercontent.com/davidsandberg/facenet/master/LICENSE.md

  - name: "action-recognition-0001-decoder"
    description: >-
      This is an general-purpose action recognition model for Kinetics-400 dataset.
      The model uses Video Transformer approach with ResNet34 encoder. Please refer
      to the kinetics <https://deepmind.com/research/open-source/open-source-datasets/kinetics/>
      dataset specification to see list of action that are recognised by this model.

      This model is only decoder part of the whole pipeline. It accepts stack of frame
      embeddings, computed by action-recognition-0001-encoder, and produces prediction
      on input video. Video frames should be sampled to cover ~1 second fragment (i.e.
      skip every second frame in 30 fps video).
    task_type: "action_recognition"
    files:
      - name: FP32/action-recognition-0001-decoder.xml
        sha256: 022d1249402eaf4d50a4e6dcf0d9df4198a3248d409474d82271cacee9986cb6
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/action-recognition-0001-decoder/FP32/action-recognition-0001-decoder.xml
      - name: FP32/action-recognition-0001-decoder.bin
        sha256: 3fe939d259eb096dba98c6e0870237399344a415ae49d33b729812a8d34c4cf3
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/action-recognition-0001-decoder/FP32/action-recognition-0001-decoder.bin
      - name: FP16/action-recognition-0001-decoder.xml
        sha256: 7fb29a3e7274d3b2dcbbc2f82a9e241415ecd0e85bc092c88b4ddbe5ebe4347d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/action-recognition-0001-decoder/FP16/action-recognition-0001-decoder.xml
      - name: FP16/action-recognition-0001-decoder.bin
        sha256: ba5d5b410c9e8f3cb198e92868d494f69ab2048cf739c397acfa58c9b9ddb92a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/action-recognition-0001-decoder/FP16/action-recognition-0001-decoder.bin
    output: "Transportation/action_recognition/resnet34_vtn/kinetics/decoder/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "action-recognition-0001-encoder"
    description: >-
      This is an general-purpose action recognition model for Kinetics-400 dataset.
      The model uses Video Transformer approach with ResNet34 encoder. Please refer
      to the kinetics <https://deepmind.com/research/open-source/open-source-datasets/kinetics/>
      dataset specification to see list of action that are recognised by this model.

      This model is only encoder part of the whole pipeline. It accepts video frame
      and produces embedding. Use action-recognition-0001-decoder to produce prediction
      from embeddings of 16 frames. Video frames should be sampled to cover ~1 second
      fragment (i.e. skip every second frame in 30 fps video).
    task_type: "action_recognition"
    files:
      - name: FP32/action-recognition-0001-encoder.xml
        sha256: 3228cfa0bb43ed2be635e3b5fe9a3b895ec88896538a73d7cc490df0780ee891
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/action-recognition-0001-encoder/FP32/action-recognition-0001-encoder.xml
      - name: FP32/action-recognition-0001-encoder.bin
        sha256: 35e1454bdac521c7b7664db9b26aebda2bba6944e9da225e9884c0241021d92a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/action-recognition-0001-encoder/FP32/action-recognition-0001-encoder.bin
      - name: FP16/action-recognition-0001-encoder.xml
        sha256: 4d6ced067ab9455ed812ada4188bc662d95e107f2d48e80aa54f90332336e120
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/action-recognition-0001-encoder/FP16/action-recognition-0001-encoder.xml
      - name: FP16/action-recognition-0001-encoder.bin
        sha256: f6347d5c4baf60581d0179a90702180798cb5f3d76079e919493d50f81406e14
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/action-recognition-0001-encoder/FP16/action-recognition-0001-encoder.bin
    output: "Transportation/action_recognition/resnet34_vtn/kinetics/encoder/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "age-gender-recognition-retail-0013"
    description: >-
      Fully convolutional network for simultaneous Age/Gender recognition. The network
      is able to recognize age of people in [18, 75] years old range, it is not applicable
      for children since their faces were not in the training set.
    task_type: "object_attributes"
    files:
      - name: FP32/age-gender-recognition-retail-0013.xml
        sha256: 53d81c7364341cf641e411cab42e82c2bdd1b348d984be3ecebf904ad16c9068
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/age-gender-recognition-retail-0013/FP32/age-gender-recognition-retail-0013.xml
      - name: FP32/age-gender-recognition-retail-0013.bin
        sha256: 4dab79cfedebd628f3327367a91c9736a32fbf9cc733cbbf1629d16910d4ace7
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/age-gender-recognition-retail-0013/FP32/age-gender-recognition-retail-0013.bin
      - name: FP16/age-gender-recognition-retail-0013.xml
        sha256: 8b5623fd58aa6343fd1ef5e44c79bb90a40effa272c50f0227eb16eac7bf60ea
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/age-gender-recognition-retail-0013/FP16/age-gender-recognition-retail-0013.xml
      - name: FP16/age-gender-recognition-retail-0013.bin
        sha256: 401101e0a01b3d68add39deae833bcf9f54238d37dd13e3fb1534aa8fbe4719d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/age-gender-recognition-retail-0013/FP16/age-gender-recognition-retail-0013.bin
    output: "Retail/object_attributes/age_gender/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "driver-action-recognition-adas-0002-decoder"
    description: >-
      This is an action recognition model for the driver monitoring use case. The
      model uses Video Transformer approach with MobileNetv2 encoder. It is able to
      recognize the following actions: drinking, doing hair or making up, operating
      the radio, reaching behind, safe driving, talking on the phone, texting.

      This model is only decoder part of the whole pipeline. It accepts stack of frame
      embeddings, computed by driver-action-recognition-adas-0002-encoder, and produces
      prediction on input video. Video frames should be sampled to cover ~1 second
      fragment (i.e. skip every second frame in 30 fps video).
    task_type: "action_recognition"
    files:
      - name: FP32/driver-action-recognition-adas-0002-decoder.xml
        sha256: 123df0cea03c315f2f1ff67d4d32dea46f5fa0933d81b1606854368dd846b8cd
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/driver-action-recognition-adas-0002-decoder/FP32/driver-action-recognition-adas-0002-decoder.xml
      - name: FP32/driver-action-recognition-adas-0002-decoder.bin
        sha256: ad9bdefcc540be5d704820fd6af43e1c5d7463a07de62cd24d27d8d081d9303e
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/driver-action-recognition-adas-0002-decoder/FP32/driver-action-recognition-adas-0002-decoder.bin
      - name: FP16/driver-action-recognition-adas-0002-decoder.xml
        sha256: 86f15bf0a4d1216f2ef8697991f7f457f6a80241b5f6dab8727f252091ec2539
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/driver-action-recognition-adas-0002-decoder/FP16/driver-action-recognition-adas-0002-decoder.xml
      - name: FP16/driver-action-recognition-adas-0002-decoder.bin
        sha256: ab2ffc20577fc71c01bf850b325e261e29bd4470d3b6afd7ea4a940a3fb74fec
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/driver-action-recognition-adas-0002-decoder/FP16/driver-action-recognition-adas-0002-decoder.bin
    output: "Transportation/action_recognition/driver_monitoring/mobilenetv2/decoder/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "driver-action-recognition-adas-0002-encoder"
    description: >-
      This is an action recognition model for the driver monitoring use case. The
      model uses Video Transformer approach with MobileNetv2 encoder. It is able to
      recognize the following actions: drinking, doing hair or making up, operating
      the radio, reaching behind, safe driving, talking on the phone, texting.

      This model is only encoder part of the whole pipeline. It accepts video frame
      and produces embedding. Use driver-action-recognition-adas-0002-decoder to produce
      prediction from embeddings of 16 frames. Video frames should be sampled to cover
      ~1 second fragment (i.e. skip every second frame in 30 fps video).
    task_type: "action_recognition"
    files:
      - name: FP32/driver-action-recognition-adas-0002-encoder.xml
        sha256: f38f78b5ba13613f2f2fe8321a7a66dc4c6f2e0bb424b4de156ddb5fb24ab90f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/driver-action-recognition-adas-0002-encoder/FP32/driver-action-recognition-adas-0002-encoder.xml
      - name: FP32/driver-action-recognition-adas-0002-encoder.bin
        sha256: f49782784647b4d84520d83b1260054ed6d6ce4c3da49e92357f64727a147805
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/driver-action-recognition-adas-0002-encoder/FP32/driver-action-recognition-adas-0002-encoder.bin
      - name: FP16/driver-action-recognition-adas-0002-encoder.xml
        sha256: 198829065524cbe806b13edae7ae89013c1c234b00841c4887ada5372690becc
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/driver-action-recognition-adas-0002-encoder/FP16/driver-action-recognition-adas-0002-encoder.xml
      - name: FP16/driver-action-recognition-adas-0002-encoder.bin
        sha256: cc6619627ded268452836220c8f23d228d674c94349778219ab032e611b6983f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/driver-action-recognition-adas-0002-encoder/FP16/driver-action-recognition-adas-0002-encoder.bin
    output: "Transportation/action_recognition/driver_monitoring/mobilenetv2/encoder/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "emotions-recognition-retail-0003"
    description: >-
      Fully convolutional network for recognition of five emotions ('neutral', 'happy',
      'sad', 'surprise', 'anger').
    task_type: "object_attributes"
    files:
      - name: FP32/emotions-recognition-retail-0003.xml
        sha256: 31e1a6aecce64f57d0c634767b0ea84d830571dd973f3b63d70bdd344d9f879a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/emotions-recognition-retail-0003/FP32/emotions-recognition-retail-0003.xml
      - name: FP32/emotions-recognition-retail-0003.bin
        sha256: bcb9b1a910fa3cd18a638bb1dbb0597c4ef7a080d1b83008c8e8c2c3c42b99dd
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/emotions-recognition-retail-0003/FP32/emotions-recognition-retail-0003.bin
      - name: FP16/emotions-recognition-retail-0003.xml
        sha256: 9c529df09b00cd6d3c038b3db36da8a6804b98164beecb8e726c14cf56b49efc
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/emotions-recognition-retail-0003/FP16/emotions-recognition-retail-0003.xml
      - name: FP16/emotions-recognition-retail-0003.bin
        sha256: e62fb4b819b3b3ad8aafcd308d4353db2f164a1a31d78de6cf5970837aeb6f7b
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/emotions-recognition-retail-0003/FP16/emotions-recognition-retail-0003.bin
      - name: INT8/emotions-recognition-retail-0003.xml
        sha256: e6a17e31dd90c9c8617c54909199875ef1ac25f7b50f810a1940e8c243ad5499
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/emotions-recognition-retail-0003/INT8/emotions-recognition-retail-0003.xml
      - name: INT8/emotions-recognition-retail-0003.bin
        sha256: 61203cb3b7318101637b444c12c9e050cb3447f682c44bc343e8926f9bfe6130
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/emotions-recognition-retail-0003/INT8/emotions-recognition-retail-0003.bin
    output: "Retail/object_attributes/emotions_recognition/0003/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "face-detection-adas-0001"
    description: >-
      Face detector for driver monitoring and similar scenarios. The network features
      a default MobileNet backbone that includes depth-wise convolutions to reduce
      the amount of computation for the 3x3 convolution block.
    task_type: "detection"
    files:
      - name: FP32/face-detection-adas-0001.xml
        sha256: f29f1db2ef2bff608c3623732a785aee31288efcea75e8b67379ffaac038421b
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-adas-0001/FP32/face-detection-adas-0001.xml
      - name: FP32/face-detection-adas-0001.bin
        sha256: 0e8fd765cfac0dc369373d456cad17aab0b6c1534f6de33398f89946aa04c673
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-adas-0001/FP32/face-detection-adas-0001.bin
      - name: FP16/face-detection-adas-0001.xml
        sha256: d066b2dad66f7e526eb00ede41b9015a449e77b95ae740e2d3e0d4c67789dfde
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-adas-0001/FP16/face-detection-adas-0001.xml
      - name: FP16/face-detection-adas-0001.bin
        sha256: e4d1ca072f26173321e580168d6b066eac5123cee136093fca492b2a0cf18cbc
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-adas-0001/FP16/face-detection-adas-0001.bin
      - name: INT8/face-detection-adas-0001.xml
        sha256: c55aab573f63c47e4a176e733b78a52247f634ac366d79abca1b9a4da37147de
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-adas-0001/INT8/face-detection-adas-0001.xml
      - name: INT8/face-detection-adas-0001.bin
        sha256: 69650c48ce9ab68928397eb15f6fd8a41f0f9259098623c962720bbfaeb906a1
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-adas-0001/INT8/face-detection-adas-0001.bin
    output: "Transportation/object_detection/face/pruned_mobilenet_reduced_ssd_shared_weights/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "face-detection-adas-binary-0001"
    description: >-
      Face detector for driver monitoring and similar scenarios. The network features
      a pruned MobileNet backbone that includes depth-wise convolutions to reduce
      the amount of computation for the 3x3 convolution block. Also some 1x1 convolutions
      are binary that can be implemented using effective binary XNOR+POPCOUNT approach
    task_type: "detection"
    files:
      - name: INT1/face-detection-adas-binary-0001.xml
        sha256: fde8c465a5e3f3425fb567d31b9591ff8be589930c8488639f8feddf7f0301f2
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-adas-binary-0001/INT1/face-detection-adas-binary-0001.xml
      - name: INT1/face-detection-adas-binary-0001.bin
        sha256: 0e0742b61fb924e937a8974da8a2e15cc6afc15630afa3f220676ee7a3a99700
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-adas-binary-0001/INT1/face-detection-adas-binary-0001.bin
    output: "Transportation/object_detection/face/pruned_mobilenet_reduced_ssd_shared_weights_binary/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "face-detection-retail-0004"
    description: >-
      Face detector based on SqueezeNet light (half-channels) as a backbone with a
      single SSD for indoor/outdoor scenes shot by a front-facing camera. The backbone
      consists of fire modules to reduce the number of computations. The single SSD
      head from 1/16 scale feature map has nine clustered prior boxes.
    task_type: "detection"
    files:
      - name: FP32/face-detection-retail-0004.xml
        sha256: e7bf0ae0ea0c2552af264c20c4736b1bf7612c549fc096b92eccd9c3d5b6ae13
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0004/FP32/face-detection-retail-0004.xml
      - name: FP32/face-detection-retail-0004.bin
        sha256: a066b383f7b59055326f4facaef34c6669d8cb2cb817f98b8517fa6cebfb6f41
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0004/FP32/face-detection-retail-0004.bin
      - name: FP16/face-detection-retail-0004.xml
        sha256: a77e48e300fd8535c97eae5a3a70e9e0a0abca190551d4b7d57d018da542c37b
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0004/FP16/face-detection-retail-0004.xml
      - name: FP16/face-detection-retail-0004.bin
        sha256: d20f133227037747343eb635c004679cb25f10acf5e823de72888f64d99ff77a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0004/FP16/face-detection-retail-0004.bin
      - name: INT8/face-detection-retail-0004.xml
        sha256: e961e827f8535eea607691382204569214162fa844f3e5ba4380e6ca0e874098
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0004/INT8/face-detection-retail-0004.xml
      - name: INT8/face-detection-retail-0004.bin
        sha256: ea68f90c1b55b70fe0c4e356b5469177a08981c4c71ad27532a1151ee7407430
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0004/INT8/face-detection-retail-0004.bin
    output: "Retail/object_detection/face/sqnet1.0modif-ssd/0004/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "face-detection-retail-0005"
    description: >-
      Face detector based on MobileNetV2 as a backbone with a single SSD head for
      indoor/outdoor scenes shot by a front-facing camera. The single SSD head from
      1/16 scale feature map has nine clustered prior boxes.
    task_type: "detection"
    files:
      - name: FP32/face-detection-retail-0005.xml
        sha256: b78b886449c333592bfa379a11c7420dbc5db929ac12f8a30ceb9cd7ec4808ed
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0005/FP32/face-detection-retail-0005.xml
      - name: FP32/face-detection-retail-0005.bin
        sha256: e5d2d463fe3b11fc99a77fe23d1daaa497309e73eca222be02bed99d0601115b
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0005/FP32/face-detection-retail-0005.bin
      - name: FP16/face-detection-retail-0005.xml
        sha256: f482f356058abc5dc3d62ad9a3cbb8cee2eb2b24969b91a8e3ba44f6329aabb9
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0005/FP16/face-detection-retail-0005.xml
      - name: FP16/face-detection-retail-0005.bin
        sha256: aee37d488af499cd89382ab5632449fce5985660c639217494ae9b64ede7d07e
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0005/FP16/face-detection-retail-0005.bin
      - name: INT8/face-detection-retail-0005.xml
        sha256: 455e1fc46ed8d48973004f04b3452a6c18dcf716475929c07eee265a146094c3
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0005/INT8/face-detection-retail-0005.xml
      - name: INT8/face-detection-retail-0005.bin
        sha256: 27dd6d53eb97198e9e94508802d47b02393c2deef7a2eebab72c1bdf05f26fb4
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-detection-retail-0005/INT8/face-detection-retail-0005.bin
    output: "Retail/object_detection/face/mobilenet_v2/0005/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "face-reidentification-retail-0095"
    description: >-
      This is a lightweight network for the face re-identification scenario. It is
      based on MobileNet V2 backbone, which consists of 3x3 inverted residual blocks
      with squeeze-excitation attention modules. Instead of the ReLU6 activations
      used in the original MobileNet V2, this network uses PReLU ones. After the backbone,
      the network applies global depthwise pooling and then uses 1x1 convolution to
      create the final embedding vector. The model produces feature vectors which
      should be close in cosine distance for similar faces and far for different faces.
    task_type: "face_recognition"
    files:
      - name: FP32/face-reidentification-retail-0095.xml
        sha256: 6a858a781ae26598245bf211fa8478cf7dbb5ab92d08260e351ba8a42584f385
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-reidentification-retail-0095/FP32/face-reidentification-retail-0095.xml
      - name: FP32/face-reidentification-retail-0095.bin
        sha256: 03836a6a1d03828322491b0608a579b1c47e5097d355c489b5b8aaf5fce1ef48
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-reidentification-retail-0095/FP32/face-reidentification-retail-0095.bin
      - name: FP16/face-reidentification-retail-0095.xml
        sha256: 223b9f4d2517b1b519c6bc5af54fafc4d94872444e6d173b3f3f800e8908df3f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-reidentification-retail-0095/FP16/face-reidentification-retail-0095.xml
      - name: FP16/face-reidentification-retail-0095.bin
        sha256: 3289078133e40e4263f682ded2a26a500905abb0fd7b943f41ca8037a4f3fe21
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/face-reidentification-retail-0095/FP16/face-reidentification-retail-0095.bin
    output: "Retail/object_reidentification/face/mobilenet_based/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "facial-landmarks-35-adas-0002"
    description: >-
      This is a custom-architecture convolutional neural network for 35 facial landmarks
      estimation.
    task_type: "object_attributes"
    files:
      - name: FP32/facial-landmarks-35-adas-0002.xml
        sha256: cbeec1382711cea61f94b8c8c8e1e5acc29d0d06d1efb6e9d4f4b73cbf56d6f0
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/facial-landmarks-35-adas-0002/FP32/facial-landmarks-35-adas-0002.xml
      - name: FP32/facial-landmarks-35-adas-0002.bin
        sha256: 232b1a25de480227f36428fdb11a7a1f623acf37eb4232ced5fabac9b7dd2ad7
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/facial-landmarks-35-adas-0002/FP32/facial-landmarks-35-adas-0002.bin
      - name: FP16/facial-landmarks-35-adas-0002.xml
        sha256: 1d3f3b4c2fec2a75a3712e8bca1ef7cda6d2bc6d3ebb4fbfa5883421fe5aac10
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/facial-landmarks-35-adas-0002/FP16/facial-landmarks-35-adas-0002.xml
      - name: FP16/facial-landmarks-35-adas-0002.bin
        sha256: b8945ba897072289c8cb44357bd211e728ecd1c093c1d4777b79d118a19ab58a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/facial-landmarks-35-adas-0002/FP16/facial-landmarks-35-adas-0002.bin
    output: "Transportation/object_attributes/facial_landmarks/custom-35-facial-landmarks/dldt"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "gaze-estimation-adas-0002"
    description: >-
      This is a custom VGG-like convolutional neural network for gaze direction estimation.
    task_type: "object_attributes"
    files:
      - name: FP32/gaze-estimation-adas-0002.xml
        sha256: 8247065b79c68c6b52712e2dc60c475b61fb4d1a3a48f0f3ebafa91218fff80a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/gaze-estimation-adas-0002/FP32/gaze-estimation-adas-0002.xml
      - name: FP32/gaze-estimation-adas-0002.bin
        sha256: 0c73b93bc4162b61a4abf6f1decc892f769e9c289de86793673dc0a723b84652
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/gaze-estimation-adas-0002/FP32/gaze-estimation-adas-0002.bin
      - name: FP16/gaze-estimation-adas-0002.xml
        sha256: f705966a348adfc288627986cd71a56a943c53d9c87daf45fc1805b8b921c4dd
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/gaze-estimation-adas-0002/FP16/gaze-estimation-adas-0002.xml
      - name: FP16/gaze-estimation-adas-0002.bin
        sha256: 01acb7d0a596f1a691e6f36235fab07b99bcab9d97b9b8fb545ea1d1a27db3b0
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/gaze-estimation-adas-0002/FP16/gaze-estimation-adas-0002.bin
      - name: INT8/gaze-estimation-adas-0002.xml
        sha256: ec90e98c9868737b209534083269f93934856ae4f1f03bd1448e86d70329969e
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/gaze-estimation-adas-0002/INT8/gaze-estimation-adas-0002.xml
      - name: INT8/gaze-estimation-adas-0002.bin
        sha256: ac281130aab7eb4a69a59520a483301b3cfe3d385402bfdec5640941fc1433f7
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/gaze-estimation-adas-0002/INT8/gaze-estimation-adas-0002.bin
    output: "Transportation/object_attributes/gaze/custom-architecture/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "handwritten-score-recognition-0003"
    description: >-
      This is a network for text recognition scenario. It consists of VGG16-like backbone
      and bidirectional LSTM encoder-decoder. The network is able to recognize school
      marks that should have format either `<digit>` or `<digit>.<digit>` (e.g. `4`
      or `3.5`).
    task_type: "optical_character_recognition"
    files:
      - name: FP32/handwritten-score-recognition-0003.xml
        sha256: 7ea68e683131b48e6ff5a5a93fcce805feac1af048881befdde310d5e2c05484
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/handwritten-score-recognition-0003/FP32/handwritten-score-recognition-0003.xml
      - name: FP32/handwritten-score-recognition-0003.bin
        sha256: 56dc7bf776b712be477417ec153f34af57f31444d40772f181889544334c67e1
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/handwritten-score-recognition-0003/FP32/handwritten-score-recognition-0003.bin
      - name: FP16/handwritten-score-recognition-0003.xml
        sha256: d01bdc60d4dbb6b4784b5423b30464f6a60eba53be78023df2121663cef5d966
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/handwritten-score-recognition-0003/FP16/handwritten-score-recognition-0003.xml
      - name: FP16/handwritten-score-recognition-0003.bin
        sha256: 4d7d4df0bd8e69fbf9a3d3d34cf2d1e0df1abe201f8d083457cd3ab8f5402d92
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/handwritten-score-recognition-0003/FP16/handwritten-score-recognition-0003.bin
    output: "Retail/handwritten-score-recognition/0003/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "head-pose-estimation-adas-0001"
    description: >-
      Head pose estimation network based on simple, handmade CNN architecture. Angle
      regression layers are convolutions + ReLU + batch norm + fully connected with
      one output.
    task_type: "head_pose_estimation"
    files:
      - name: FP32/head-pose-estimation-adas-0001.xml
        sha256: 4407734b15901641df2ff94005734173abdb910350d60ae498e3e889ac0eb195
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001.xml
      - name: FP32/head-pose-estimation-adas-0001.bin
        sha256: e4047e643bd39d97288dc5d22abe8ead850e05ac1bc44605443bbb2abfc2e246
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001.bin
      - name: FP16/head-pose-estimation-adas-0001.xml
        sha256: 436a6be25690800a4e39efe1b1c21478e0d7a26004a1d070848dc88719b351b0
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.xml
      - name: FP16/head-pose-estimation-adas-0001.bin
        sha256: 535a6af806999e22cca5e4071e55841a694a6b60370a6f8fb3b9d0cda5f81c41
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/head-pose-estimation-adas-0001/FP16/head-pose-estimation-adas-0001.bin
      - name: INT8/head-pose-estimation-adas-0001.xml
        sha256: 13f5a6967b29c7e24476450b8b1660ac1e8ad8fe680aa33ecd2a458b50b81242
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/head-pose-estimation-adas-0001/INT8/head-pose-estimation-adas-0001.xml
      - name: INT8/head-pose-estimation-adas-0001.bin
        sha256: abc0fb7f08e782301c4ffccf9fc5ce626e608a1e7f9c179baf6513519fa38416
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/head-pose-estimation-adas-0001/INT8/head-pose-estimation-adas-0001.bin
    output: "Transportation/object_attributes/headpose/vanilla_cnn/dldt"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "human-pose-estimation-0001"
    description: >-
      This is a multi-person 2D pose estimation network (based on the OpenPose approach)
      with tuned MobileNet v1 as a feature extractor. It finds a human pose: body
      skeleton, which consists of keypoints and connections between them, for every
      person inside image. The pose may contain up to 18 keypoints: ears, eyes, nose,
      neck, shoulders, elbows, wrists, hips, knees and ankles.
    task_type: "human_pose_estimation"
    files:
      - name: FP32/human-pose-estimation-0001.xml
        sha256: 539eb9ea4f5d1336adcea499198f9c0b4e9af1dbdf8ca4cb4a527090afb54da8
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/human-pose-estimation-0001/FP32/human-pose-estimation-0001.xml
      - name: FP32/human-pose-estimation-0001.bin
        sha256: 9790da47abf072c509ff843695a7b9b96283729731ba4d711fb50201f376b2fc
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/human-pose-estimation-0001/FP32/human-pose-estimation-0001.bin
      - name: FP16/human-pose-estimation-0001.xml
        sha256: e45ca9d35396d2a5af74b2d45d7ed8423f7595096f50064ac251ac05fc08cf74
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/human-pose-estimation-0001/FP16/human-pose-estimation-0001.xml
      - name: FP16/human-pose-estimation-0001.bin
        sha256: 48c607a55b22b540c38b6ed295eba211aaa6cd4acd47776f0a1259829cb51196
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/human-pose-estimation-0001/FP16/human-pose-estimation-0001.bin
      - name: INT8/human-pose-estimation-0001.xml
        sha256: 763c8a9a4fdc35506b7fe02c844dac1af0286aa5843c093845e832af1fd4d5e7
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/human-pose-estimation-0001/INT8/human-pose-estimation-0001.xml
      - name: INT8/human-pose-estimation-0001.bin
        sha256: 0d252f0fd98c598fb38eaa907fa8b3d15cf2d420d743649b4b6c5dbdbbe5f1ac
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/human-pose-estimation-0001/INT8/human-pose-estimation-0001.bin
    output: "Transportation/human_pose_estimation/mobilenet-v1/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "inceptionv3-int8-sparse-v1-tf-0001"
    description: >-
      This is the Inception v3 model that is designed to perform image classification.
      The model has been pretrained on the ImageNet image database and then pruned
      to **30.9%** of sparsity and quantized to INT8 fixed-point precision using
      so-called Quantization-aware training approach implemented in TensorFlow framework.
      The sparsity is represented by zeros inside the weights of Convolutional and
      Fully-conneted layers. For details about the original floating point model,
      check out the paper <https://arxiv.org/pdf/1512.03385.pdf>.

      The model input is a blob that consists of a single image of "1x299x299x3"
      in BGR order.

      The model output for `inceptionv3-int8-sparse-v1-tf-0001` is the usual object
      classifier output for the 1001 different classifications matching those in
      the ImageNet database (the first item represents the background).
    task_type: "classification"
    files:
      - name: FP32/inceptionv3-int8-sparse-v1-tf-0001.xml
        sha256: a9188b81eb814cfadfe233792129fcdc2d0ecfec7612d4fe37ba735332152b91
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-sparse-v1-tf-0001/FP32/inceptionv3-int8-sparse-v1-tf-0001.xml
      - name: FP32/inceptionv3-int8-sparse-v1-tf-0001.bin
        sha256: 9e370db96022b379bc3d10bfa7f52290702c230108a0f3e798b3aad36b8da99f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-sparse-v1-tf-0001/FP32/inceptionv3-int8-sparse-v1-tf-0001.bin
      - name: FP16/inceptionv3-int8-sparse-v1-tf-0001.xml
        sha256: 4e4531b08fc335188910b020536d8da50886e5ee35856d807cf5770bb29f812d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-sparse-v1-tf-0001/FP16/inceptionv3-int8-sparse-v1-tf-0001.xml
      - name: FP16/inceptionv3-int8-sparse-v1-tf-0001.bin
        sha256: a671e7b4eb18ea926861e01272af28d2d14a7738aa95fcbd53115682c1a9e290
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-sparse-v1-tf-0001/FP16/inceptionv3-int8-sparse-v1-tf-0001.bin
    output: "PublicCompressed/classification/inceptionv3-dldt/INT8_sparse_v1/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "inceptionv3-int8-sparse-v2-tf-0001"
    description: >-
      This is the Inception v3 model that is designed to perform image classification.
      The model has been pretrained on the ImageNet image database and then pruned
      to **59.9%** of sparsity and quantized to INT8 fixed-point precision using
      so-called Quantization-aware training approach implemented in TensorFlow framework.
      The sparsity is represented by zeros inside the weights of Convolutional and
      Fully-conneted layers. For details about the original floating point model,
      check out the paper <https://arxiv.org/pdf/1512.03385.pdf>.

      The model input is a blob that consists of a single image of "1x299x299x3"
      in BGR order.

      The model output for `inceptionv3-int8-sparse-v2-tf-0001` is the usual object
      classifier output for the 1001 different classifications matching those in
      the ImageNet database (the first item represents the background).
    task_type: "classification"
    files:
      - name: FP32/inceptionv3-int8-sparse-v2-tf-0001.xml
        sha256: bccb7f1820ce88cbb560885af9a577b586aecf7c799901d8ffe70845069fbf8c
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-sparse-v2-tf-0001/FP32/inceptionv3-int8-sparse-v2-tf-0001.xml
      - name: FP32/inceptionv3-int8-sparse-v2-tf-0001.bin
        sha256: 2c7faf42a761c343815621fde4d2b79ec316f87ffefb2f4105b59ea915806279
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-sparse-v2-tf-0001/FP32/inceptionv3-int8-sparse-v2-tf-0001.bin
      - name: FP16/inceptionv3-int8-sparse-v2-tf-0001.xml
        sha256: 0f09ce6087bf36e2c5d3ba06587ce2a43dd362e89ac699670a33abaa3aae29e3
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-sparse-v2-tf-0001/FP16/inceptionv3-int8-sparse-v2-tf-0001.xml
      - name: FP16/inceptionv3-int8-sparse-v2-tf-0001.bin
        sha256: 865a63e70da08213d5181842d080cb356417bbe19285ddb4ecb4e1f595902c6a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-sparse-v2-tf-0001/FP16/inceptionv3-int8-sparse-v2-tf-0001.bin
    output: "PublicCompressed/classification/inceptionv3-dldt/INT8_sparse_v2/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "inceptionv3-int8-tf-0001"
    description: >-
      This is the Inception v3 model that is designed to perform image classification.
      The model has been pretrained on the ImageNet image database and then quantized
      to INT8 fixed-point precision using so-called Quantization-aware training
      approach implemented in TensorFlow framework. For details about the original
      floating point model, check out the paper <https://arxiv.org/pdf/1512.03385.pdf>.

      The model input is a blob that consists of a single image of "1x299x299x3"
      in BGR order.

      The model output for `inceptionv3-int8-tf-0001` is the usual object classifier
      output for the 1001 different classifications matching those in the ImageNet
      database (the first item represents the background).
    task_type: "classification"
    files:
      - name: FP32/inceptionv3-int8-tf-0001.xml
        sha256: 5df7f99641007d61ef12f6cffb1ab00d17e00abe1ca7059315a4d06f389db296
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-tf-0001/FP32/inceptionv3-int8-tf-0001.xml
      - name: FP32/inceptionv3-int8-tf-0001.bin
        sha256: db5aa42bd86e072235b1fc1b822d8b53f2f9f6710fbb8a18c8047158afef26f8
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-tf-0001/FP32/inceptionv3-int8-tf-0001.bin
      - name: FP16/inceptionv3-int8-tf-0001.xml
        sha256: d798e6e35c16efe5cfe220bb02f3ec79d107f67f77ded99f713c44d215ec1f20
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-tf-0001/FP16/inceptionv3-int8-tf-0001.xml
      - name: FP16/inceptionv3-int8-tf-0001.bin
        sha256: 2321c645c5a633d4afd8dff3d7ce358a7654c3c579afd1a3a0e07d6b8f87f328
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/inceptionv3-int8-tf-0001/FP16/inceptionv3-int8-tf-0001.bin
    output: "PublicCompressed/classification/inceptionv3-dldt/INT8/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "instance-segmentation-security-0010"
    description: >-
      This model is an instance segmentation network for 80 classes of objects.
      It is a Mask R-CNN with ResNeXt101-32x8 backbone, PANet feature refiner with
      GroupNorm and DeformableConv operations and Adaptive Feature Pooling in all
      ROI-wise heads.
    task_type: "instance_segmentation"
    files:
      - name: FP32/instance-segmentation-security-0010.xml
        sha256: 1824cfe7005b6523d488696a701ec6e55512c8eac2386c80dafc3e624ac0fecd
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0010/FP32/instance-segmentation-security-0010.xml
      - name: FP32/instance-segmentation-security-0010.bin
        sha256: 1c4d3791f5c28cdb0e716ee02bf8ff41f61d45e6d3b8692c97a6540aa2bc5437
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0010/FP32/instance-segmentation-security-0010.bin
      - name: FP16/instance-segmentation-security-0010.xml
        sha256: 9edd060c56cc9afd243bf2799ba5dd73b0a56232e437f6b940ec04a355093e23
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0010/FP16/instance-segmentation-security-0010.xml
      - name: FP16/instance-segmentation-security-0010.bin
        sha256: 7aeb02fbe551607be9abb32a24e57c703bf992ee89138ce1b73644b56a3c7adb
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0010/FP16/instance-segmentation-security-0010.bin
    output: "Security/instance_segmentation/common/0010/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "instance-segmentation-security-0050"
    description: >-
      This model is an instance segmentation network for 80 classes of objects.
      It is a Mask R-CNN with ResNet50 backbone, FPN and Bottom-Up Augmentation
      blocks and light-weight RPN.
    task_type: "instance_segmentation"
    files:
      - name: FP32/instance-segmentation-security-0050.xml
        sha256: 94d6a0543eaa8ab5255cbf42e78d4fb2841c376fd3f79b8edcb6c5f2aa718b14
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0050/FP32/instance-segmentation-security-0050.xml
      - name: FP32/instance-segmentation-security-0050.bin
        sha256: c923af7602592a17375e4dd7ba5b0869dc47022bd50d2558f58b1cca2ed6cfc9
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0050/FP32/instance-segmentation-security-0050.bin
      - name: FP16/instance-segmentation-security-0050.xml
        sha256: 4b8d567303e09af942274ce6ebb3b1606292cb91af6c1a9c6f93f3ee81003f6c
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0050/FP16/instance-segmentation-security-0050.xml
      - name: FP16/instance-segmentation-security-0050.bin
        sha256: 743058892ecaac32a6d789bfa177e11d335bd9b12257367b2ceed1304bf96cda
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0050/FP16/instance-segmentation-security-0050.bin
    output: "Security/instance_segmentation/common/0050/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "instance-segmentation-security-0083"
    description: >-
      This model is an instance segmentation network for 80 classes of objects.
      It is a Mask R-CNN model with ResNeXt152 backbone and Feature Pyramid Networks
      block for feature maps refinement.
    task_type: "instance_segmentation"
    files:
      - name: FP32/instance-segmentation-security-0083.xml
        sha256: 63a93786c3b45598165e5f7a226ed7ad67601a51e1d35d7dfd88302e4a78095a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0083/FP32/instance-segmentation-security-0083.xml
      - name: FP32/instance-segmentation-security-0083.bin
        sha256: 3226bf893e9877749c723532164952416dab5b812e825ad533c44285207a2f23
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0083/FP32/instance-segmentation-security-0083.bin
      - name: FP16/instance-segmentation-security-0083.xml
        sha256: c1a6fc6dce895252b7341933061db188a40773b101ecfd7c9d274042368e91a2
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0083/FP16/instance-segmentation-security-0083.xml
      - name: FP16/instance-segmentation-security-0083.bin
        sha256: 885f156f0947d873024dcdce51b1c5e59b60dd34d26b5bcc98da39b2267cca8b
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/instance-segmentation-security-0083/FP16/instance-segmentation-security-0083.bin
    output: "Security/instance_segmentation/common/0083/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "landmarks-regression-retail-0009"
    description: >-
      This is a lightweight landmarks regressor for the Smart Classroom scenario.
      It has a classic convolutional design: stacked 3x3 convolutions, batch normalizations,
      PReLU activations, and poolings. Final regression is done by the global depthwise
      pooling head and FullyConnected layers. The model predicts five facial landmarks:
      two eyes, nose, and two lip corners.
    task_type: "object_attributes"
    files:
      - name: FP32/landmarks-regression-retail-0009.xml
        sha256: d12e17ea039d75ff2cbd6dde58ffd46998dc1e6761e3d5ebbf094df0b58ce56c
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/landmarks-regression-retail-0009/FP32/landmarks-regression-retail-0009.xml
      - name: FP32/landmarks-regression-retail-0009.bin
        sha256: 46795837d35e8199b7c5b57e1f76297827bf516a150c0d5643197d8c325f1dbc
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/landmarks-regression-retail-0009/FP32/landmarks-regression-retail-0009.bin
      - name: FP16/landmarks-regression-retail-0009.xml
        sha256: fa0000165ce9b35b0c6e08e07d7cdfd12c68fcf043a07a1f8c8f3c0545f0a0e5
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/landmarks-regression-retail-0009/FP16/landmarks-regression-retail-0009.xml
      - name: FP16/landmarks-regression-retail-0009.bin
        sha256: 5d74c26cbb836b3de358ab05d4cbd92c4eb713dc74484cff9de82b2deb3d8527
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/landmarks-regression-retail-0009/FP16/landmarks-regression-retail-0009.bin
    output: "Retail/object_attributes/landmarks_regression/0009/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "license-plate-recognition-barrier-0001"
    description: >-
      This model uses a small-footprint network trained end-to-end to recognize Chinese
      license plates in traffic.
    task_type: "optical_character_recognition"
    files:
      - name: FP32/license-plate-recognition-barrier-0001.xml
        sha256: bda8905e09a79c3aa7b06cd65e9b48d9b92c534a344b65e6a2100b5b44a9bf05
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/license-plate-recognition-barrier-0001/FP32/license-plate-recognition-barrier-0001.xml
      - name: FP32/license-plate-recognition-barrier-0001.bin
        sha256: e28f7533481c31ee768bba89c6ee0ef05a1892c9919bd4abc125335a8644291d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/license-plate-recognition-barrier-0001/FP32/license-plate-recognition-barrier-0001.bin
      - name: FP16/license-plate-recognition-barrier-0001.xml
        sha256: a68cfb5a7d81d2896db97bbc06576b5b0df2e955ba770df96506eeefe505e722
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/license-plate-recognition-barrier-0001/FP16/license-plate-recognition-barrier-0001.xml
      - name: FP16/license-plate-recognition-barrier-0001.bin
        sha256: cdead95dde2f27f85a192360343998ca6f0fac160a1aecdf7ecbda06eafc883f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/license-plate-recognition-barrier-0001/FP16/license-plate-recognition-barrier-0001.bin
      - name: INT8/license-plate-recognition-barrier-0001.xml
        sha256: c61e8998ef2c0ad16fe5c6e50b692c4663d7fb067b9bc7179bdbfca4cc954832
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/license-plate-recognition-barrier-0001/INT8/license-plate-recognition-barrier-0001.xml
      - name: INT8/license-plate-recognition-barrier-0001.bin
        sha256: 26f1211824ebfcef1db799b865aa31bb91aba9e1ebcc58b4817c775a3e7f7ea5
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/license-plate-recognition-barrier-0001/INT8/license-plate-recognition-barrier-0001.bin
    output: "Security/optical_character_recognition/license_plate/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "mobilenetv2-int8-sparse-v1-tf-0001"
    description: >-
      Mobilenet v2 INT8 quantized and pruned to 30.8% weights sparsity rate in TensorFlow.
      Acc@top-1 on ImageNet is 71.42.
    task_type: "classification"
    files:
      - name: FP32/mobilenetv2-int8-sparse-v1-tf-0001.xml
        sha256: 33b32b0c768b9ea5dae2c83d3220e523523a600f806de63b827efd591818ce53
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-sparse-v1-tf-0001/FP32/mobilenetv2-int8-sparse-v1-tf-0001.xml
      - name: FP32/mobilenetv2-int8-sparse-v1-tf-0001.bin
        sha256: 6ae4be4a4672f44fbdf7286b6d15a6bc2c21dacd5f257e39f8121c0d109d2f86
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-sparse-v1-tf-0001/FP32/mobilenetv2-int8-sparse-v1-tf-0001.bin
      - name: FP16/mobilenetv2-int8-sparse-v1-tf-0001.xml
        sha256: 1d93e9cd523f7b8b33ff9c118ffb2acca753fd3c68ab7dbb114aed2ff22de3a0
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-sparse-v1-tf-0001/FP16/mobilenetv2-int8-sparse-v1-tf-0001.xml
      - name: FP16/mobilenetv2-int8-sparse-v1-tf-0001.bin
        sha256: eec27b598e2d94e1157a2939b8dc67b32e61c75fa4debf6a421df77013299d09
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-sparse-v1-tf-0001/FP16/mobilenetv2-int8-sparse-v1-tf-0001.bin
    output: "PublicCompressed/classification/mobilenetv2-dldt/INT8_sparse_v1/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "mobilenetv2-int8-sparse-v2-tf-0001"
    description: >-
      Mobilenet v2 INT8 quantized and pruned to 53.01% weights sparsity rate in TensorFlow.
      Acc@top-1 on ImageNet is 70.856.
    task_type: "classification"
    files:
      - name: FP32/mobilenetv2-int8-sparse-v2-tf-0001.xml
        sha256: 484058458c8efaa061cfed8d373fa6194a17f4a74385528680b046bfdb0a872d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-sparse-v2-tf-0001/FP32/mobilenetv2-int8-sparse-v2-tf-0001.xml
      - name: FP32/mobilenetv2-int8-sparse-v2-tf-0001.bin
        sha256: 344db57e36e27befffde4e372c59b5f650c96e6bda6e2488d28dfaffc4984ee7
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-sparse-v2-tf-0001/FP32/mobilenetv2-int8-sparse-v2-tf-0001.bin
      - name: FP16/mobilenetv2-int8-sparse-v2-tf-0001.xml
        sha256: 76819b86b945291425697884b2acc6ceb0c49bb4b3925d81dc747c7173f363ad
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-sparse-v2-tf-0001/FP16/mobilenetv2-int8-sparse-v2-tf-0001.xml
      - name: FP16/mobilenetv2-int8-sparse-v2-tf-0001.bin
        sha256: 7402ebe219256139d218b1b2eec7fd4b9fcfad393064ee50234c0d3f725a97eb
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-sparse-v2-tf-0001/FP16/mobilenetv2-int8-sparse-v2-tf-0001.bin
    output: "PublicCompressed/classification/mobilenetv2-dldt/INT8_sparse_v2/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "mobilenetv2-int8-tf-0001"
    description: >-
      MobileNet v2 INT8 quantized in TensorFlow. Acc@Top-1 on ImageNet is 70.8.
    task_type: "classification"
    files:
      - name: FP32/mobilenetv2-int8-tf-0001.xml
        sha256: d8467de9fdacc46a4513e715d2e37e4e7f5ee4aef332e4241dd60e5deefa7967
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-tf-0001/FP32/mobilenetv2-int8-tf-0001.xml
      - name: FP32/mobilenetv2-int8-tf-0001.bin
        sha256: a659b393c3f8f9a00855198a90471a5b8a0b00c67c683e814014033c76a33139
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-tf-0001/FP32/mobilenetv2-int8-tf-0001.bin
      - name: FP16/mobilenetv2-int8-tf-0001.xml
        sha256: 341a0ef4b36ffce2dbda3c85ff0bcc20ab673447dcbad11d19a12c84d88cb5db
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-tf-0001/FP16/mobilenetv2-int8-tf-0001.xml
      - name: FP16/mobilenetv2-int8-tf-0001.bin
        sha256: 4c8fe0c18392971949d396e82ed02b3c520f12ee242eda3aabff282164edadcf
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/mobilenetv2-int8-tf-0001/FP16/mobilenetv2-int8-tf-0001.bin
    output: "PublicCompressed/classification/mobilenetv2-dldt/INT8/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "pedestrian-and-vehicle-detector-adas-0001"
    description: >-
      Pedestrian and vehicle detection network based on MobileNet v1.0 + SSD.
    task_type: "detection"
    files:
      - name: FP32/pedestrian-and-vehicle-detector-adas-0001.xml
        sha256: d3aed35e321ca91ad861f0457cd4a8cefe90c44253ee60d028de7fad6a08ae27
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-and-vehicle-detector-adas-0001/FP32/pedestrian-and-vehicle-detector-adas-0001.xml
      - name: FP32/pedestrian-and-vehicle-detector-adas-0001.bin
        sha256: 7ce62bc9708c2407b60269c968b5b0a3167aec47c4070e87634657134aa1aaf8
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-and-vehicle-detector-adas-0001/FP32/pedestrian-and-vehicle-detector-adas-0001.bin
      - name: FP16/pedestrian-and-vehicle-detector-adas-0001.xml
        sha256: 63ad64cbe580a57fa2db8e69729f9fa93dfe6c4beb4bbfef4916b2dea9d9c458
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-and-vehicle-detector-adas-0001/FP16/pedestrian-and-vehicle-detector-adas-0001.xml
      - name: FP16/pedestrian-and-vehicle-detector-adas-0001.bin
        sha256: d5b2a74485313299515400f0de6b116a6cb5c776098a1f36bddf942f6fba2087
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-and-vehicle-detector-adas-0001/FP16/pedestrian-and-vehicle-detector-adas-0001.bin
    output: "Transportation/object_detection/pedestrian-and-vehicle/mobilenet-reduced-ssd/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "pedestrian-detection-adas-0002"
    description: >-
      Pedestrian detection network based on SSD framework with tuned MobileNet v1
      as a feature extractor.
    task_type: "detection"
    files:
      - name: FP32/pedestrian-detection-adas-0002.xml
        sha256: 6e72ac8a5c16769587bd17bc27804a4914fe16c72e6b5f4a8f27772030adb1e0
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-detection-adas-0002/FP32/pedestrian-detection-adas-0002.xml
      - name: FP32/pedestrian-detection-adas-0002.bin
        sha256: d4b8cad14ad4e85cb88aca6ab3f55be4214c0fd04cd036b631f9b365eb287377
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-detection-adas-0002/FP32/pedestrian-detection-adas-0002.bin
      - name: FP16/pedestrian-detection-adas-0002.xml
        sha256: 80d4ab15050239685351b49506a15071b3066c23bdbbcbc7b6fc2230c8834d46
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-detection-adas-0002/FP16/pedestrian-detection-adas-0002.xml
      - name: FP16/pedestrian-detection-adas-0002.bin
        sha256: 6f5c036879005f87e2ddaf09d7c48988fc142e6c72182b2abc3d09b275f4597d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-detection-adas-0002/FP16/pedestrian-detection-adas-0002.bin
      - name: INT8/pedestrian-detection-adas-0002.xml
        sha256: 6585f16fa7401b8eccd839ecca85b8acabab3f01793d85c31daa19401dac9b98
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-detection-adas-0002/INT8/pedestrian-detection-adas-0002.xml
      - name: INT8/pedestrian-detection-adas-0002.bin
        sha256: 929d7dba718a5e51745a0d6f331fc96013573ced80c72ff4b5125c32e51c4ce6
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-detection-adas-0002/INT8/pedestrian-detection-adas-0002.bin
    output: "Transportation/object_detection/pedestrian/mobilenet-reduced-ssd/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "pedestrian-detection-adas-binary-0001"
    description: >-
      Pedestrian detection network based on SSD framework with tuned MobileNet v1
      as a feature extractor. Some layers of MobileNet v1 are binary and use I1 arithm
    task_type: "detection"
    files:
      - name: INT1/pedestrian-detection-adas-binary-0001.xml
        sha256: e64e7ce32c87e1c698b50abb8f2cf1d96c7651d45fc20bac09c417e046afa7f4
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-detection-adas-binary-0001/INT1/pedestrian-detection-adas-binary-0001.xml
      - name: INT1/pedestrian-detection-adas-binary-0001.bin
        sha256: 7c2761ca3859ef55a80d9ed924225df7ba363fcb151e4ec2f7d1061b70bdb374
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/pedestrian-detection-adas-binary-0001/INT1/pedestrian-detection-adas-binary-0001.bin
    output: "Transportation/object_detection/pedestrian/mobilenet-reduced-ssd-binary/dldt"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-attributes-recognition-crossroad-0230"
    description: >-
      This model presents a person attributes classification algorithm analysis scenario.
      It produces probability of person attributions existing on the sample and a
      position of two point on sample, whiches can be used for color prob (like, color
      picker in graphical editors)
    task_type: "object_attributes"
    files:
      - name: FP32/person-attributes-recognition-crossroad-0230.xml
        sha256: 1405818700375229aa006508b75f243ade4934bb456badb77b87d94a8eee630b
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-attributes-recognition-crossroad-0230/FP32/person-attributes-recognition-crossroad-0230.xml
      - name: FP32/person-attributes-recognition-crossroad-0230.bin
        sha256: 1d1c392826e77373d87fd1d7c65ce238c615f729e5524f1dfbc07a3a6c0cf8db
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-attributes-recognition-crossroad-0230/FP32/person-attributes-recognition-crossroad-0230.bin
      - name: FP16/person-attributes-recognition-crossroad-0230.xml
        sha256: fc7d229c63da3bec1e590d746f184445dbcc3d2f95b2512f497a0a928fcbe837
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-attributes-recognition-crossroad-0230/FP16/person-attributes-recognition-crossroad-0230.xml
      - name: FP16/person-attributes-recognition-crossroad-0230.bin
        sha256: 033c56ba8e93c03604e78b99f9b7e5ab07fa57cfd1d865cb62fc001744fc6e72
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-attributes-recognition-crossroad-0230/FP16/person-attributes-recognition-crossroad-0230.bin
    output: "Security/object_attributes/pedestrian/person-attributes-recognition-crossroad-0230/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-detection-action-recognition-0005"
    description: >-
      This is an action detector for the Smart Classroom scenario. It is based on
      the RMNet backbone that includes depth-wise convolutions to reduce the amount
      of computations for the 3x3 convolution block. The first SSD head from 1/16
      scale feature map has four clustered prior boxes and outputs detected persons
      (two class detector). The second SSD-based head predicts actions of the detected
      persons. Possible actions: sitting, standing, raising hand.
    task_type: "detection"
    files:
      - name: FP32/person-detection-action-recognition-0005.xml
        sha256: fafac8c503d5dd8216b7a55c797d85ab1e37e72f7d20b4573049097abd094dd1
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0005/FP32/person-detection-action-recognition-0005.xml
      - name: FP32/person-detection-action-recognition-0005.bin
        sha256: b68ab79b18b570569024665ec9a72e1c15568c5721d243e0e74f0423560361db
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0005/FP32/person-detection-action-recognition-0005.bin
      - name: FP16/person-detection-action-recognition-0005.xml
        sha256: b9c879858c2c1308d82bd3038705cff9290d7757ae72fcdff5be6e8701514d2c
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0005/FP16/person-detection-action-recognition-0005.xml
      - name: FP16/person-detection-action-recognition-0005.bin
        sha256: 72263b506b29f7d41eadd33386d67faebea19b35cf799ae876a807d35160da8f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0005/FP16/person-detection-action-recognition-0005.bin
      - name: INT8/person-detection-action-recognition-0005.xml
        sha256: 27ca878ed286ab655a681a1ec32f8b930fedcae59395f6fd3defddc8bcfb4fea
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0005/INT8/person-detection-action-recognition-0005.xml
      - name: INT8/person-detection-action-recognition-0005.bin
        sha256: f154273ce9138d2314f68e24a2319fd1add8e9099bd3f8163e939b7d09e73df6
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0005/INT8/person-detection-action-recognition-0005.bin
    output: "Retail/action_detection/pedestrian/rmnet_ssd/0165/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-detection-action-recognition-0006"
    description: >-
      Person Detection and Action Recognition model on TF
    task_type: "detection"
    files:
      - name: FP32/person-detection-action-recognition-0006.xml
        sha256: ed9fc552dd3180e5aab5706a13cc76c0e957ad0958f87b8a50df90b46538083c
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0006/FP32/person-detection-action-recognition-0006.xml
      - name: FP32/person-detection-action-recognition-0006.bin
        sha256: 8d643910cd1e670f1832d989b7af1d90d14c44a665fb7fd3c6c5bdcb61a36517
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0006/FP32/person-detection-action-recognition-0006.bin
      - name: FP16/person-detection-action-recognition-0006.xml
        sha256: b45bd21653fc25dca0b9872cde7f23e2f68006e718dc3225dbfbea5bb9c9e1a5
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0006/FP16/person-detection-action-recognition-0006.xml
      - name: FP16/person-detection-action-recognition-0006.bin
        sha256: 1db6fef93efe3214720ce8d05ad52cd0f24c92c5c49fa72ebe6c32debb2e798f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0006/FP16/person-detection-action-recognition-0006.bin
      - name: INT8/person-detection-action-recognition-0006.xml
        sha256: 8d007b657e8ff78ca5646fe2a765aa5f9012cf8d6b468d0c193ea4a2e45da3b1
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0006/INT8/person-detection-action-recognition-0006.xml
      - name: INT8/person-detection-action-recognition-0006.bin
        sha256: baa89392295213d85af91f271db6ca959d81df0a1352c5475f0a628621d6ce4b
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-0006/INT8/person-detection-action-recognition-0006.bin
    output: "Retail/action_detection/pedestrian/rmnet_ssd/0028_tf/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-detection-action-recognition-teacher-0002"
    description: >-
      This is an action detector for the Smart Classroom scenario. It is based on
      the RMNet backbone that includes depth-wise convolutions to reduce the amount
      of computations for the 3x3 convolution block. The first SSD head from 1/16
      scale feature map has four clustered prior boxes and outputs detected persons
      (two class detector). The second SSD-based head predicts actions of the detected
      persons. Possible actions: standing, writing, demonstrating.
    task_type: "detection"
    files:
      - name: FP32/person-detection-action-recognition-teacher-0002.xml
        sha256: 9ea17d029b2ac665e7b1d167ddec6f87a0b7f5d055e23d0a1a241ea92e907806
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-teacher-0002/FP32/person-detection-action-recognition-teacher-0002.xml
      - name: FP32/person-detection-action-recognition-teacher-0002.bin
        sha256: 711ab8b5737f72d6087c86c017e97d8ebc6e29795b5c63c7665f1e1c37909347
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-teacher-0002/FP32/person-detection-action-recognition-teacher-0002.bin
      - name: FP16/person-detection-action-recognition-teacher-0002.xml
        sha256: 805a7b99e423fe8083398f6261c960c7dda619d2b91cfea7c4f620ce67700c84
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-teacher-0002/FP16/person-detection-action-recognition-teacher-0002.xml
      - name: FP16/person-detection-action-recognition-teacher-0002.bin
        sha256: 9854776b1233e7021deaeb3fc0fe245375b67bd9c5d3e1528d04286b1793e440
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-action-recognition-teacher-0002/FP16/person-detection-action-recognition-teacher-0002.bin
    output: "Retail/action_detection/teacher/rmnet_ssd/0005_cut/dldt"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-detection-raisinghand-recognition-0001"
    description: >-
      This is an action detector for the Smart Classroom scenario. It is based on
      the RMNet backbone that includes depth-wise convolutions to reduce the amount
      of computations for the 3x3 convolution block. The first SSD head from 1/16
      scale feature map has four clustered prior boxes and outputs detected persons
      (two class detector). The second SSD-based head predicts actions of the detected
      persons. Possible actions: raising hand and other.
    task_type: "detection"
    files:
      - name: FP32/person-detection-raisinghand-recognition-0001.xml
        sha256: c4f3b052575eab14f92b04750ad2482f74ac02f48314dd8aaf691e9673aba3be
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-raisinghand-recognition-0001/FP32/person-detection-raisinghand-recognition-0001.xml
      - name: FP32/person-detection-raisinghand-recognition-0001.bin
        sha256: 327aeec1ddc53cc03406ca28c45d4b8b9965030b353142d9cc0c13f229991a61
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-raisinghand-recognition-0001/FP32/person-detection-raisinghand-recognition-0001.bin
      - name: FP16/person-detection-raisinghand-recognition-0001.xml
        sha256: b04db30da4888c66fcb69dc57c4a3891bee0105f3c888ebc628257f29b277a55
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-raisinghand-recognition-0001/FP16/person-detection-raisinghand-recognition-0001.xml
      - name: FP16/person-detection-raisinghand-recognition-0001.bin
        sha256: 58ff7bba9d4f10665dd52aa011fcfe6184cccfbd48f3ecfef79b90033de1e6a5
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-raisinghand-recognition-0001/FP16/person-detection-raisinghand-recognition-0001.bin
    output: "Retail/action_detection/pedestrian/rmnet_ssd/0165_cut_2cl/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-detection-retail-0002"
    description: "Person detection (HyperNet+RFCN+DetectionOutput)."
    task_type: "detection"
    files:
      - name: FP32/person-detection-retail-0002.xml
        sha256: 157f22003cdbd1b6c2ee4368d4a39b589f0a31f32571eda6424a37b42c7a0a03
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-retail-0002/FP32/person-detection-retail-0002.xml
      - name: FP32/person-detection-retail-0002.bin
        sha256: 78f600869517ee2a9ecc79505b5cfab9849c4c4494035041993c97cc7f4fb745
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-retail-0002/FP32/person-detection-retail-0002.bin
      - name: FP16/person-detection-retail-0002.xml
        sha256: f09d1e90bb33706ffacbec9a52ab014438efbef4a38040875c289b18fd30783c
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-retail-0002/FP16/person-detection-retail-0002.xml
      - name: FP16/person-detection-retail-0002.bin
        sha256: 04d28806b41709a01e803a1da0894c17d8033f93e6d38822a732f2ba2fe6ea1c
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-retail-0002/FP16/person-detection-retail-0002.bin
    output: "Retail/object_detection/pedestrian/hypernet-rfcn/0026/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-detection-retail-0013"
    description: >-
      This is a pedestrian detector for the Retail scenario. It is based on MobileNetV2-like
      backbone that includes depth-wise convolutions to reduce the amount of computation
      for the 3x3 convolution block. The single SSD head from 1/16 scale feature map
      has 12 clustered prior boxes.
    task_type: "detection"
    files:
      - name: FP32/person-detection-retail-0013.xml
        sha256: 49cb6a4e0221fc7c32c15f7e35e4d7b7f0c5a8958809872ddfa1085eaf38a77d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-retail-0013/FP32/person-detection-retail-0013.xml
      - name: FP32/person-detection-retail-0013.bin
        sha256: c870150640a9ed9e6ab7e3d93398d4ca7604d7b97569b77ee7494649271bbc83
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-retail-0013/FP32/person-detection-retail-0013.bin
      - name: FP16/person-detection-retail-0013.xml
        sha256: 00c82c835e703f3167ef4b703f1297b146cfcc72ccdc19259e65dcd18c3bcdae
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-retail-0013/FP16/person-detection-retail-0013.xml
      - name: FP16/person-detection-retail-0013.bin
        sha256: 77eb13de84d9368da1d437aece02ba14b4ff0e48b194feb48a8b5076c861039a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-retail-0013/FP16/person-detection-retail-0013.bin
      - name: INT8/person-detection-retail-0013.xml
        sha256: 569e111c0cecc2d7fcb43d3516fd793bbd5c1246cd0532055e58184cbb0cb7b0
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-retail-0013/INT8/person-detection-retail-0013.xml
      - name: INT8/person-detection-retail-0013.bin
        sha256: efdc2566e15bbc1e31990eb0a7a35becacc076e052212ec6f2b7341d0f33cb8e
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-detection-retail-0013/INT8/person-detection-retail-0013.bin
    output: "Retail/object_detection/pedestrian/rmnet_ssd/0013/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-reidentification-retail-0031"
    description: >-
      This is a person reidentification model for a general scenario. It uses a whole
      body image as an input and outputs an embedding vector to match a pair of images
      by the Cosine distance. The model is based on RMNet backbone that was developed
      for fast inference. A single reidentification head from the 1/16 scale feature
      map outputs the embedding vector of 256 floats.
    task_type: "object_attributes"
    files:
      - name: FP32/person-reidentification-retail-0031.xml
        sha256: d7578559b9188b1df506f1e85ad9cdb23562f4bfc7fc16279cefdb919ebbe54d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0031/FP32/person-reidentification-retail-0031.xml
      - name: FP32/person-reidentification-retail-0031.bin
        sha256: 8b9d349d330909815d2e75b57654c4cd6c27eb37c87d3280dfeaae03d166a4f4
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0031/FP32/person-reidentification-retail-0031.bin
      - name: FP16/person-reidentification-retail-0031.xml
        sha256: 7c6847b695bada6c28afcbda810c12cc65eedfad52ae8cf26c576103262206d6
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0031/FP16/person-reidentification-retail-0031.xml
      - name: FP16/person-reidentification-retail-0031.bin
        sha256: 833c136bcce82bcba6de6289fc21ee24f24d4597e52c41717c2602ee275b2f7d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0031/FP16/person-reidentification-retail-0031.bin
      - name: INT8/person-reidentification-retail-0031.xml
        sha256: b173a43e1bdc09b8dde60ef4fb932feaf3faac8e7f8d5c8e467485ae72d68a2d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0031/INT8/person-reidentification-retail-0031.xml
      - name: INT8/person-reidentification-retail-0031.bin
        sha256: 5533422c49746f6856dca186822a9a15c47b88dffced26401b374ba99e731f57
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0031/INT8/person-reidentification-retail-0031.bin
    output: "Retail/object_reidentification/pedestrian/rmnet_based/0031/dldt"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-reidentification-retail-0076"
    description: >-
      This is a person reidentification model for a general scenario. It uses a whole
      body image as an input and outputs an embedding vector to match a pair of images
      by the Cosine distance. The model is based on RMNet backbone that was developed
      for fast inference. A single reidentification head from the 1/16 scale feature
      map outputs the embedding vector of 256 floats. The model is provided without
      last calibration layer, but can be used in the same way as the original model
      (with insignificant drop in accuracy).
    task_type: "object_attributes"
    files:
      - name: FP32/person-reidentification-retail-0076.xml
        sha256: e83551854e5c04e8ed5be09645ee99be38d69cc68e9bd69c982a8f647697b163
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0076/FP32/person-reidentification-retail-0076.xml
      - name: FP32/person-reidentification-retail-0076.bin
        sha256: acd718a8e6bd0c9e52605ecfe3f5a7ba87280976315bccc94e9302bbe520d898
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0076/FP32/person-reidentification-retail-0076.bin
      - name: FP16/person-reidentification-retail-0076.xml
        sha256: f447f991f54eca6f1277f766fc08893e55cbc70be0d7c81c93b53d08f1b35557
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0076/FP16/person-reidentification-retail-0076.xml
      - name: FP16/person-reidentification-retail-0076.bin
        sha256: c8a127cb2b8ff5f26b1d248de5a07b79c916103ee39bec0825fb990e4b043fd6
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0076/FP16/person-reidentification-retail-0076.bin
      - name: INT8/person-reidentification-retail-0076.xml
        sha256: 7a9e06244dcf8c493e098f1a0457550b446b793e713fe64507b84043b3cea375
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0076/INT8/person-reidentification-retail-0076.xml
      - name: INT8/person-reidentification-retail-0076.bin
        sha256: a9ccbfa75998427553910159459d9d001b0264e02a6ee6c07e24a2a4f2f329cd
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0076/INT8/person-reidentification-retail-0076.bin
    output: "Retail/object_reidentification/pedestrian/rmnet_based/0076/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-reidentification-retail-0079"
    description: >-
      This is a person reidentification model for a general scenario. It uses a whole
      body image as an input and outputs an embedding vector to match a pair of images
      by the Cosine distance. The model is based on RMNet backbone that was developed
      for fast inference. A single reidentification head from the 1/16 scale feature
      map outputs the embedding vector of 256 floats. The model is provided without
      last calibration layer, but can be used in the same way as the original model
      (with insignificant drop in accuracy).
    task_type: "object_attributes"
    files:
      - name: FP32/person-reidentification-retail-0079.xml
        sha256: 457037391be4449ecde20e4c8fd103c548add2ac5141f72c0a1ec91719e50868
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0079/FP32/person-reidentification-retail-0079.xml
      - name: FP32/person-reidentification-retail-0079.bin
        sha256: e341d80b568d939dc121d2c4785d1f8bc90df477cd1754d0b286b2e24b7b33e4
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0079/FP32/person-reidentification-retail-0079.bin
      - name: FP16/person-reidentification-retail-0079.xml
        sha256: 745e1f430ff577803e49ac9dcf94b669bffdf71b8ab859896d01c85fbd448c76
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0079/FP16/person-reidentification-retail-0079.xml
      - name: FP16/person-reidentification-retail-0079.bin
        sha256: 95c426b1d7e8f06f417172f5b1058bd906c769c8c10b3846f8b3adc826390d93
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0079/FP16/person-reidentification-retail-0079.bin
      - name: INT8/person-reidentification-retail-0079.xml
        sha256: 9383a991882eda2907506bca887b0bb70fd41fb01d34a5d79cbcfd10d4b672eb
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0079/INT8/person-reidentification-retail-0079.xml
      - name: INT8/person-reidentification-retail-0079.bin
        sha256: ebbf0d88705e371e0f7f3abea5c889958da1e87c265a605a33d6e155d46f3658
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-reidentification-retail-0079/INT8/person-reidentification-retail-0079.bin
    output: "Retail/object_reidentification/pedestrian/rmnet_based/0079/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-vehicle-bike-detection-crossroad-0078"
    description: >-
      Person/Vehicle/Bike detector is based on SSD detection architecture, RMNet backbone,
      and learnable image downscale block (like person-vehicle-bike-detection-crossroad-0066,
      but with extra pooling). The model is intended for security surveillance applications
      and works in a variety of scenes and weather/lighting conditions.
    task_type: "detection"
    files:
      - name: FP32/person-vehicle-bike-detection-crossroad-0078.xml
        sha256: 57d3638c34c4247ab2b60aa006aa628f2a8f6a2ea7d7ae276c06c92d4b54e19f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-vehicle-bike-detection-crossroad-0078/FP32/person-vehicle-bike-detection-crossroad-0078.xml
      - name: FP32/person-vehicle-bike-detection-crossroad-0078.bin
        sha256: 755e0442d18eadf6b6b1b83cf0b80e742e9e2f4c0792e5050509a9f376636a94
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-vehicle-bike-detection-crossroad-0078/FP32/person-vehicle-bike-detection-crossroad-0078.bin
      - name: FP16/person-vehicle-bike-detection-crossroad-0078.xml
        sha256: ec48338ebe4d253b120850ad650a98c50d751bd181b5b8d8db54eafec1be2035
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-vehicle-bike-detection-crossroad-0078/FP16/person-vehicle-bike-detection-crossroad-0078.xml
      - name: FP16/person-vehicle-bike-detection-crossroad-0078.bin
        sha256: 361bb6e53c199e0b332cb27f11c553b08432b3e39218c8b865cf8116083703c8
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-vehicle-bike-detection-crossroad-0078/FP16/person-vehicle-bike-detection-crossroad-0078.bin
      - name: INT8/person-vehicle-bike-detection-crossroad-0078.xml
        sha256: f340233916d6f3b8813541e3e7679e62d68bfbc23ddb92a025b87aca2a4ce50b
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-vehicle-bike-detection-crossroad-0078/INT8/person-vehicle-bike-detection-crossroad-0078.xml
      - name: INT8/person-vehicle-bike-detection-crossroad-0078.bin
        sha256: 4e1bd5ee45a90b4fe834281d2b35b97c92ab553b6835e2677ec4de79fd446c9c
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-vehicle-bike-detection-crossroad-0078/INT8/person-vehicle-bike-detection-crossroad-0078.bin
    output: "Security/object_detection/crossroad/0078/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "person-vehicle-bike-detection-crossroad-1016"
    description: >-
      Multiclass (person -  vehicle -  non-vehicle) detector based on SSD detection
      architecture -  MobileNetV2 backbone)
    task_type: "detection"
    files:
      - name: FP32/person-vehicle-bike-detection-crossroad-1016.xml
        sha256: ed13c22444792c8930dfc4884be53751e129f04c57e891fa15dceb118e5aee0a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-vehicle-bike-detection-crossroad-1016/FP32/person-vehicle-bike-detection-crossroad-1016.xml
      - name: FP32/person-vehicle-bike-detection-crossroad-1016.bin
        sha256: 0858938f00ee87fb47c632f47039316f6060a096e74dd3e5dc061d850b4b702d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-vehicle-bike-detection-crossroad-1016/FP32/person-vehicle-bike-detection-crossroad-1016.bin
      - name: FP16/person-vehicle-bike-detection-crossroad-1016.xml
        sha256: 9e45127e6c3814c7444a8da694b0c175d9ab8b25416eeeb98411a36d6eaf9ad8
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-vehicle-bike-detection-crossroad-1016/FP16/person-vehicle-bike-detection-crossroad-1016.xml
      - name: FP16/person-vehicle-bike-detection-crossroad-1016.bin
        sha256: 3d22081d3b1a8c3e24dcbbe23b677a92ad144530880df33f070615e42901cc55
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/person-vehicle-bike-detection-crossroad-1016/FP16/person-vehicle-bike-detection-crossroad-1016.bin
    output: "Security/object_detection/crossroad/1016/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "resnet-50-int8-sparse-v1-tf-0001"
    description: >-
      This is the Resnet-50 v1 model that is designed to perform image classification.
      The model has been pretrained on the ImageNet image database and then pruned
      to **28.4%** of sparsity and quantized to INT8 fixed-point precision using
      so-called Quantization-aware training approach implemented in TensorFlow framework.
      The sparsity is represented by zeros inside the weights of Convolutional and
      Fully-conneted layers. For details about the original floating point model,
      check out the [paper](https://arxiv.org/pdf/1512.03385.pdf).

      The model input is a blob that consists of a single image of "1x224x224x3"
      in BGR order.

      The model output for `resnet-50-int8-sparse-v1-tf-0001` is the usual object
      classifier output for the 1000 different classifications matching those in
      the ImageNet database.
    task_type: "classification"
    files:
      - name: FP32/resnet-50-int8-sparse-v1-tf-0001.xml
        sha256: 6063d0c338ac6282e22a94d0a138593df5d12f6fdfa0a256580cc86f10ba1357
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-sparse-v1-tf-0001/FP32/resnet-50-int8-sparse-v1-tf-0001.xml
      - name: FP32/resnet-50-int8-sparse-v1-tf-0001.bin
        sha256: 1053b7d0808e0c2a77cc5681f1acfaf87d297639449a498efa30bebfd25c18ac
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-sparse-v1-tf-0001/FP32/resnet-50-int8-sparse-v1-tf-0001.bin
      - name: FP16/resnet-50-int8-sparse-v1-tf-0001.xml
        sha256: 1623c51bddd03d369ac67fc74566b85fe9297e34df67732f06fdf67c3ad04009
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-sparse-v1-tf-0001/FP16/resnet-50-int8-sparse-v1-tf-0001.xml
      - name: FP16/resnet-50-int8-sparse-v1-tf-0001.bin
        sha256: ff58a5f185e7db302496854e62a0b8eacbd4496eeb2ef87e2bd1d3d7dda95ec0
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-sparse-v1-tf-0001/FP16/resnet-50-int8-sparse-v1-tf-0001.bin
    output: "PublicCompressed/classification/resnet50-dldt/INT8_sparse_v1/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "resnet-50-int8-sparse-v2-tf-0001"
    description: >-
      This is the Resnet-50 v1 model that is designed to perform image classification.
      The model has been pretrained on the ImageNet image database and then pruned
      to **60.4%** of sparsity and quantized to INT8 fixed-point precision using
      so-called Quantization-aware training approach implemented in TensorFlow framework.
      The sparsity is represented by zeros inside the weights of Convolutional and
      Fully-conneted layers. For details about the original floating point model,
      check out the [paper](https://arxiv.org/pdf/1512.03385.pdf).

      The model input is a blob that consists of a single image of "1x224x224x3"
      in BGR order.

      The model output for `resnet-50-int8-sparse-v2-tf-0001` is the usual object
      classifier output for the 1000 different classifications matching those in
      the ImageNet database.
    task_type: "classification"
    files:
      - name: FP32/resnet-50-int8-sparse-v2-tf-0001.xml
        sha256: 5345acb93bd379b4daf807d6675c02c41689aec085f0860b3339092df82ea341
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-sparse-v2-tf-0001/FP32/resnet-50-int8-sparse-v2-tf-0001.xml
      - name: FP32/resnet-50-int8-sparse-v2-tf-0001.bin
        sha256: 9858ddf582f225518fb106514b81ffdb0cf8db61d31a848f8e3994c492cb10ff
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-sparse-v2-tf-0001/FP32/resnet-50-int8-sparse-v2-tf-0001.bin
      - name: FP16/resnet-50-int8-sparse-v2-tf-0001.xml
        sha256: 069809548c4767df2449f55d95d59bd5850321f0ebc8cdfa7910a165bcf23a03
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-sparse-v2-tf-0001/FP16/resnet-50-int8-sparse-v2-tf-0001.xml
      - name: FP16/resnet-50-int8-sparse-v2-tf-0001.bin
        sha256: d52cd898a3cdadd32700a29342a956cca50dd0d11985470cbe6c4d8fbc29f8b2
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-sparse-v2-tf-0001/FP16/resnet-50-int8-sparse-v2-tf-0001.bin
    output: "PublicCompressed/classification/resnet50-dldt/INT8_sparse_v2/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "resnet-50-int8-tf-0001"
    description: >-
      This is the Resnet-50 v1 model that is designed to perform image classification.
      The model has been pretrained on the ImageNet image database and then quantized
      to INT8 fixed-point precision using so-called Quantization-aware training approach
      implemented in TensorFlow framework. For details about the original floating
      point model, check out the [paper](https://arxiv.org/pdf/1512.03385.pdf).

      The model input is a blob that consists of a single image of "1x224x224x3"
      in BGR order.

      The model output for `resnet-50-int8-tf-0001` is the usual object classifier
      output for the 1000 different classifications matching those in the ImageNet
      database.
    task_type: "classification"
    files:
      - name: FP32/resnet-50-int8-tf-0001.xml
        sha256: 27e9bc3b785fab357e84734722f51c4aee308946f05792be4c24e766fdfed477
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-tf-0001/FP32/resnet-50-int8-tf-0001.xml
      - name: FP32/resnet-50-int8-tf-0001.bin
        sha256: 1aa88c32c3d4bcef7945be75a18e805076db706f39da5242d62cbbcfa7172303
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-tf-0001/FP32/resnet-50-int8-tf-0001.bin
      - name: FP16/resnet-50-int8-tf-0001.xml
        sha256: 390d13c3f390b7430fc832a01cc7ce5e2004664703f4479cf698bfe1baa51e2c
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-tf-0001/FP16/resnet-50-int8-tf-0001.xml
      - name: FP16/resnet-50-int8-tf-0001.bin
        sha256: 0b252f934968afbe6a6dd096e1c4cc542bae8bcd27d4b6a6755e222fde770c19
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet-50-int8-tf-0001/FP16/resnet-50-int8-tf-0001.bin
    output: "PublicCompressed/classification/resnet50-dldt/INT8/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "resnet50-binary-0001"
    description: >-
      This is a classical classification network for 1000 classes trained on ImageNet.
      The difference is that most convolutional layers were replaced by binary once
      that can be implemented as XNOR+POPCOUN operations. Only input, final and shortcut
      layers were kept as FP32, all the rest convolutional layers are replaced by
      BinaryConvolution layers.
    task_type: "classification"
    files:
      - name: INT1/resnet50-binary-0001.xml
        sha256: 1a7e41ab273f9e7b064e60e889ba2f13ce1b07cb4610096bd3abef33a93bf992
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet50-binary-0001/INT1/resnet50-binary-0001.xml
      - name: INT1/resnet50-binary-0001.bin
        sha256: e843a458ae786f860698919709fb0852ef8138d4461ce8c744f96fe29ef0d580
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/resnet50-binary-0001/INT1/resnet50-binary-0001.bin
    output: "PublicCompressed/classification/resnet50_binary/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "road-segmentation-adas-0001"
    description: >-
      This is a segmentation network to classify each pixel into four classes: BG,
      road, curb, mark.
    task_type: "semantic_segmentation"
    files:
      - name: FP32/road-segmentation-adas-0001.xml
        sha256: 3dde42ae03c6dcad084aa899ffc7c64a354d77ce8276d3729abdd8b499e178ad
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/road-segmentation-adas-0001/FP32/road-segmentation-adas-0001.xml
      - name: FP32/road-segmentation-adas-0001.bin
        sha256: e4ec8fa66deb6904b5b6faa109fa699098cc1f947bf5216c6e31595ec397c569
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/road-segmentation-adas-0001/FP32/road-segmentation-adas-0001.bin
      - name: FP16/road-segmentation-adas-0001.xml
        sha256: 75375125d19859bbd96e8ff69f48ee72d7eab2c97d45ea5da90bb7f6a7ab9b4f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/road-segmentation-adas-0001/FP16/road-segmentation-adas-0001.xml
      - name: FP16/road-segmentation-adas-0001.bin
        sha256: 292b8c8789d66f102ffb9b87104b39488bfa55293ef97e7d6a50439762cdd884
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/road-segmentation-adas-0001/FP16/road-segmentation-adas-0001.bin
    output: "Transportation/segmentation/curbs/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "semantic-segmentation-adas-0001"
    description: >-
      This is a segmentation network to classify each pixel into 20 classes:

      - road

      - sidewalk

      - building

      - wall

      - fence

      - pole

      - traffic light

      - traffic sign

      - vegetation

      - terrain

      - sky

      - person

      - rider

      - car

      - truck

      - bus

      - train

      - motorcycle

      - bicycle

      - ego-vehicle
    task_type: "semantic_segmentation"
    files:
      - name: FP32/semantic-segmentation-adas-0001.xml
        sha256: 9f646a68bde022e8ccc4d74ea35d6d205b9fe123cbd8714605acbe9da847ca17
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/semantic-segmentation-adas-0001/FP32/semantic-segmentation-adas-0001.xml
      - name: FP32/semantic-segmentation-adas-0001.bin
        sha256: 5a616b105fa42f574e4d23cfc227c10b8bdcc0ba0e66864d7aa4b8a269b7cc76
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/semantic-segmentation-adas-0001/FP32/semantic-segmentation-adas-0001.bin
      - name: FP16/semantic-segmentation-adas-0001.xml
        sha256: 51f1951fadda0a45169bbe5f3b5f16247ea9986ff9ab73662d8b4fbd39e0f534
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/semantic-segmentation-adas-0001/FP16/semantic-segmentation-adas-0001.xml
      - name: FP16/semantic-segmentation-adas-0001.bin
        sha256: 8c39dcb0d3569003264165eda163833eef2d0803121147ab06f46697e4f8b4c4
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/semantic-segmentation-adas-0001/FP16/semantic-segmentation-adas-0001.bin
    output: "Transportation/segmentation/semantic_segmentation/icnet_icv/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "single-image-super-resolution-1032"
    description: >-
      An Attention-Based Approach for Single Image Super Resolution <https://arxiv.org/pdf/1807.06779.pdf>
      but with reduced number of channels and changes in network achitecture. It enhances
      the resolution of the input image by a factor of 4.
    task_type: "image_processing"
    files:
      - name: FP32/single-image-super-resolution-1032.xml
        sha256: 9e07cc539924ad57d4088a2f290eb115a6d1b3a60650c39a739c5b6115af7c77
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/single-image-super-resolution-1032/FP32/single-image-super-resolution-1032.xml
      - name: FP32/single-image-super-resolution-1032.bin
        sha256: e2403b56bd57b0e7c68e33dad3fb1af5e3f0be4a3ad7c7cbc1836fddf0c062b0
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/single-image-super-resolution-1032/FP32/single-image-super-resolution-1032.bin
      - name: FP16/single-image-super-resolution-1032.xml
        sha256: 1b56a9ce00fd386382cba178030f9ad58825d257db90338ddbadfddb68347a2a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/single-image-super-resolution-1032/FP16/single-image-super-resolution-1032.xml
      - name: FP16/single-image-super-resolution-1032.bin
        sha256: ac8a8c9387098ae9bc0cbda82cfe3235c9d2f9652277bbf07d78b96d2c4ff7e9
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/single-image-super-resolution-1032/FP16/single-image-super-resolution-1032.bin
    output: "Security/super_resolution/srresnet/dldt/1032/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "single-image-super-resolution-1033"
    description: >-
      An Attention-Based Approach for Single Image Super Resolution <https://arxiv.org/pdf/1807.06779.pdf>
      but with reduced number of channels and changes in network achitecture. It enhances
      the resolution of the input image by a factor of 3.
    task_type: "image_processing"
    files:
      - name: FP32/single-image-super-resolution-1033.xml
        sha256: 835d18b789e8d9d0543e35ee30be98dd69387078e9eac3c92efcab9f4f052943
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/single-image-super-resolution-1033/FP32/single-image-super-resolution-1033.xml
      - name: FP32/single-image-super-resolution-1033.bin
        sha256: 4f788a5d05373a8e68a20df7bde17347dbaf1531db0ed7ca340977c0dcb18b7a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/single-image-super-resolution-1033/FP32/single-image-super-resolution-1033.bin
      - name: FP16/single-image-super-resolution-1033.xml
        sha256: 9639ed3609187e8af7ad2e302ebfc980ea608528018e2e9d919a74a695455ea4
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/single-image-super-resolution-1033/FP16/single-image-super-resolution-1033.xml
      - name: FP16/single-image-super-resolution-1033.bin
        sha256: 0c0bd11d77f6a23242592db1c6ae0a3f0c8b472952aa3c2f5449cc448f68d90f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/single-image-super-resolution-1033/FP16/single-image-super-resolution-1033.bin
    output: "Security/super_resolution/srresnet/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "text-detection-0003"
    description: >-
      Text detector based on PixelLink <https://arxiv.org/pdf/1801.01315.pdf> architecture
      with MobileNetV2-like <https://arxiv.org/pdf/1801.04381.pdf> as a backbone
      for indoor/outdoor scenes.
    task_type: "detection"
    files:
      - name: FP32/text-detection-0003.xml
        sha256: 99f1bd3713176703e5e25f374e337a694786136053bb1dbf0507959ffec43a1f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-detection-0003/FP32/text-detection-0003.xml
      - name: FP32/text-detection-0003.bin
        sha256: 4ce684ad28cb70dc464565e1a476718845e3cc190fca14f385117f9ad970bcc4
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-detection-0003/FP32/text-detection-0003.bin
      - name: FP16/text-detection-0003.xml
        sha256: afa7c31ff970112c07d38018be3f359fb36a11782e9c9b32d29ae6ed317df841
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-detection-0003/FP16/text-detection-0003.xml
      - name: FP16/text-detection-0003.bin
        sha256: 0ee50f6aad475bf34116f809278766e0ecc82a648bbde40e2070c2e36f62ace7
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-detection-0003/FP16/text-detection-0003.bin
      - name: INT8/text-detection-0003.xml
        sha256: 85e079aa98e0bdc926b3a99d418fae7cadbc33868a190b6b534d1a4674d19396
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-detection-0003/INT8/text-detection-0003.xml
      - name: INT8/text-detection-0003.bin
        sha256: 5685f059522ae30cdbdef60317882988415fccc0e33950ed224b4d81d8e1a27c
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-detection-0003/INT8/text-detection-0003.bin
    output: "Retail/object_detection/text/pixel_link_mobilenet_v2/0003/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "text-detection-0004"
    description: >-
      Text detector based on PixelLink <https://arxiv.org/pdf/1801.01315.pdf> architecture
      with MobileNetV2, depth_multiplier=1.4 <(https://arxiv.org/pdf/1801.04381.pdf>
      as a backbone for indoor/outdoor scenes.
    task_type: "detection"
    files:
      - name: FP32/text-detection-0004.xml
        sha256: 247291f9adcb443130d8343398c3e45191c5a98a788fcebf46bc93f27f83447f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-detection-0004/FP32/text-detection-0004.xml
      - name: FP32/text-detection-0004.bin
        sha256: f6b58bf15c43cc017bd5f979b46b3159969968e47d3827de866d76d537931e1a
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-detection-0004/FP32/text-detection-0004.bin
      - name: FP16/text-detection-0004.xml
        sha256: 83b472a3f0b89bc3fb0b4d55ec51931ba218f56309ae35004a0543b33ec8939b
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-detection-0004/FP16/text-detection-0004.xml
      - name: FP16/text-detection-0004.bin
        sha256: 25b12925d0695af246ae68fbdf2ca1b61ac5b1f6b4b368386c2d82c880c93b70
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-detection-0004/FP16/text-detection-0004.bin
    output: "Retail/object_detection/text/pixel_link_mobilenet_v2/0004/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "text-recognition-0012"
    description: >-
      This is a network for text recognition scenario. It consists of VGG16-like backbone
      and bidirectional LSTM encoder-decoder. The network is able to recognize case-insensitive
      alpha-numeric text (36 unique symbols).
    task_type: "optical_character_recognition"
    files:
      - name: FP32/text-recognition-0012.xml
        sha256: b02671bb96f5699e39b80213005f30d144c42b7e12f97913c3debcb364e36b52
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-recognition-0012/FP32/text-recognition-0012.xml
      - name: FP32/text-recognition-0012.bin
        sha256: df7426c3a16c005eda3c9efc6afeefe38259b36748819fc0b28f3d2a67c16239
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-recognition-0012/FP32/text-recognition-0012.bin
      - name: FP16/text-recognition-0012.xml
        sha256: b4d9e00f5e88e6a257b8b96ad2e99e1a72f2669a9fb1ea1861b2efb2ac597eda
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-recognition-0012/FP16/text-recognition-0012.xml
      - name: FP16/text-recognition-0012.bin
        sha256: 657f2b3fdcab897980f976692bb0b93bd05f7b29b111bfe518726ef5c835c786
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/text-recognition-0012/FP16/text-recognition-0012.bin
    output: "Retail/text_recognition/bilstm_crnn_bilstm_decoder/0012/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "vehicle-attributes-recognition-barrier-0039"
    description: >-
      This model presents a vehicle attributes classification algorithm for a traffic
      analysis scenario.
    task_type: "object_attributes"
    files:
      - name: FP32/vehicle-attributes-recognition-barrier-0039.xml
        sha256: eb7022336e05b57cf46e8a8cc5cbce85f4a28d40b0731cbe2e5452950fba2ef2
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-attributes-recognition-barrier-0039/FP32/vehicle-attributes-recognition-barrier-0039.xml
      - name: FP32/vehicle-attributes-recognition-barrier-0039.bin
        sha256: 8195ea60216d9aefdab41e3129900aa847f4f0d3d003ce93aa15ecba0ca18e91
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-attributes-recognition-barrier-0039/FP32/vehicle-attributes-recognition-barrier-0039.bin
      - name: FP16/vehicle-attributes-recognition-barrier-0039.xml
        sha256: 9d7ffb084a2dab087f63f0671c95703a80a85bc451d9326699c56d3c2e2fdb05
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-attributes-recognition-barrier-0039/FP16/vehicle-attributes-recognition-barrier-0039.xml
      - name: FP16/vehicle-attributes-recognition-barrier-0039.bin
        sha256: be8b61e337a23ffa57d1742f92d2317560303652f330fef0cbe918161bfcaf50
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-attributes-recognition-barrier-0039/FP16/vehicle-attributes-recognition-barrier-0039.bin
      - name: INT8/vehicle-attributes-recognition-barrier-0039.xml
        sha256: 6241052429bee567936b18f5c81db0c600c6e43c48dd64d20f6b56cb8681be1c
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-attributes-recognition-barrier-0039/INT8/vehicle-attributes-recognition-barrier-0039.xml
      - name: INT8/vehicle-attributes-recognition-barrier-0039.bin
        sha256: 4ca9587b866ecc92418b87424ec5becb05f73a9781cd2eab6abeff7a54067590
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-attributes-recognition-barrier-0039/INT8/vehicle-attributes-recognition-barrier-0039.bin
    output: "Security/object_attributes/vehicle/resnet10_update_1/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "vehicle-detection-adas-0002"
    description: >-
      This is a vehicle detection network based on an SSD framework with tuned MobileNet
      v1 as a feature extractor.
    task_type: "detection"
    files:
      - name: FP32/vehicle-detection-adas-0002.xml
        sha256: 9c866248be954641c6fc266a859b95369501ed1d6927cebc432ce707e682e4e4
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-detection-adas-0002/FP32/vehicle-detection-adas-0002.xml
      - name: FP32/vehicle-detection-adas-0002.bin
        sha256: bafe8ad70bb232e2b35928a31b9a4d3c7d4a6d6995b6bf2012c0ba9674f9d66d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-detection-adas-0002/FP32/vehicle-detection-adas-0002.bin
      - name: FP16/vehicle-detection-adas-0002.xml
        sha256: 848f0f58dbfd735fafe003ea21e2e6d54f4c76689b3f491a85d13c78821d1c72
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-detection-adas-0002/FP16/vehicle-detection-adas-0002.xml
      - name: FP16/vehicle-detection-adas-0002.bin
        sha256: f2ce728a0140da04f1c7cb3726e73b8868055bc59518ed2bdd2de3a787dbf8cb
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-detection-adas-0002/FP16/vehicle-detection-adas-0002.bin
      - name: INT8/vehicle-detection-adas-0002.xml
        sha256: f630d81c9f05eb76f5e539d6026f45437af6b448ba5211bdff95431008249ea8
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-detection-adas-0002/INT8/vehicle-detection-adas-0002.xml
      - name: INT8/vehicle-detection-adas-0002.bin
        sha256: a7bf4a5edbc278a2d25ef33541958170670f346baf9dd07e6b02fc5618ba4a63
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-detection-adas-0002/INT8/vehicle-detection-adas-0002.bin
    output: "Transportation/object_detection/vehicle/mobilenet-reduced-ssd/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "vehicle-detection-adas-binary-0001"
    description: >-
      This is a vehicle detection network based on an SSD framework with tuned MobileNet
      v1 as a feature extractor and using binary layer for speedup. This detecector
      was created by binarization the vehicle-detection-adas-0002
    task_type: "detection"
    files:
      - name: INT1/vehicle-detection-adas-binary-0001.xml
        sha256: c98bf5984895b1309861597ec36181446877407cd985bb490e14461f41312670
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-detection-adas-binary-0001/INT1/vehicle-detection-adas-binary-0001.xml
      - name: INT1/vehicle-detection-adas-binary-0001.bin
        sha256: afdd8a2f175b2f19c07083ff23b2e28105f3d1c7dc06a4b1a1d5c2c42b98294f
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-detection-adas-binary-0001/INT1/vehicle-detection-adas-binary-0001.bin
    output: "Transportation/object_detection/vehicle/mobilenet-reduced-ssd-binary/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

  - name: "vehicle-license-plate-detection-barrier-0106"
    description: >-
      This is a MobileNetV2 + SSD-based vehicle and (Chinese) license plate detector
      for the "Barrier" use case.
    task_type: "detection"
    files:
      - name: FP32/vehicle-license-plate-detection-barrier-0106.xml
        sha256: 6125e1ab15871fb5f3d99b125158cb38ab7796b66f348013fac0cdefd274f023
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-license-plate-detection-barrier-0106/FP32/vehicle-license-plate-detection-barrier-0106.xml
      - name: FP32/vehicle-license-plate-detection-barrier-0106.bin
        sha256: 56fda262d99ef097cc95ede0c4b64516fc545b1694984174d45be3772903c0e7
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-license-plate-detection-barrier-0106/FP32/vehicle-license-plate-detection-barrier-0106.bin
      - name: FP16/vehicle-license-plate-detection-barrier-0106.xml
        sha256: d45158ff83b8705ce43f752a824e5bde756f84b720e0109d5c784606cc080770
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106.xml
      - name: FP16/vehicle-license-plate-detection-barrier-0106.bin
        sha256: 8c4941114e9d3e1a5908b83fa3324362b7eb91b3ec9792df6cebfa720588dd80
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106.bin
      - name: INT8/vehicle-license-plate-detection-barrier-0106.xml
        sha256: f9ca8aa2b68c67a27d8fa41d2a37bc2363a1ae6c9d0fcebc6dd5a75d067b00e4
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-license-plate-detection-barrier-0106/INT8/vehicle-license-plate-detection-barrier-0106.xml
      - name: INT8/vehicle-license-plate-detection-barrier-0106.bin
        sha256: d41240cf81bd56c9e74e6eb88737898d90fa145bed1cc9284ef98892ca2e5a9d
        source: https://download.01.org/opencv/2019/open_model_zoo/R2/20190716_170000_models_bin/vehicle-license-plate-detection-barrier-0106/INT8/vehicle-license-plate-detection-barrier-0106.bin
    output: "Security/object_detection/barrier/0106/dldt/"
    framework: dldt
    license: https://raw.githubusercontent.com/opencv/open_model_zoo/master/LICENSE

models:
  - name: SampLeNet_example

    # list of launchers for your topology.
    launchers:
      # launcher framework (e.g. caffe, dlsdk)
      - framework: dlsdk
        # device for infer (e.g. for dlsdk cpu, gpu, hetero:cpu,gpu ...)
        # Note: not all devices support blob execution, it is the reason why for sample we will use myriad.
        device: MYRIAD
        # exported executable network blob
        # you can export executable network blob from OpenVINO IR using compile_tool, see https://docs.openvinotoolkit.org/latest/_inference_engine_tools_compile_tool_README.html
        # path to model is prefixed with directory, specified in "-m/--models" option
        model: SampleNet.blob
        # launcher returns raw result, so it should be converted
        # to an appropriate representation with adapter
        adapter: classification

    # metrics, preprocessing and postprocessing are typically dataset specific, so dataset field
    # specifies data and all other steps required to validate topology
    # there is typically definitions file, which contains options for common datasets and which is merged
    # during evaluation, but since "sample_dataset" is not used anywhere else, this config contains full definition
    datasets:
      # uniquely distinguishable name for dataset
      # note that all other steps are specific for this dataset only
      # if you need to test topology on multiple datasets, you need to specify
      # every step explicitly for each dataset
      - name: sample_dataset
        # directory where input images are searched.
        # prefixed with directory specified in "-s/--source" option
        data_source: sample_dataset/test
        # parameters for annotation conversion to a common annotation representation format.
        annotation_conversion:
          # specified which annotation converter will be used
          #  In order to do this you need to provide your own annotation converter,
          # i.e. implement BaseFormatConverter interface.
          # All annotation converters are stored in accuracy_checker/annotation_converters directory.
          converter: cifar
          # converter specific parameters.
          # Full range available options you can find in accuracy_checker/annotation_converters/README.md
          # relative paths will be merged with "-s/--source" option
          data_batch_file: cifar-10-batches-py/test_batch
          # cifar stores images as binary file, we should convert them to png in first evaluation.
          # Yo do not need to use these options if you have already converted dataset images.
          convert_images: True
          # path to save converted images.
          converted_images_dir: sample_dataset/test
          # number of classes in the dataset, used for label_map generation
          num_classes: 10

        # list of preprocessing, applied to each image during validation
        # order of entries matters
        preprocessing:
          # resize input image to topology input size
          # you may specify size to which image should be resized
          # via dst_width, dst_height fields
          - type: resize
            size: 32
            # topology is trained on RGB images, but OpenCV reads in BGR
            # thence it must be converted to RGB
          - type: bgr_to_rgb
          # dataset mean and standard deviation
          - type: normalization
            # you may specify precomputed statistics manually or use precomputed values, such as ImageNet as well
            mean: (125.307, 122.961, 113.8575)
            std: (51.5865, 50.847, 51.255)

        # list of metrics, calculated on dataset
        metrics:
          - type: accuracy
            top_k: 1

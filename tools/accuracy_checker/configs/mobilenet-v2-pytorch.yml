models:
  - name: mobilenet-v2-pytorch

    launchers:
      - framework: onnx_runtime
        model: public/mobilenet-v2-pytorch/mobilenet-v2.onnx
        adapter: classification
        inputs:
          - name: data
            type: INPUT
            shape: 1,3,224,224

    datasets:
      - name: imagenet_1000_classes
        reader: pillow_imread

        # In order to be used by model, images must be:
        # 1) Resized to 256x256 with bilinear interpolation
        # 2) Cropped central part 224x224
        # 3) Normalized by 255
        # 4) Normalized by (0.229, 0.224, 0.225) with mean values (0.485, 0.456, 0.406)
        preprocessing:
          - type: resize
            size: 256
            aspect_ratio_scale: greater
            use_pillow: true
            interpolation: BILINEAR

          - type: crop
            size: 224
            use_pillow: true

          - type: normalization
            std: 255

          - type: normalization
            mean: (0.485, 0.456, 0.406)
            std: (0.229, 0.224, 0.225)

            # Using accuracy metric, achieved result of public model - 71.8

  - name: mobilenet-v2-pytorch

    # list of launchers for MobileNetV2.
    launchers:
      - framework: dlsdk
        tags:
          - FP32
        model:   public/mobilenet-v2-pytorch/FP32/mobilenet-v2-pytorch.xml
        weights: public/mobilenet-v2-pytorch/FP32/mobilenet-v2-pytorch.bin
        adapter: classification

      - framework: dlsdk
        tags:
          - FP16
        model:   public/mobilenet-v2-pytorch/FP16/mobilenet-v2-pytorch.xml
        weights: public/mobilenet-v2-pytorch/FP16/mobilenet-v2-pytorch.bin
        adapter: classification

      - framework: dlsdk
        tags:
          - FP32-INT8
        model:   public/mobilenet-v2-pytorch/FP32-INT8/mobilenet-v2-pytorch.xml
        weights: public/mobilenet-v2-pytorch/FP32-INT8/mobilenet-v2-pytorch.bin
        adapter: classification

      - framework: dlsdk
        tags:
          - FP16-INT8
        model:   public/mobilenet-v2-pytorch/FP16-INT8/mobilenet-v2-pytorch.xml
        weights: public/mobilenet-v2-pytorch/FP16-INT8/mobilenet-v2-pytorch.bin
        adapter: classification

    datasets:
      - name: imagenet_1000_classes
        reader: pillow_imread

        # Image channels must be swapped, because "pillow_imread" reads in RGB, but converted model expect BGR
        preprocessing:
          - type: bgr_to_rgb

          - type: resize
            size: 256
            aspect_ratio_scale: greater
            use_pillow: true
            interpolation: BILINEAR

          - type: crop
            size: 224
            use_pillow: true

            # Using accuracy metric, achieved result of public model - 71.8

global_definitions: ../dataset_definitions.yml

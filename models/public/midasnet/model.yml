# Copyright (c) 2022 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  MidasNet is a model for monocular depth estimation trained by mixing several datasets;
  as described in the following paper: Towards Robust Monocular Depth Estimation:
  Mixing Datasets for Zero-Shot Cross-Dataset Transfer <https://arxiv.org/abs/1907.01341>

  The model input is a blob that consists of a single image of "1, 3, 384, 384" in
  "RGB" order.

  The model output is an inverse depth map that is defined up to an unknown scale
  factor.
task_type: monocular_depth_estimation
files:
  - name: models/midas_net.py
    size: 2662
    checksum: ad8d94e07cfb60e463f383057763a0faa29e7547fe3b4482c787a5948050f37f0878c6f307d455f6759928237e43b78c
    source: https://raw.githubusercontent.com/intel-isl/MiDaS/ffb70fd13361434114383ce7eb898c2f5bec6176/models/midas_net.py
  - name: models/base_model.py
    size: 355
    checksum: cf959343ae280093bb38eb225f4d3b1de791ef7e245c35f02315bd984065379e7a29b5830010aad34d3ac38ca77bfa04
    source: https://raw.githubusercontent.com/intel-isl/MiDaS/ffb70fd13361434114383ce7eb898c2f5bec6176/models/base_model.py
  - name: models/blocks.py
    size: 3596
    checksum: 3bca3aadb2e7fc5990e4d909740e2c8c6cbedd326fc49ea858e06ebe97269d6410d2f28e0cec3ca2b5b466928c84fa2e
    source: https://raw.githubusercontent.com/intel-isl/MiDaS/ffb70fd13361434114383ce7eb898c2f5bec6176/models/blocks.py
  - name: model.pt
    size: 422509849
    checksum: 22219f664a4b235e797585d56a398c25e7cbb3cdb46f61bdc0e0596dc713495ece860ac57df8b22f7b530ea00c21b049
    original_source: https://github.com/intel-isl/MiDaS/releases/download/v2_1/model-openvino.pt
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2022.1/midasnet/model-openvino.pt
framework: pytorch
postprocessing:
  - $type: regex_replace
    file: models/blocks.py
    pattern: 'import torch.nn as nn'
    replacement: 'import torch.nn as nn\nimport torchvision.models as models'
  - $type: regex_replace
    file: models/blocks.py
    pattern: 'torch.hub.load\("facebookresearch/WSL-Images", "resnext101_32x8d_wsl"\)'
    replacement: 'models.resnext101_32x8d()'
conversion_to_onnx_args:
  - --model-name=MidasNet
  - --model-path=$dl_dir
  - --weights=$dl_dir/model.pt
  - --import-module=models.midas_net
  - --input-shape=1,3,384,384
  - --output-file=$conv_dir/midasnet.onnx
  - --input-names=image
  - --output-names=inverse_depth
model_optimizer_args:
  - --input=image
  - --layout=image(NCHW)
  - --mean_values=image[123.675,116.28,103.53]
  - --scale_values=image[51.525,50.4,50.625]
  - --reverse_input_channels
  - --output=inverse_depth
  - --input_model=$conv_dir/midasnet.onnx
license: https://raw.githubusercontent.com/intel-isl/MiDaS/master/LICENSE

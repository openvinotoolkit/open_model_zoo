# Copyright (c) 2019 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  MidasNet is a model for monocular depth estimation trained by mixing several datasets;
  as described in the following paper: 
  "Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer"
  <https://arxiv.org/abs/1907.01341>

  The model input is a blob that consists of a single image of "1x3x384x384" in RGB order.

  The model output is an inverse depth map that is defined up to an unknown scale factor.
task_type: monocular_depth_estimation
files:
  - name: models/midas_net.py
    size: 2662
    sha256: 0bf2e5295b69b3af9adafaf97e154186d29a808325435440aa68c7aa4d25f753
    source: https://raw.githubusercontent.com/intel-isl/MiDaS/ffb70fd13361434114383ce7eb898c2f5bec6176/models/midas_net.py
  - name: models/base_model.py
    size: 355
    sha256: a05c91a037f85ebc07f39b269f0784df577c25fb46f84b27b5fcbbd1e44236ff
    source: https://raw.githubusercontent.com/intel-isl/MiDaS/ffb70fd13361434114383ce7eb898c2f5bec6176/models/base_model.py
  - name: models/blocks.py
    size: 3596
    sha256: ba87812d0b5b247966471511d2d1a47fd6f492afb372bc49af6de3a46f4cf6c7
    source: https://raw.githubusercontent.com/intel-isl/MiDaS/ffb70fd13361434114383ce7eb898c2f5bec6176/models/blocks.py
  - name: model.pt
    size: 422397766
    sha256: 5237e007f53f05d0a66f40590abfead08dbb662629089e3462daf741ac9932d6
    source: https://download.01.org/opencv/public_models/032020/midasnet/model-001.pt
framework: pytorch
postprocessing:
  - $type: regex_replace
    file: models/blocks.py
    pattern: 'align_corners=True'
    replacement: 'align_corners=False'
  - $type: regex_replace
    file: models/blocks.py
    pattern: 'import torch.nn as nn'
    replacement: 'import torch.nn as nn\nimport torchvision.models as models'
  - $type: regex_replace
    file: models/blocks.py
    pattern: 'torch.hub.load\("facebookresearch/WSL-Images", "resnext101_32x8d_wsl"\)'
    replacement: 'models.resnext101_32x8d()'
conversion_to_onnx_args:
  - --model-name=MidasNet
  - --model-path=$dl_dir
  - --weights=$dl_dir/model.pt
  - --import-module=models.midas_net
  - --input-shape=1,3,384,384
  - --output-file=$conv_dir/midasnet.onnx
  - --input-names=image
  - --output-names=inverse_depth
model_optimizer_args:
  - --input=image
  - --mean_values=image[123.675,116.28,103.53]
  - --scale_values=image[51.525,50.4,50.625]
  - --reverse_input_channels
  - --output=inverse_depth
  - --input_model=$conv_dir/midasnet.onnx
license: https://raw.githubusercontent.com/intel-isl/MiDaS/master/LICENSE

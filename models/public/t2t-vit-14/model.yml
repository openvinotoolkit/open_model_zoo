# Copyright (c) 2022 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  The "t2t-vit-14" model is a variant of the Tokens-To-Token Vision Transformer(T2T-ViT)
  pre-trained on ImageNet dataset for image classification task. T2T-ViT progressively
  tokenize the image to tokens and has an efficient backbone. T2T-ViT consists of
  two main components: 1) a layer-wise "Tokens-to-Token module" to model the local
  structure information of the image and reduce the length of tokens progressively;
  2) an efficient "T2T-ViT backbone" to draw the global attention relation on tokens
  from the T2T module. The model has 14 transformer layers in T2T-ViT backbone with
  384 hidden dimensions.

  More details provided in the paper <https://arxiv.org/abs/2101.11986> and repository
  <https://github.com/yitu-opensource/T2T-ViT>.
task_type: classification
files:
  - name: timm-0.5.4-py3-none-any.whl
    size: 431537
    checksum: e8f1967a8e2029fe21a43875132b4b123227b718abc35725d7f2b9fd0ef2062884ac3dd558570b51a780aad89bc375d6
    source: https://files.pythonhosted.org/packages/49/65/a83208746dc9c0d70feff7874b49780ff110810feb528df4b0ecadcbee60/timm-0.5.4-py3-none-any.whl
  - name: models/t2t_vit.py
    size: 12499
    checksum: caca4a1eced1616d403a3e582ebb30f79c9ab08be1b8789f4ddc5c34c55dccd0c95557062017e9794ff4e9b3bf017a63
    source: https://raw.githubusercontent.com/yitu-opensource/T2T-ViT/2c25580c6b6968bba043be3c8f5d581428c6716d/models/t2t_vit.py
  - name: models/token_transformer.py
    size: 2326
    checksum: a0e33192063f3ada47a504f5381c7f4c196ddae531b0514096ea06ee29bfa94a9716ffc8410fdd58bca07c732c0b4ef9
    source: https://raw.githubusercontent.com/yitu-opensource/T2T-ViT/2c25580c6b6968bba043be3c8f5d581428c6716d/models/token_transformer.py
  - name: models/token_performer.py
    size: 2370
    checksum: 77fd18c505f7780dd4f5a1149a208ef4b56b486bb9d89d05132321b32969ae79194ce5f49c8d194969176c1e9a4bedf6
    source: https://raw.githubusercontent.com/yitu-opensource/T2T-ViT/2c25580c6b6968bba043be3c8f5d581428c6716d/models/token_performer.py
  - name: models/transformer_block.py
    size: 3286
    checksum: e0ae48049b38c15664267d1e6a469f2427159d938feb9d438c37f6b922b65a959fe5172b8dee099fd3ae25a63c52489f
    source: https://raw.githubusercontent.com/yitu-opensource/T2T-ViT/2c25580c6b6968bba043be3c8f5d581428c6716d/models/transformer_block.py
  - name: 81.5_T2T_ViT_14.pth
    size: 86212823
    checksum: 98c8ae06a1e9997f3e83ad2dfbac49985bf7bd7723eb64e4b8462338163be02657998f0bd9f8997367417003caeaf7a1
    source: https://github.com/yitu-opensource/T2T-ViT/releases/download/main/81.5_T2T_ViT_14.pth.tar
postprocessing:
  - $type: unpack_archive
    format: zip
    file: timm-0.5.4-py3-none-any.whl
conversion_to_onnx_args:
  - --model-path=$dl_dir
  - --model-path=$config_dir
  - --model-name=create_model
  - --import-module=model
  - --model-param=weights=r"$dl_dir/81.5_T2T_ViT_14.pth"
  - --input-shape=1,3,224,224
  - --input-names=image
  - --output-names=probs
  - --output-file=$conv_dir/t2t-vit-14.onnx
  - --opset_version=12
model_optimizer_args:
  - --input_shape=[1,3,224,224]
  - --input=image
  - --input_model=$conv_dir/t2t-vit-14.onnx
  - --mean_values=image[123.675,116.28,103.53]
  - --scale_values=image[58.395,57.12,57.375]
  - --reverse_input_channels
  - --layout=image(NCHW)
  - --output=probs
framework: pytorch
license: https://raw.githubusercontent.com/yitu-opensource/T2T-ViT/main/LICENSE

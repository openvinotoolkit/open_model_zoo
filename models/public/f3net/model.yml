# Copyright (c) 2022 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  F3Net: Fusion, Feedback and Focus for Salient Object Detection. For details see
  the repository <https://github.com/weijun88/F3Net>, paper <https://arxiv.org/abs/1911.11445>
task_type: salient_object_detection
files:
  - name: f3net/net.py
    size: 8656
    checksum: 17947bb60281d99ed16a5f646d0476a1fb439e21c70a8efbdd12151aad271599e4951bff546a89ac5fddf5058af7d6cb
    source: https://raw.githubusercontent.com/weijun88/F3Net/eecace3adf1e8946b571a4f4397681252f9dc1b8/src/net.py
  - name: f3net/dataset.py
    size: 4497
    checksum: 0a741a171f3faf065af323de147165bee85f627e572aad00529cfcddcf26c34b212e223c0da3d8d45ffa760c79ba4712
    source: https://raw.githubusercontent.com/weijun88/F3Net/eecace3adf1e8946b571a4f4397681252f9dc1b8/src/dataset.py
  - name: f3net/model-32
    size: 102506472
    checksum: 6476078ef447502af76f214b96161f6295662ccef6d412aec90d0aca03fc5d7759fdd880c9ddec146e656114805acfc2
    original_source:
      $type: google_drive
      id: 1jcsmxZHL6DGwDplLp93H4VeN2ZjqBsOF
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2022.1/f3net/f3net/model-32
postprocessing:
  - $type: regex_replace
    file: f3net/net.py
    pattern: 'torch.load\(self.cfg.snapshot\)'
    replacement: "torch.load(self.cfg.snapshot, map_location=torch.device('cpu'))"
  - $type: regex_replace
    file: f3net/net.py
    pattern: 'import matplotlib.pyplot as plt'
    replacement: ''
  - $type: regex_replace
    file: f3net/net.py
    # remove extra feature maps used for calculation loss during training
    pattern: 'return pred1, pred2, out2h, out3h, out4h, out5h'
    replacement: "return pred2"
  - $type: regex_replace
    file: f3net/dataset.py
    pattern: 'import cv2'
    replacement: ''
conversion_to_onnx_args:
  - --model-name=f3net
  - --model-path=$config_dir
  - --model-path=$dl_dir
  - --import-module=model
  - --input-shape=1,3,352,352
  - --output-file=$conv_dir/f3net.onnx
  - --model-param=weights=r"$dl_dir/f3net/model-32"
  - --input-names=input.1
  - --output-names="saliency_map"
model_optimizer_args:
  - --input_shape=[1,3,352,352]
  - --input=input.1
  - --layout=input.1(NCHW)
  - --input_model=$conv_dir/f3net.onnx
  - --mean_values=input.1[124.55,118.90,102.94]
  - --scale_values=input.1[56.77,55.97,57.50]
  - --reverse_input_channels
  - --output="saliency_map"
framework: pytorch
quantizable: true
license: https://github.com/weijun88/F3Net/blob/master/LICENSE

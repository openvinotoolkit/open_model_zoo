# Copyright (c) 2022 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  This is a model for monocular depth estimation trained on the NYU Depth V2 dataset,
  as described in the paper Deeper Depth Prediction with Fully Convolutional Residual
  Networks <https://arxiv.org/abs/1606.00373>, where it is referred to as ResNet-UpProj.
  The model input is a single color image. The model output is an inverse depth map
  that is defined up to an unknown scale factor. More details can be found in the
  following repository <https://github.com/iro-cp/FCRN-DepthPrediction>.
task_type: monocular_depth_estimation
framework: tf
files:
  - name: NYU_FCRN-checkpoint.zip
    size: 472588519
    checksum: a7e281b3c8ed500f6d3d759febbb3c5a72ae66a8b432ca4e68b45d4defed0f9ca1f3606cbc34a136203283b9a5370122
    original_source: http://campar.in.tum.de/files/rupprecht/depthpred/NYU_FCRN-checkpoint.zip
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2022.1/fcrn-dp-nyu-depth-v2-tf/NYU_FCRN-checkpoint.zip
postprocessing:
  - $type: unpack_archive
    format: zip
    file: NYU_FCRN-checkpoint.zip
model_optimizer_args:
  - --input=Placeholder
  - --reverse_input_channels
  - --input_shape=[1,228,304,3]
  - --layout=Placeholder(NHWC)
  - --output=ConvPred/ConvPred
  - --input_meta=$dl_dir/NYU_FCRN.ckpt.meta
quantizable: true
license: https://raw.githubusercontent.com/iro-cp/FCRN-DepthPrediction/master/LICENSE

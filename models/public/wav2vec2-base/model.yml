# Copyright (c) 2021 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  Wav2Vec2.0-base is a model, which pre-trained to learn speech representations on
  unlabeled data as described in wav2vec 2.0: A Framework for Self-Supervised Learning
  of Speech Representations <https://arxiv.org/abs/2006.11477> paper and fine-tuned
  for speech recognition task with a Connectionist Temporal Classification (CTC) loss
  on LibriSpeech dataset containing 960 hours of audio. The model is composed of a
  multi-layer convolutional feature encoder which takes as input raw audio and outputs
  latent speech representations, then fed to a Transformer to build representations
  capturing information from the entire sequence. For base model Transformer consists
  of 12 transformer layers and has 768 as feature dimension. For details please also
  check repository <https://github.com/pytorch/fairseq/tree/master/examples/wav2vec#wav2vec-20>
  and model card <https://huggingface.co/facebook/wav2vec2-base-960h>.
task_type: named_entity_recognition
files:
  - name: transformers-4.8.2-py3-none-any.whl
    size: 2499371
    sha384: a81a7683013fb48690c47e4e2d12a6c6e744b4261ae085f9a98d09f6c3e61d98
    source: https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl
  - name: wav2vec2-base-960h/pytorch_model.bin
    size: 377667514
    sha384: c34f9827b034a1b9141dbf6f652f8a60eda61cdf5771c9e05bfa99033c92cd96
    source: https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin
  - name: wav2vec2-base-960h/config.json
    size: 1596
    sha384: d3ec255c063d9f95057b553b19c20135b259875834a4fe9deb218a6be25b4cf3
    source: https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/config.json
  - name: wav2vec2-base-960h/vocab.json
    size: 291
    sha384: 19727f8944fe6459fc3f240ae2c198395b740f6a029bd23e06656266b83bcf64
    source: https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json
  - name: packaging-20.9-py2.py3-none-any.whl
    size: 40870
    sha384: 67714da7f7bc052e064859c05c595155bd1ee9f69f76557e21f051443c20947a
    source: https://files.pythonhosted.org/packages/3e/89/7ea760b4daa42653ece2380531c90f64788d979110a2ab51049d92f408af/packaging-20.9-py2.py3-none-any.whl
postprocessing:
  - $type: unpack_archive
    format: zip
    file: transformers-4.8.2-py3-none-any.whl
  - $type: unpack_archive
    format: zip
    file: packaging-20.9-py2.py3-none-any.whl
  - $type: regex_replace
    file: transformers/__init__.py
    pattern: 'from . import dependency_versions_check'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/deepspeed.py
    pattern: 'from .dependency_versions_check import dep_version_check'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: 'from tqdm.auto import tqdm'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: from filelock import FileLock
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: from huggingface_hub import HfApi, HfFolder, Repository
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: return HfApi\(endpoint=HUGGINGFACE_CO_RESOLVE_ENDPOINT\)\.create_repo\(\n.*\n.*\n.*\n.*\n.*\n.*\n+.*\)
    replacement: 'return None'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: 'repo = Repository\(repo_path_or_name, clone_from=repo_url, use_auth_token=use_auth_token\)'
    replacement: 'repo = None'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: 'def _push_to_hub\(cls, repo\: Repository, commit_message\: Optional\[str\]
      = None\) -> str\:'
    replacement: 'def _push_to_hub(cls, repo, commit_message: Optional[str] = None)
      -> str:'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: '-> Repository\:'
    replacement: ':'
conversion_to_onnx_args:
  - --model-path=$dl_dir
  - --model-path=$config_dir
  - --model-name=create_model
  - --import-module=model
  - --model-param=model_dir=r"$dl_dir/wav2vec2-base-960h"
  - --input-names=inputs
  - --output-names=logits
  - --input-shapes=[1,30480]
  - --output-file=$conv_dir/wav2vec2-base.onnx
  - '--conversion-param=dynamic_axes={"inputs": {0: "batch_size", 1: "sequence_len"},
    "logits": {0: "batch_size", 1: "sequence_len"}}'
model_optimizer_args:
  - --input_shape=[1,30480]
  - --input=inputs
  - --input_model=$conv_dir/wav2vec2-base.onnx
  - --output=logits
framework: pytorch
quantizable: yes
license: https://raw.githubusercontent.com/pytorch/fairseq/master/LICENSE

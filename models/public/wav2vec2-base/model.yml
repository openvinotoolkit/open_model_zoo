# Copyright (c) 2022-2024 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  Wav2Vec2.0-base is a model, which pre-trained to learn speech representations on
  unlabeled data as described in wav2vec 2.0: A Framework for Self-Supervised Learning
  of Speech Representations <https://arxiv.org/abs/2006.11477> paper and fine-tuned
  for speech recognition task with a Connectionist Temporal Classification (CTC) loss
  on LibriSpeech dataset containing 960 hours of audio. The model is composed of a
  multi-layer convolutional feature encoder which takes as input raw audio and outputs
  latent speech representations, then fed to a Transformer to build representations
  capturing information from the entire sequence. For base model Transformer consists
  of 12 transformer layers and has 768 as feature dimension. For details please also
  check repository <https://github.com/pytorch/fairseq/tree/master/examples/wav2vec#wav2vec-20>
  and model card <https://huggingface.co/facebook/wav2vec2-base-960h>.
task_type: named_entity_recognition
files:
  - name: transformers-4.8.2-py3-none-any.whl
    size: 2499371
    checksum: 91713fbb6bf46b5a216c3336260cc03e7d2c7cbd031e810d22feeed0865f9e0f5d7a87c45f7d60669587cbc9548c30c1
    source: https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl
  - name: wav2vec2-base-960h/pytorch_model.bin
    size: 377667514
    checksum: 647658a0fc4376ddccb8430207fd50f22a59f607f821ddb6e7dfec7bf2f41d3bbe4d6e62c2779530f1a2e20ec75acf9b
    original_source: https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2022.1/wav2vec2-base/pytorch_model.bin
  - name: wav2vec2-base-960h/config.json
    size: 1596
    checksum: 1c28d7ba60f46b0212c73afde1ff9a77a0bc2801c3dc6bcac77835ed147e0df49a28bc627c0a76b1f6b8959170e7627b
    original_source: https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/config.json
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2022.1/wav2vec2-base/config.json
  - name: wav2vec2-base-960h/vocab.json
    size: 291
    checksum: 87dc62dd416ca1d37674e5169d701d443b0644f23c0584d52b5813d025ebb5cecf9ea64850c4c09fe10766e7b2e8435c
    original_source: https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2022.1/wav2vec2-base/vocab.json
  - name: packaging-20.9-py2.py3-none-any.whl
    size: 40870
    checksum: 422fac4cb009bed3eae42e9688b1712ee15dde1799c888f33c802792e925373dee046602d1d31c460d9d2af3ff6b93a1
    source: https://files.pythonhosted.org/packages/3e/89/7ea760b4daa42653ece2380531c90f64788d979110a2ab51049d92f408af/packaging-20.9-py2.py3-none-any.whl
postprocessing:
  - $type: unpack_archive
    format: zip
    file: transformers-4.8.2-py3-none-any.whl
  - $type: unpack_archive
    format: zip
    file: packaging-20.9-py2.py3-none-any.whl
  - $type: regex_replace
    file: transformers/__init__.py
    pattern: 'from . import dependency_versions_check'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/deepspeed.py
    pattern: 'from .dependency_versions_check import dep_version_check'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: 'from tqdm.auto import tqdm'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: from filelock import FileLock
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: from huggingface_hub import HfApi, HfFolder, Repository
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: return HfApi\(endpoint=HUGGINGFACE_CO_RESOLVE_ENDPOINT\)\.create_repo\(\n.*\n.*\n.*\n.*\n.*\n.*\n+.*\)
    replacement: 'return None'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: 'repo = Repository\(repo_path_or_name, clone_from=repo_url, use_auth_token=use_auth_token\)'
    replacement: 'repo = None'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: 'def _push_to_hub\(cls, repo\: Repository, commit_message\: Optional\[str\]
      = None\) -> str\:'
    replacement: 'def _push_to_hub(cls, repo, commit_message: Optional[str] = None)
      -> str:'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: '-> Repository\:'
    replacement: ':'
conversion_to_onnx_args:
  - --model-path=$dl_dir
  - --model-path=$config_dir
  - --model-name=create_model
  - --import-module=model
  - --model-param=model_dir=r"$dl_dir/wav2vec2-base-960h"
  - --input-names=inputs
  - --output-names=logits
  - --input-shapes=[1,30480]
  - --output-file=$conv_dir/wav2vec2-base.onnx
  - '--conversion-param=dynamic_axes={"inputs": {0: "batch_size", 1: "sequence_len"},
    "logits": {0: "batch_size", 1: "sequence_len"}}'
input_info:
  - name: inputs
    shape: [1, 30480]
    layout: NS
model_optimizer_args:
  - --input_model=$conv_dir/wav2vec2-base.onnx
  - --output=logits
framework: pytorch
license: https://raw.githubusercontent.com/pytorch/fairseq/master/LICENSE

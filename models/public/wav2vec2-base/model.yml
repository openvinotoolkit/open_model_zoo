# Copyright (c) 2021 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  "bert-base-ner" is a fine-tuned BERT model that is ready to use for Named Entity
  Recognition and achieves state-of-the-art performance for the NER task. It has been
  trained to recognize four types of entities: location (LOC), organizations (ORG),
  person (PER) and Miscellaneous (MISC).

  Specifically, this model is a bert-base-cased model that was fine-tuned on the English
  version of the standard CoNLL-2003 Named Entity Recognition <https://www.aclweb.org/anthology/W03-0419.pdf>
  dataset. For details about the original model, check out BERT: Pre-training of Deep
  Bidirectional Transformers for Language Understanding <https://arxiv.org/abs/1810.04805>,
  HuggingFace's Transformers: State-of-the-art Natural Language Processing <https://arxiv.org/abs/1910.03771>
  papers and repository <https://github.com/huggingface/transformers>

  Tokenization occurs using the BERT tokenizer (see the demo code for implementation
  details) and the enclosed "vocab.txt" dictionary file.
task_type: named_entity_recognition
files:
  - name: transformers-4.8.2-py3-none-any.whl
    size: 2499371
    sha256: a81a7683013fb48690c47e4e2d12a6c6e744b4261ae085f9a98d09f6c3e61d98
    source: https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl
  - name: wav2vec2-base-960h/pytorch_model.bin
    size: 377667514
    sha256: c34f9827b034a1b9141dbf6f652f8a60eda61cdf5771c9e05bfa99033c92cd96
    source: https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin
  - name: wav2vec2-base-960h/config.json
    size: 1596
    sha256: d3ec255c063d9f95057b553b19c20135b259875834a4fe9deb218a6be25b4cf3
    source: https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/config.json
  - name: wav2vec2-base-960h/vocab.json
    size: 291
    sha256: 19727f8944fe6459fc3f240ae2c198395b740f6a029bd23e06656266b83bcf64
    source: https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/vocab.json
  - name: packaging-20.9-py2.py3-none-any.whl
    size: 40870
    sha256: 67714da7f7bc052e064859c05c595155bd1ee9f69f76557e21f051443c20947a
    source: https://files.pythonhosted.org/packages/3e/89/7ea760b4daa42653ece2380531c90f64788d979110a2ab51049d92f408af/packaging-20.9-py2.py3-none-any.whl
postprocessing:
  - $type: unpack_archive
    format: zip
    file: transformers-4.8.2-py3-none-any.whl
  - $type: unpack_archive
    format: zip
    file: packaging-20.9-py2.py3-none-any.whl
  - $type: regex_replace
    file: transformers/__init__.py
    pattern: 'from . import dependency_versions_check'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/deepspeed.py
    pattern: 'from .dependency_versions_check import dep_version_check'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: 'from tqdm.auto import tqdm'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: from filelock import FileLock
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: from huggingface_hub import HfApi, HfFolder, Repository
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: return HfApi\(endpoint=HUGGINGFACE_CO_RESOLVE_ENDPOINT\)\.create_repo\(\n.*\n.*\n.*\n.*\n.*\n.*\n+.*\)
    replacement: 'return None'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: 'repo = Repository\(repo_path_or_name, clone_from=repo_url, use_auth_token=use_auth_token\)'
    replacement: 'repo = None'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: 'def _push_to_hub\(cls, repo\: Repository, commit_message\: Optional\[str\] = None\) -> str\:'
    replacement: 'def _push_to_hub(cls, repo, commit_message: Optional[str] = None) -> str:'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: '-> Repository\:'
    replacement: ':'
conversion_to_onnx_args:
  - --model-path=$dl_dir
  - --model-path=$config_dir
  - --model-name=create_model
  - --import-module=model
  - --model-param=model_dir=r"$dl_dir/wav2vec2-base-960h"
  - --input-names=inputs
  - --output-names=logits
  - --input-shapes=[1,30480]
  - --output-file=$conv_dir/wav2vec2-base.onnx
  - '--conversion-param=dynamic_axes={"inputs": {0: "batch_size", 1: "sequence_len"}, "logits": {0: "batch_size", 1: "sequence_len"}}'
model_optimizer_args:
  - --input_shape=[1,30480]
  - --input=inputs
  - --input_model=$conv_dir/wav2vec2-base.onnx
  - --output=logits
framework: pytorch
quantizable: yes
license: https://raw.githubusercontent.com/pytorch/fairseq/master/LICENSE

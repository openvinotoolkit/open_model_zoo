models:
  - name: efficientnet-b5-pytorch

    launchers:
      - framework: onnx_runtime
        model: public/efficientnet-b5-pytorch/efficientnet-b5-pytorch.onnx
        adapter: classification
        inputs:
          - name: data
            type: INPUT
            shape: 1,3,456,456

    datasets:
      - name: imagenet_1000_classes
        reader: pillow_imread

        preprocessing:
          - type: resize
            size: 488
            aspect_ratio_scale: greater
            use_pillow: True
            interpolation: BICUBIC
            # Crop ratio 0.934
          - type: crop
            use_pillow: True
            size: 456

          - type: normalization
            mean: (123.675,116.28,103.53)
            std: (58.395,57.12,57.375)

  - name: efficientnet-b5-pytorch

    launchers:
      - framework: dlsdk
        tags:
          - FP32
        model:   public/efficientnet-b5-pytorch/FP32/efficientnet-b5-pytorch.xml
        weights: public/efficientnet-b5-pytorch/FP32/efficientnet-b5-pytorch.bin
        adapter: classification

      - framework: dlsdk
        tags:
          - FP16
        model:   public/efficientnet-b5-pytorch/FP16/efficientnet-b5-pytorch.xml
        weights: public/efficientnet-b5-pytorch/FP16/efficientnet-b5-pytorch.bin
        adapter: classification

    datasets:
      - name: imagenet_1000_classes
        reader: pillow_imread

        preprocessing:
          - type: rgb_to_bgr

          - type: resize
            size: 488
            aspect_ratio_scale: greater
            use_pillow: True
            interpolation: BICUBIC
            # Crop ration 0.934
          - type: crop
            use_pillow: True
            size: 456

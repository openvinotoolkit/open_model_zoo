# Overview of OpenVINO&trade; Toolkit Public Pre-Trained Models

@sphinxdirective

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Device Support
   
   omz_models_public_device_support


.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Action Recognition Models
   
   omz_models_model_common_sign_language_0001
   omz_models_model_i3d_rgb_tf

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Classification Models
   
   omz_models_model_alexnet
   omz_models_model_anti_spoof_mn3
   omz_models_model_caffenet
   omz_models_model_densenet_121
   omz_models_model_densenet_121_caffe2
   omz_models_model_densenet_121_tf
   omz_models_model_densenet_161
   omz_models_model_densenet_161_tf
   omz_models_model_densenet_169
   omz_models_model_densenet_169_tf
   omz_models_model_densenet_201
   omz_models_model_densenet_201_tf
   omz_models_model_dla_34
   omz_models_model_efficientnet_b0
   omz_models_model_efficientnet_b0_pytorch
   omz_models_model_efficientnet_b0_auto_aug
   omz_models_model_efficientnet_b5
   omz_models_model_efficientnet_b5_pytorch
   omz_models_model_efficientnet_b7_pytorch
   omz_models_model_efficientnet_b7_auto_aug
   omz_models_model_googlenet_v1
   omz_models_model_googlenet_v1_tf
   omz_models_model_googlenet_v2
   omz_models_model_googlenet_v2_tf
   omz_models_model_googlenet_v3
   omz_models_model_googlenet_v3_pytorch
   omz_models_model_googlenet_v4_tf
   omz_models_model_hbonet_0_25
   omz_models_model_hbonet_0_5
   omz_models_model_hbonet_1_0
   omz_models_model_inception_resnet_v2_tf
   omz_models_model_mixnet_l
   omz_models_model_mobilenet_v1_0_25_128
   omz_models_model_mobilenet_v1_0_50_160
   omz_models_model_mobilenet_v1_0_50_224
   omz_models_model_mobilenet_v1_1_0_224
   omz_models_model_mobilenet_v1_1_0_224_tf
   omz_models_model_mobilenet_v2
   omz_models_model_mobilenet_v2_1_0_224
   omz_models_model_mobilenet_v2_1_4_224
   omz_models_model_mobilenet_v2_pytorch
   omz_models_model_mobilenet_v3_large_1_0_224_tf
   omz_models_model_mobilenet_v3_small_1_0_224_tf
   omz_models_model_nfnet_f0
   omz_models_model_octave_densenet_121_0_125
   omz_models_model_octave_resnet_101_0_125
   omz_models_model_octave_resnet_200_0_125
   omz_models_model_octave_resnet_26_0_25
   omz_models_model_octave_resnet_50_0_125
   omz_models_model_octave_resnext_101_0_25
   omz_models_model_octave_resnext_50_0_25
   omz_models_model_octave_se_resnet_50_0_125
   omz_models_model_open_closed_eye_0001
   omz_models_model_regnetx_3_2gf
   omz_models_model_repvgg_a0
   omz_models_model_repvgg_b1
   omz_models_model_repvgg_b3
   omz_models_model_resnest_50_pytorch
   omz_models_model_resnet_18_pytorch
   omz_models_model_resnet_34_pytorch
   omz_models_model_resnet_50_caffe2
   omz_models_model_resnet_50_pytorch
   omz_models_model_resnet_50_tf
   omz_models_model_rexnet_v1_x1_0
   omz_models_model_se_inception
   omz_models_model_se_resnet_101
   omz_models_model_se_resnet_152
   omz_models_model_se_resnet_50
   omz_models_model_se_resnext_101
   omz_models_model_se_resnext_50
   omz_models_model_shufflenet_v2_x1_0
   omz_models_model_squeezenet1_0
   omz_models_model_squeezenet1_1
   omz_models_model_squeezenet1_1_caffe2
   omz_models_model_vgg16
   omz_models_model_vgg19
   omz_models_model_vgg19_caffe2

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Colorization Models
   
   omz_models_model_colorization_siggraph
   omz_models_model_colorization_v2

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Face Recognition Models
   
   omz_models_model_face_recognition_resnet100_arcface_onnx
   omz_models_model_facenet_20180408_102900
   omz_models_model_Sphereface

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Human Pose Estimation Models
   
   omz_models_model_higher_hrnet_w32_human_pose_estimation
   omz_models_model_human_pose_estimation_3d_0001
   omz_models_model_single_human_pose_estimation_0001

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Image Inpainting Models
   
   omz_models_model_gmcnn_places2_tf

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Image Processing Models
   
   omz_models_model_deblurgan_v2

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Image Translation Models
   
   omz_models_model_cocosnet

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Instance Segmentation Models
   
   omz_models_model_mask_rcnn_inception_resnet_v2_atrous_coco
   omz_models_model_mask_rcnn_inception_v2_coco
   omz_models_model_mask_rcnn_resnet101_atrous_coco
   omz_models_model_mask_rcnn_resnet50_atrous_coco
   omz_models_model_yolact_resnet50_fpn_pytorch

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Monocular Depth Estimation Models
   
   omz_models_model_fcrn_dp_nyu_depth_v2_tf
   omz_models_model_midasnet

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Named Entity Recognition Models
   
   omz_models_model_bert_base_ner

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Object Attribute Estimation Models
   
   omz_models_model_vehicle_reid_0001

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Object Detection Models
   
   omz_models_model_ctdet_coco_dlav0_384
   omz_models_model_ctdet_coco_dlav0_512
   omz_models_model_ctpn
   omz_models_model_efficientdet_d0_tf
   omz_models_model_efficientdet_d1_tf
   omz_models_model_face_detection_retail_0044
   omz_models_model_faceboxes_pytorch
   omz_models_model_faster_rcnn_inception_resnet_v2_atrous_coco
   omz_models_model_faster_rcnn_inception_v2_coco
   omz_models_model_faster_rcnn_resnet101_coco
   omz_models_model_faster_rcnn_resnet50_coco
   omz_models_model_mobilefacedet_v1_mxnet
   omz_models_model_mobilenet_ssd
   omz_models_model_mtcnn
   omz_models_model_pelee_coco
   omz_models_model_retinaface_resnet50_pytorch
   omz_models_model_retinanet_tf
   omz_models_model_rfcn_resnet101_coco_tf
   omz_models_model_ssd_resnet34_1200_onnx
   omz_models_model_ssd300
   omz_models_model_ssd512
   omz_models_model_ssd_mobilenet_v1_coco
   omz_models_model_ssd_mobilenet_v1_fpn_coco
   omz_models_model_ssd_mobilenet_v2_coco
   omz_models_model_ssd_resnet50_v1_fpn_coco
   omz_models_model_ssdlite_mobilenet_v2
   omz_models_model_ultra_lightweight_face_detection_rfb_320
   omz_models_model_ultra_lightweight_face_detection_slim_320
   omz_models_model_vehicle_license_plate_detection_barrier_0123
   omz_models_model_yolo_v1_tiny_tf
   omz_models_model_yolo_v2_tf
   omz_models_model_yolo_v2_tiny_tf
   omz_models_model_yolo_v3_tf
   omz_models_model_yolo_v3_tiny_tf
   omz_models_model_yolo_v4_tf
   omz_models_model_yolo_v4_tiny_tf

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Optical Character Recognition Models
   
   omz_models_model_license_plate_recognition_barrier_0007
   omz_models_model_text_recognition_resnet_fc

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Place Recognition Models
   
   omz_models_model_netvlad_tf

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Salient Object Detection Models
   
   omz_models_model_f3net

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Semantic Segmentation Models
   
   omz_models_model_brain_tumor_segmentation_0001
   omz_models_model_brain_tumor_segmentation_0002
   omz_models_model_deeplabv3
   omz_models_model_fastseg_large
   omz_models_model_fastseg_small
   omz_models_model_hrnet_v2_c1_segmentation
   omz_models_model_pspnet_pytorch

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Sound Classification Models
   
   omz_models_model_aclnet
   omz_models_model_aclnet_int8

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Speech Recognition Models
   
   omz_models_model_mozilla_deepspeech_0_6_1
   omz_models_model_mozilla_deepspeech_0_8_2
   omz_models_model_quartznet_15x5_en

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Style Transfer Models
   
   omz_models_model_fast_neural_style_mosaic_onnx

.. toctree::
   :maxdepth: 1
   :hidden:
   :caption: Text-to-speech Models
   
   omz_models_model_forward_tacotron
   omz_models_model_wavernn


.. raw:: html

   <script>
      window.TABLE_SORT = true;
   </script>

@endsphinxdirective

OpenVINO&trade; toolkit provides a set of public pre-trained models
that you can use for learning and demo purposes or for developing deep learning
software. Most recent version is available in the [repo on Github](https://github.com/openvinotoolkit/open_model_zoo).
The table [Public Pre-Trained Models Device Support](./device_support.md) summarizes devices supported by each model.

You can download models and convert them into Inference Engine format (\*.xml + \*.bin) using the OpenVINOâ„¢ [Model Downloader](../../tools/downloader/README.md) and other automation tools.

## Classification 
| Model Name <br> Model Version                                            						| Implementation    | Top 1 <br> Accuracy | Top 5 <br> Accuracy | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ------------------- | ------------------- | ------ | ------- |
| AlexNet <br> [alexnet](./alexnet/README.md)                              						| Caffe             | 56.60%              | 79.81%              | 1.5    | 60.965  |    
| AntiSpoofNet <br> [anti-spoof-mn3](./anti-spoof-mn3/README.md)           						| PyTorch           | 3.81%               |                     | 0.15   | 3.02    |                                                
| CaffeNet <br> [caffenet](./caffenet/README.md)                           						| Caffe             | 56.71%              | 79.91%              | 1.5    | 60.965  |   
| DenseNet 121 <br> [densenet-121](./densenet-121/README.md)               						| Caffe             | 74.42%              | 92.14%              | 5.724  | 7.971   |
| DenseNet 121 <br> [densenet-121-tf](./densenet-121-tf/README.md)         						| TensorFlow        | 74.46%              | 92.13%              | 5.7287 | 7.9714  |
| DenseNet 121 <br> [densenet-121-caffe2](./densenet-121-caffe2/README.md)          			| Caffe2            | 74.90%              | 92.19%              | 5.723  | 7.971   |
| DenseNet 161 <br> [densenet-161](./densenet-161/README.md)   		    						| Caffe             | 77.55%              | 93.92%              | 15.561 | 28.666  |
| DenseNet 161 <br> [densenet-161-tf](./densenet-161-tf/README.md)              				| TensorFlow        | 76.45%              | 93.23%              | 14.128 | 28.666  |
| DenseNet 169 <br> [densenet-169](./densenet-169/README.md)      		    					| Caffe             | 76.11%       		  | 93.11%              | 6.788  | 14.139  |
| DenseNet 169 <br> [densenet-169-tf](./densenet-169-tf/README.md)           					| TensorFlow        | 76.14%              | 93.12%              | 6.7932 | 14.1389 |
| DenseNet 201 <br> [densenet-201](./densenet-201/README.md)      		  		    			| Caffe             | 76.89%              | 93.56%              | 8.673  | 20.001  |
| DenseNet 201 <br> [densenet-201-tf](./densenet-201-tf/README.md)            					| TensorFlow        | 76.93%              | 93.56%              | 8.6786 | 20.0013 |
| DLA 34 <br> [dla-34](./dla-34/README.md)                                       				| PyTorch           | 74.64%              | 92.06%              | 6.1368 | 15.7344 |
| EfficientNet B0 <br> [efficientnet-b0](./efficientnet-b0/README.md)          					| TensorFlow        | 75.70%              | 92.76%              | 0.819  | 5.268   |
| EfficientNet B0 <br> [efficientnet-b0-pytorch](./efficientnet-b0-pytorch/README.md)			| PyTorch           | 76.91%              | 93.21%              | 0.819  | 5.268   |
| EfficientNet B0 AutoAugment <br> [efficientnet-b0_auto_aug](./efficientnet-b0_auto_aug/README.md)| TensorFlow     | 76.43%              | 93.04%              | 0.819  | 5.268   |
| EfficientNet B5 <br> [efficientnet-b5](./efficientnet-b5/README.md)   						| TensorFlow        | 83.33%              | 96.67%              | 21.252 | 30.303  |
| EfficientNet B5 <br> [efficientnet-b5-pytorch](./efficientnet-b5-pytorch/README.md)      		| PyTorch           | 83.69%              | 96.71%              | 21.252 | 30.303  |
| EfficientNet B7 <br> [efficientnet-b7-pytorch](./efficientnet-b7-pytorch/README.md)    		| PyTorch           | 84.42%              | 96.91%              | 77.618 | 66.193  |
| EfficientNet B7 AutoAugment <br> [efficientnet-b7_auto_aug](./efficientnet-b7_auto_aug/README.md) | TensorFlow    | 84.68%              | 97.09%              | 77.618 | 66.193  |
| HBONet 1.0 <br> [hbonet-1.0](./hbonet-1.0/README.md)                     		    			| PyTorch           | 73.10%              | 91.00%              | 0.6208 | 4.5443  |
| HBONet 0.5 <br> [hbonet-0.5](./hbonet-0.5/README.md)               		   					| PyTorch           | 67.00%              | 86.90%              | 0.1977 | 2.5287  |
| HBONet 0.25 <br> [hbonet-0.25](./hbonet-0.25/README.md)                   		    		| PyTorch           | 57.30%              | 79.80%              | 0.0758 | 1.9299  |
| Inception (GoogleNet) V1 <br> [googlenet-v1](./googlenet-v1/README.md)          		    	| Caffe             | 68.93%              | 89.14%              | 3.266  | 6.999   |
| Inception (GoogleNet) V1 <br> [googlenet-v1-tf](./googlenet-v1-tf/README.md)            		| TensorFlow        | 69.81%              | 89.60%              | 3.016  | 6.619   |
| Inception (GoogleNet) V2 <br> [googlenet-v2](./googlenet-v2/README.md)            		    | Caffe             | 72.02%              | 90.84%              | 4.058  | 11.185  |
| Inception (GoogleNet) V2 <br> [googlenet-v2-tf](./googlenet-v2-tf/README.md)            		| TensorFlow        | 74.09%              | 91.80%              | 4.058  | 11.185  |
| Inception (GoogleNet) V3 <br> [googlenet-v3](./googlenet-v3/README.md)            		    | TensorFlow        | 77.90%              | 93.81%              | 11.469 | 23.819  |
| Inception (GoogleNet) V3 <br> [googlenet-v3-pytorch](./googlenet-v3-pytorch/README.md)        | PyTorch           | 77.69%              | 93.70%              | 11.469 | 23.817  |
| Inception (GoogleNet) V4 <br> [googlenet-v4-tf](./googlenet-v4-tf/README.md)      		    | TensorFlow        | 80.20%              | 95.21%              | 24.584 | 42.648  |
| Inception-ResNet V2 <br> [inception-resnet-v2-tf](./inception-resnet-v2-tf/README.md)         | TensorFlow        | 80.14%              | 95.10%              | 22.227 | 30.223  |
| MixNet L <br> [mixnet-l](./mixnet-l/README.md)              		    						| TensorFlow        | 78.30%              | 93.91%              | 0.565  | 7.3     |
| MobileNet V1 0.25 128 <br> [mobilenet-v1-0.25-128](./mobilenet-v1-0.25-128/README.md)    		| Caffe             | 40.54%              | 65.00%              | 0.028  | 0.468   |
| MobileNet V1 0.5 160 <br> [mobilenet-v1-0.50-160](./mobilenet-v1-0.50-160/README.md)     		| Caffe             | 59.86%              | 82.04%              | 0.156  | 1.327   |
| MobileNet V1 0.5 224 <br> [mobilenet-v1-0.50-224](./mobilenet-v1-0.50-224/README.md)      	| Caffe             | 63.04%              | 84.93%              | 0.304  | 1.327   |
| MobileNet V1 1.0 224 <br> [mobilenet-v1-1.0-224](./mobilenet-v1-1.0-224/README.md)   			| Caffe             | 69.50%              | 89.22%              | 1.148  | 4.221   |
| MobileNet V1 1.0 224 <br> [mobilenet-v1-1.0-224-tf](./mobilenet-v1-1.0-224-tf/README.md)		| TensorFlow        | 71.03%              | 89.94%              | 1.148  | 4.221   |
| MobileNet V2 1.0 224 <br> [mobilenet-v2](./mobilenet-v2/README.md)	    					| Caffe             | 71.22%              | 90.18%              | 0.876  | 3.489   |
| MobileNet V2 1.0 224 <br> [mobilenet-v2-1.0-224](./mobilenet-v2-1.0-224/README.md)         	| TensorFlow        | 71.85%              | 90.69%              | 0.615  | 3.489   |
| MobileNet V2 1.0 224 <br> [mobilenet-v2-pytorch](./mobilenet-v2-pytorch/README.md)   			| PyTorch           | 71.90%     		  | 90.30%              | 0.615  | 3.489   |
| MobileNet V2 1.4 224 <br> [mobilenet-v2-1.4-224](./mobilenet-v2-1.4-224/README.md)	    	| TensorFlow        | 74.09%              | 91.97%              | 1.183  | 6.087   |
| MobileNet V3 Small 1.0 <br> [mobilenet-v3-small-1.0-224-tf](./mobilenet-v3-small-1.0-224-tf/README.md)| TensorFlow| 67.36%              | 87.45%              | 0.121  | 2.537   |
| MobileNet V3 Large 1.0 <br> [mobilenet-v3-large-1.0-224-tf](./mobilenet-v3-large-1.0-224-tf/README.md)| TensorFlow| 75.70%              | 92.76%              | 0.4536 | 5.4721  |
| NFNet F0 <br> [nfnet-f0](./nfnet-f0/README.md)           		    							| PyTorch           | 83.34%              | 96.56%              | 24.8053| 71.4444 |
| DenseNet 121, alpha=0.125 <br> [octave-densenet-121-0.125](./octave-densenet-121-0.125/README.md)| MXNet          | 76.07%              | 93.05%              | 4.883  | 7.977   |
| RegNetX-3.2GF <br> [regnetx-3.2gf](./regnetx-3.2gf/README.md)      		    				| PyTorch           | 78.17%              | 94.08%              | 6.3893 | 15.2653 |
| ResNet 26, alpha=0.25 <br> [octave-resnet-26-0.25](./octave-resnet-26-0.25/README.md)         | MXNet             | 76.08%              | 92.58%              | 3.768  | 15.99   |
| ResNet 50, alpha=0.125 <br> [octave-resnet-50-0.125](./octave-resnet-50-0.125/README.md)	    | MXNet             | 78.19%              | 93.86%              | 7.221  | 25.551  |
| ResNet 101, alpha=0.125 <br> [octave-resnet-101-0.125](./octave-resnet-101-0.125/README.md)	| MXNet             | 79.18%              | 94.42%              | 13.387 | 44.543  |
| ResNet 200, alpha=0.125 <br> [octave-resnet-200-0.125](./octave-resnet-200-0.125/README.md)	| MXNet             | 79.99%              | 94.87%              | 25.407 | 64.667  |
| ResNeXt 50, alpha=0.25 <br> [octave-resnext-50-0.25](./octave-resnext-50-0.25/README.md)		| MXNet             | 78.77%              | 94.18%              | 6.444  | 25.02   |
| ResNeXt 101, alpha=0.25 <br> [octave-resnext-101-0.25](./octave-resnext-101-0.25/README.md) 	| MXNet             | 79.56%              | 94.44%              | 11.521 | 44.169  |
| SE-ResNet 50, alpha=0.125 <br> [octave-se-resnet-50-0.125](./octave-se-resnet-50-0.125/README.md)| MXNet          | 78.71%              | 94.09%              | 7.246  | 28.082  |
| open-closed-eye-0001 <br> [open-closed-eye-0001](./open-closed-eye-0001/README.md)    		| PyTorch           | 95.84%              |                     | 0.0014 | 0.0113  |
| RepVGG A0 <br> [repvgg-a0](./repvgg-a0/README.md)             		    					| PyTorch           | 72.40%              | 90.49%              | 2.7286 | 8.3094  |
| RepVGG B1 <br> [repvgg-b1](./repvgg-b1/README.md)               		    					| PyTorch           | 78.37%              | 94.09%              | 23.6472| 51.8295 |
| RepVGG B3 <br> [repvgg-b3](./repvgg-b3/README.md)                  		    				| PyTorch           | 80.50%              | 95.25%              | 52.4407| 110.9609|
| ResNeSt 50 <br> [resnest-50-pytorch](./resnest-50-pytorch/README.md)     		    			| PyTorch           | 81.11%              | 95.36%              | 10.8148| 27.4493 |
| ResNet 18 <br> [resnet-18-pytorch](./resnet-18-pytorch/README.md)	    						| PyTorch           | 69.75%              | 89.09%              | 3.637  | 11.68   |
| ResNet 34 <br> [resnet-34-pytorch](./resnet-34-pytorch/README.md)  		    				| PyTorch           | 73.30%              | 91.42%              | 7.3409 | 21.7892 |
| ResNet 50 <br> [resnet-50-pytorch](./resnet-50-pytorch/README.md)	    						| PyTorch           | 76.13%              | 92.86%              | 8.216  | 25.53   |
| ResNet 50 <br> [resnet-50-caffe2](./resnet-50-caffe2/README.md)								| Caffe2            | 76.38%              | 93.19%              | 8.216  | 25.53   |
| ResNet 50 <br> [resnet-50-tf](./resnet-50-tf/README.md)     		    						| TensorFlow        | 76.17%        	  | 92.98%        		| 8.2164 | 25.53   |
| ReXNet V1 x1.0 <br> [rexnet-v1-x1.0](./rexnet-v1-x1.0/README.md)               		    	| PyTorch           | 77.86%              | 93.87%              | 0.8325 | 4.7779  |
| SE-Inception <br> [se-inception](./se-inception/README.md)     		    					| Caffe             | 76.00%              | 92.96%              | 4.091  | 11.922  |
| SE-ResNet 50 <br> [se-resnet-50](./se-resnet-50/README.md)            		    			| Caffe             | 77.60%              | 93.85%              | 7.775  | 28.061  |
| SE-ResNet 101 <br> [se-resnet-101](./se-resnet-101/README.md)          		    			| Caffe             | 78.25%              | 94.21%              | 15.239 | 49.274  |
| SE-ResNet 152 <br> [se-resnet-152](./se-resnet-152/README.md)         		    			| Caffe             | 78.51%              | 94.45%              | 22.709 | 66.746  |
| SE-ResNeXt 50 <br> [se-resnext-50](./se-resnext-50/README.md)          		    			| Caffe             | 78.97%              | 94.63%              | 8.533  | 27.526  |
| SE-ResNeXt 101 <br> [se-resnext-101](./se-resnext-101/README.md)           		    		| Caffe             | 80.17%              | 95.19%              | 16.054 | 48.886  |
| Shufflenet V2 x1.0 <br> [shufflenet-v2-x1.0](./shufflenet-v2-x1.0/README.md)       		    | PyTorch           | 69.36%              | 88.32%              | 0.2957 | 2.2705  |
| SqueezeNet v1.0 <br> [squeezenet1.0](./squeezenet1.0/README.md)  		    					| Caffe             | 57.68%              | 80.38%              | 1.737  | 1.248   |
| SqueezeNet v1.1 <br> [squeezenet1.1](./squeezenet1.1/README.md)          		    			| Caffe             | 58.38%              | 81.00%              | 0.785  | 1.236   |
| SqueezeNet v1.1 <br> [squeezenet1.1-caffe2](./squeezenet1.1-caffe2/README.md)          		| Caffe2            | 56.50%              | 79.58%              | 0.785  | 1.236   |
| VGG 16 <br> [vgg16](./vgg16/README.md)                           		    					| Caffe             | 70.97%              | 89.88%              | 30.974 | 138.36  |
| VGG 19 <br> [vgg19](./vgg19/README.md)                 		    							| Caffe             | 71.06%              | 89.83%              | 39.3   | 143.667 |
| VGG 19 <br> [vgg19-caffe2](./vgg19-caffe2/README.md)                          		    	| Caffe2            | 71.06%              | 89.83%              | 39.3   | 143.667 |


## Semantic Segmentation
| Model Name <br> Model Version                                            						| Implementation    | Accuracy 			  | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ------------------- | ------ | ------- |
| DeepLab V3 <br> [deeplabv3](./deeplabv3/README.md)											| TensorFlow        | 66.85%              | 11.469 | 23.819  |    
| HRNet V2 C1 Segmentation <br> [hrnet-v2-c1-segmentation](./hrnet-v2-c1-segmentation/README.md)| PyTorch           | 77.69%              | 81.993 | 66.4768 |    
| Fastseg MobileV3Large LR-ASPP, F=128 <br> [fastseg-large](./fastseg-large/README.md)			| PyTorch           | 72.67%              |140.9611| 3.2     |    
| Fastseg MobileV3Small LR-ASPP, F=128 <br> [fastseg-small](./fastseg-small/README.md)			| PyTorch           | 67.15%              | 69.2204| 1.1     |    
| PSPNet R-50-D8 <br> [pspnet-pytorch](./pspnet-pytorch/README.md)								| PyTorch           | 70.60%              |357.1719| 46.5827 |    


## Instance Segmentation
| Model Name <br> Model Version                                            						| Implementation    | Accuracy <br> Metric 1  | Accuracy <br> Metric 2 | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ----------------------- | ---------------------- | ------ | ------- |
| Mask R-CNN Inception ResNet V2 <br> [mask_rcnn_inception_resnet_v2_atrous_coco](./mask_rcnn_inception_resnet_v2_atrous_coco/README.md)| TensorFlow|39.86%|35.36%     | 675.314| 92.368  |   
| Mask R-CNN Inception V2 <br> [mask_rcnn_inception_v2_coco](./mask_rcnn_inception_v2_coco/README.md)      | TensorFlow | 27.12%              | 21.48%                 | 54.926 | 21.772  |    
| Mask R-CNN ResNet 50 <br> [mask_rcnn_resnet50_atrous_coco](./mask_rcnn_resnet50_atrous_coco/README.md)   | TensorFlow	| 29.75%              | 27.46%                 | 294.738| 50.222  |    
| Mask R-CNN ResNet 101 <br> [mask_rcnn_resnet101_atrous_coco](./mask_rcnn_resnet101_atrous_coco/README.md)| TensorFlow	| 34.92%              | 31.30%                 | 674.58 | 69.188  |    
| YOLACT ResNet 50 FPN <br> [yolact-resnet50-fpn-pytorch](./yolact-resnet50-fpn-pytorch/README.md)         | PyTorch    | 28.00%              | 30.69%                 | 118.575| 36.829  |    


## 3D Semantic Segmentation
| Model Name <br> Model Version                                            						| Implementation    | Mean <br> Accuracy  | Median <br> Accuracy| GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ------------------- | ------------------- | ------ | ------- |
| Brain Tumor Segmentation <br> [brain-tumor-segmentation-0001](./brain-tumor-segmentation-0001/README.md)| MXNet   | 92.40%              |  93.17%             | 409.996| 38.192  |    
| Brain Tumor Segmentation 2 <br> [brain-tumor-segmentation-0002](./brain-tumor-segmentation-0002/README.md)|PyTorch| 91.48%              |  92.70%             | 300.801| 4.51    |    

## Object Detection
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| CTPN <br> [ctpn](./ctpn/README.md)															| TensorFlow        | 73.67%                 | 55.813 | 17.237  |    
| CenterNet (CTDET with DLAV0) 384x384 <br> [ctdet_coco_dlav0_384](./ctdet_coco_dlav0_384/README.md)| ONNX          | 41.61%                 | 34.994 | 17.911  |    
| CenterNet (CTDET with DLAV0) 512x512 <br> [ctdet_coco_dlav0_512](./ctdet_coco_dlav0_512/README.md)| ONNX          | 44.28%                 | 62.211 | 17.911  |    
| EfficientDet-D0 <br> [efficientdet-d0-tf](./efficientdet-d0-tf/README.md)						| TensorFlow        | 31.95%                 | 2.54   | 3.9     |    
| EfficientDet-D1 <br> [efficientdet-d1-tf](./efficientdet-d1-tf/README.md)						| TensorFlow        | 37.54%                 | 6.1    | 6.6     |    
| FaceBoxes <br> [faceboxes-pytorch](./faceboxes-pytorch/README.md)						        | PyTorch           | 83.57%                 | 1.8975 | 1.0059  |    
| Face Detection Retail <br> [face-detection-retail-0044](./face-detection-retail-0044/README.md)| Caffe            | 83.00%                 | 1.067  | 0.588   |    
| Faster R-CNN with Inception-ResNet v2 <br> [faster_rcnn_inception_resnet_v2_atrous_coco](./faster_rcnn_inception_resnet_v2_atrous_coco/README.md)|TensorFlow| 40.69% | 30.687 |13.307|    
| Faster R-CNN with Inception v2 <br> [faster_rcnn_inception_v2_coco](./faster_rcnn_inception_v2_coco/README.md)| TensorFlow | 26.24%        | 30.687 | 13.307  |    
| Faster R-CNN with ResNet 50 <br> [faster_rcnn_resnet50_coco](./faster_rcnn_resnet50_coco/README.md)| TensorFlow   | 31.09%                 | 57.203 | 29.162  |    
| Faster R-CNN with ResNet 101 <br> [faster_rcnn_resnet101_coco](./faster_rcnn_resnet101_coco/README.md)| TensorFlow| 35.72%                 | 112.052| 48.128  |    
| MobileFace Detection V1 <br> [mobilefacedet-v1-mxnet](./mobilefacedet-v1-mxnet/README.md)     | MXNet             | 78.75%                 | 3.5456 | 7.6828  |    
| MTCNN <br> [mtcnn](./mtcnn/README.md) (mtcnn-p)												| Caffe             | 62.26%                 | 3.366  | 0.007   |    
| MTCNN <br> [mtcnn](./mtcnn/README.md) (mtcnn-r)												| Caffe             | 62.26%                 | 0.003  | 0.1     |    
| MTCNN <br> [mtcnn](./mtcnn/README.md) (mtcnn-o)												| Caffe             | 62.26%                 | 0.026  | 0.389   |    
| Pelee <br> [pelee-coco](./pelee-coco/README.md)												| Caffe             | 21.98%                 | 1.290  | 5.98    |    
| RetinaFace with ResNet 50 <br> [retinaface-resnet50-pytorch](./retinaface-resnet50-pytorch/README.md)| PyTorch    | 91.78%                 | 88.8627| 27.2646 |    
| RetinaNet with Resnet 50 <br> [retinanet-tf](./retinanet-tf/README.md)						| TensorFlow        | 33.15%                 |238.9469| 64.9706 |    
| R-FCN with Resnet-101 <br> [rfcn-resnet101-coco-tf](./rfcn-resnet101-coco-tf/README.md)		| TensorFlow        | 45.02%                 | 53.462 | 171.85  |    
| SSD 300 <br> [ssd300](./ssd300/README.md)														| Caffe             | 87.09%                 | 62.815 | 26.285  |    
| SSD 512 <br> [ssd512](./ssd512/README.md)														| Caffe             | 91.07%                 | 180.611| 27.189  |    
| SSD with MobileNet <br> [mobilenet-ssd](./mobilenet-ssd/README.md)							| Caffe             | 67.00%                 | 2.316  | 5.783   |    
| SSD with MobileNet <br> [ssd_mobilenet_v1_coco](./ssd_mobilenet_v1_coco/README.md)			| TensorFlow        | 23.32%                 | 2.494  | 6.807   |    
| SSD with MobileNet FPN <br> [ssd_mobilenet_v1_fpn_coco](./ssd_mobilenet_v1_fpn_coco/README.md)| TensorFlow        | 35.55%                 | 123.309| 36.188  |    
| SSD with MobileNet V2 <br> [ssd_mobilenet_v2_coco](./ssd_mobilenet_v2_coco/README.md)			| TensorFlow        | 24.95%                 | 3.775  | 16.818  |    
| SSD lite with MobileNet V2 <br> [ssdlite_mobilenet_v2](./ssdlite_mobilenet_v2/README.md)		| TensorFlow        | 24.29%                 | 1.525  | 4.475   |    
| SSD with ResNet-50 V1 FPN <br> [ssd_resnet50_v1_fpn_coco](./ssd_resnet50_v1_fpn_coco/README.md)| TensorFlow       | 38.46%                 |178.6807| 59.9326 |    
| SSD with ResNet 34 1200x1200 <br> [ssd-resnet34-1200-onnx](./ssd-resnet34-1200-onnx/README.md)| PyTorch           | 39.28%                 | 433.411| 20.058  |    
| Ultra Lightweight Face Detection RFB 320 <br> [ultra-lightweight-face-detection-rfb-320](./ultra-lightweight-face-detection-rfb-320/README.md)   |PyTorch|84.78%|0.2106|0.3004|
| Ultra Lightweight Face Detection slim 320 <br> [ultra-lightweight-face-detection-slim-320](./ultra-lightweight-face-detection-slim-320/README.md)|PyTorch|83.32%|0.1724|0.2844|
| Vehicle License Plate Detection Barrier <br> [vehicle-license-plate-detection-barrier-0123](./vehicle-license-plate-detection-barrier-0123/README.md)|TensorFlow|99.52%|0.271|0.547|    
| YOLO v1 Tiny <br> [yolo-v1-tiny-tf](./yolo-v1-tiny-tf/README.md) 								| TensorFlow.js     | 54.79%                 | 6.9883 | 15.8587 |    
| YOLO v2 Tiny <br> [yolo-v2-tiny-tf](./yolo-v2-tiny-tf/README.md)								| Keras     	    | 29.12%                 | 5.4236 | 11.2295 |    
| YOLO v2 <br> [yolo-v2-tf](./yolo-v2-tf/README.md)												| Keras      	    | 56.48%                 | 63.0301| 50.9526 |    
| YOLO v3 <br> [yolo-v3-tf](./yolo-v3-tf/README.md)												| Keras      	    | 67.72%                 | 65.9843| 61.9221 |    
| YOLO v3 Tiny <br> [yolo-v3-tiny-tf](./yolo-v3-tiny-tf/README.md)								| Keras      	    | 39.70%                 |5.582   | 8.848   |    
| YOLO v4 <br> [yolo-v4-tf](./yolo-v4-tf/README.md)												| Keras      	    | 77.40%                 |129.5567| 64.33   |    
| YOLO v4 Tiny <br> [yolo-v4-tiny-tf](./yolo-v4-tiny-tf/README.md)								| Keras      	    | 0.463%                 | 6.9289 | 6.0535  |    


## Face Recognition
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| FaceNet <br> [facenet-20180408-102900](./facenet-20180408-102900/README.md)					| TensorFlow	    | 99.14%                 | 2.846  | 23.469  |    
| LResNet100E-IR,ArcFace@ms1m-refine-v2 <br> [face-recognition-resnet100-arcface-onnx](./face-recognition-resnet100-arcface-onnx/README.md)| MXNet|99.68%|24.2115|65.1320|    
| SphereFace <br> [Sphereface](./Sphereface/README.md)											| Caffe  	        | 98.83%                 | 3.504  | 22.671  |    


## Human Pose Estimation
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| human-pose-estimation-3d-0001 <br> [human-pose-estimation-3d-0001](./human-pose-estimation-3d-0001/README.md)	| PyTorch |100.45mm          | 18.998 | 5.074   |    
| single-human-pose-estimation-0001 <br> [single-human-pose-estimation-0001](./single-human-pose-estimation-0001/README.md)| PyTorch| 69.05% | 60.125 | 33.165  |    
| higher-hrnet-w32-human-pose-estimation <br> [higher-hrnet-w32-human-pose-estimation](./higher-hrnet-w32-human-pose-estimation/README.md)| PyTorch | 64.64% | 92.8364 | 28.6180 |    


## Monocular Depth Estimation
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| midasnet <br> [midasnet](./midasnet/README.md)												| PyTorch   	    | 0.07071                |207.25144| 104.081|    
| FCRN ResNet50-Upproj <br> [fcrn-dp-nyu-depth-v2-tf](./fcrn-dp-nyu-depth-v2-tf/README.md)		| TensorFlow	    | 0.573                  | 63.5421| 34.5255 |    


## Image Inpainting
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| GMCNN Inpainting <br> [gmcnn-places2-tf](./gmcnn-places2-tf/README.md)						| TensorFlow 	    | 33.47Db                |691.1589| 12.7773 |    


## Style Transfer
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| fast-neural-style-mosaic-onnx <br> [fast-neural-style-mosaic-onnx](./fast-neural-style-mosaic-onnx/README.md)| ONNX |12.04dB               |15.518  |1.679    |   


## Action Recognition
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| RGB-I3D, pretrained on ImageNet <br> [i3d-rgb-tf](./i3d-rgb-tf/README.md)						| TensorFlow	    | 86.01%                 |278.9815| 12.6900 |    
| common-sign-language-0001 <br> [common-sign-language-0001](./common-sign-language-0001/README.md)| PyTorch  	    | 93.58%                 | 4.2269 | 4.1128  |    
 

## Colorization
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| colorization-v2 <br> [colorization-v2](./colorization-v2/README.md)							| PyTorch   	    | 26.99dB                | 83.6045| 32.2360 |    
| colorization-siggraph <br> [colorization-siggraph](./colorization-siggraph/README.md)			| PyTorch   	    | 27.73dB                |150.5441| 34.0511 |    


## Sound Classification
| Model Name <br> Model Version                                            						| Implementation    | Top 1 <br> Accuracy | Top 5 <br> Accuracy | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ------------------- | ------------------- | ------ | ------- |
| ACLNet <br> [aclnet](./aclnet/README.md)														| PyTorch	        | 86%                 | 92%                 | 1.4    | 2.7     |
| ACLNet-int8 <br> [aclnet-int8](./aclnet-int8/README.md)										| PyTorch	        | 87%                 | 93%                 | 1.41   | 2.71    |   


## Speech Recognition
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| DeepSpeech V0.6.1 <br> [mozilla-deepspeech-0.6.1](./mozilla-deepspeech-0.6.1/README.md)       | TensorFlow	    | 7.55%                  | 0.0472 | 47.2    |    
| DeepSpeech V0.8.2 <br> [mozilla-deepspeech-0.8.2](./mozilla-deepspeech-0.8.2/README.md)       | TensorFlow	    | 6.13%                  | 0.0472 | 47.2    |    
| QuartzNet <br> [quartznet-15x5-en](./quartznet-15x5-en/README.md)								| Pytorch   	    | 3.86%                  | 2.4195 | 18.8857 |    


## Image Translation
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops  | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------- | ------- |
| CoCosNet <br> [cocosnet](./cocosnet/README.md)												| PyTorch   	    | 12.93dB                |1080.7032| 167.9141|    


## Optical Character Recognition
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| license-plate-recognition-barrier-0007 <br> [license-plate-recognition-barrier-0007](./license-plate-recognition-barrier-0007/README.md) | TensorFlow | 98% | 0.347 | 1.435 |


## Place Recognition
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| NetVLAD <br> [netvlad-tf](./netvlad-tf/README.md) 											| TensorFlow        | 82.03%                 | 36.6374| 149.0021|


## Deblurring
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| DeblurGAN-v2 <br> [deblurgan-v2](./deblurgan-v2/README.md)  									| PyTorch           | 28.25Db                | 80.8919| 2.1083  |

## Salient object detection
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| F3Net <br> [f3net](./f3net/README.md)        													| PyTorch           | 84.21%                 | 31.2883| 25.2791 |


## Text Recognition
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| Resnet-FC <br> [text-recognition-resnet-fc](./text-recognition-resnet-fc/README.md)    		| PyTorch           | 90.94%                 | 40.3704| 177.9668|

## Text to Speech
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| ForwardTacotron <br> [forward-tacotron-duration-prediction](./forward-tacotron/README.md)     | PyTorch           |  						 | 6.66   | 13.81   |
| ForwardTacotron <br> [forward-tacotron-regression](./forward-tacotron/README.md)              | PyTorch           |  						 | 4.91   | 3.05    |
| WaveRNN <br> [wavernn-upsampler](./wavernn/README.md)    										| PyTorch           |						 | 0.37   | 0.4     |
| WaveRNN <br> [wavernn-rnn](./wavernn/README.md)     											| PyTorch           |						 | 0.06   | 3.83    |


## Named Entity Recognition
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| bert-base-NER <br> [bert-base-ner](./bert-base-ner/README.md) 								| PyTorch	        | 94.45%                 | 22.3874| 107.4319|


## Vehicle Reidentification
| Model Name <br> Model Version                                            						| Implementation    | Accuracy               | GFlops | mParams |
| ---------------------------------------------------------------------------------------------	| ----------------- | ---------------------- | ------ | ------- |
| vehicle-reid-0001 <br> [vehicle-reid-0001](./vehicle-reid-0001/README.md)						| PyTorch	        | 96.31%                 | 2.643  | 2.183   |



## See Also
* [Open Model Zoo Demos](../../demos/README.md)
* [Model Downloader](../../tools/downloader/README.md)
* [Overview of OpenVINO&trade; Toolkit Intel's Pre-Trained Models](../intel/index.md)



## Legal Information
Caffe, Caffe2, Keras, MXNet, PyTorch, and TensorFlow are trademarks or brand names of their respective owners.
All company, product and service names used in this website are for identification purposes only.
Use of these names,trademarks and brands does not imply endorsement.

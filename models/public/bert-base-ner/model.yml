# Copyright (c) 2022-2023 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  "bert-base-ner" is a fine-tuned BERT model that is ready to use for Named Entity
  Recognition and achieves state-of-the-art performance for the NER task. It has been
  trained to recognize four types of entities: location (LOC), organizations (ORG),
  person (PER) and Miscellaneous (MISC).

  Specifically, this model is a bert-base-cased model that was fine-tuned on the English
  version of the standard CoNLL-2003 Named Entity Recognition <https://www.aclweb.org/anthology/W03-0419.pdf>
  dataset. For details about the original model, check out BERT: Pre-training of Deep
  Bidirectional Transformers for Language Understanding <https://arxiv.org/abs/1810.04805>,
  HuggingFace's Transformers: State-of-the-art Natural Language Processing <https://arxiv.org/abs/1910.03771>
  papers and repository <https://github.com/huggingface/transformers>

  Tokenization occurs using the BERT tokenizer (see the demo code for implementation
  details) and the enclosed "vocab.txt" dictionary file.
task_type: named_entity_recognition
files:
  - name: transformers-4.5.1-py3-none-any.whl
    size: 2060589
    checksum: e9cb161eef172deac1068d491ed9f7918f5aaa087c9170f8d6356924ade6fd3f2be580c47cef37aa419a2be64db42a28
    source: https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl
  - name: bert-base-ner/pytorch_model.bin
    size: 433316646
    checksum: 59e6fefd0f29534cab9681891a15e9762b1d2dd8d047f55a792b39243631a008ac91a0e354f2ca2aa942be443540a8cb
    original_source: https://huggingface.co/dslim/bert-base-NER/resolve/main/pytorch_model.bin
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2023.2/bert-base-ner/pytorch_model.bin
  - name: bert-base-ner/config.json
    size: 829
    checksum: 66d217d33ba89085a56afc3b485b4e997d278d5253519e6a536c234fce3e065fb80ef39d27894df176148cb457c1cfcb
    original_source: https://huggingface.co/dslim/bert-base-NER/resolve/main/config.json
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2023.2/bert-base-ner/config.json
  - name: bert-base-ner/vocab.txt
    size: 213450
    checksum: b13bb7bd69958cf6d486a291894d90a8693adcea0cb177d1fbe652000def2b169dc82b292ef51736d1f6f15fee1ab486
    original_source: https://huggingface.co/dslim/bert-base-NER/resolve/main/vocab.txt
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2023.2/bert-base-ner/vocab.txt
  - name: packaging-20.9-py2.py3-none-any.whl
    size: 40870
    checksum: 422fac4cb009bed3eae42e9688b1712ee15dde1799c888f33c802792e925373dee046602d1d31c460d9d2af3ff6b93a1
    source: https://files.pythonhosted.org/packages/3e/89/7ea760b4daa42653ece2380531c90f64788d979110a2ab51049d92f408af/packaging-20.9-py2.py3-none-any.whl
postprocessing:
  - $type: unpack_archive
    format: zip
    file: transformers-4.5.1-py3-none-any.whl
  - $type: unpack_archive
    format: zip
    file: packaging-20.9-py2.py3-none-any.whl
  - $type: regex_replace
    file: transformers/__init__.py
    pattern: 'from . import dependency_versions_check'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: 'from tqdm.auto import tqdm'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: 'from .hf_api import HfFolder'
    replacement: '# \g<0>'
  - $type: regex_replace
    file: transformers/file_utils.py
    pattern: from filelock import FileLock
    replacement: '# \g<0>'
conversion_to_onnx_args:
  - --model-path=$dl_dir
  - --model-path=$config_dir
  - --model-name=create_model
  - --import-module=model
  - --model-param=model_dir=r"$dl_dir/bert-base-ner"
  - --input-names=input_ids,attention_mask,token_type_ids
  - --output-names=output
  - --input-shapes=[1,128],[1,128],[1,128]
  - --output-file=$conv_dir/bert-base-ner.onnx
  - --inputs-dtype=long
  - '--conversion-param=dynamic_axes={"input_ids": {0: "batch_size", 1: "sequence_len"},"attention_mask": {0: "batch_size", 1: "sequence_len"}, "token_type_ids": {0: "batch_size", 1: "sequence_len"}, "output": {0: "batch_size", 1: "sequence_len"}}'
input_info:
  - name: input_ids
    shape: [1, 128]
    layout: NC
  - name: attention_mask
    shape: [1, 128]
    layout: NC
  - name: token_type_ids
    shape: [1, 128]
    layout: NC
model_optimizer_args:
  - --input_model=$conv_dir/bert-base-ner.onnx
  - --output=output
framework: pytorch
quantizable: true
license: https://huggingface.co/dslim/bert-base-NER

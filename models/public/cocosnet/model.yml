# Copyright (c) 2022 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  Cross-domain correspondence network is a exemplar-based image translation model,
  consisting of correspondence and translation parts. Model was pre-trained on ADE20k
  dataset. For details see paper <https://arxiv.org/abs/2004.05571> and repository
  <https://github.com/microsoft/CoCosNet>.
task_type: image_translation
files:
  - name: model_files/util/__init__.py
    size: 72
    checksum: dfc6f539e037c1d6a8a1747c8a64f20431a0847874461c845a60aa686936d51163d7db6a56fc5086558512f544051fac
    source: https://raw.githubusercontent.com/microsoft/CoCosNet/33f98d092407094a15a08b0555d6f5359490cd3e/util/__init__.py
  - name: model_files/util/util.py
    size: 17551
    checksum: ada7dfbea39ed1a0bc97f03dab894fe1eac065bc0e0c7361def8e7a9e5bac75627eaa38d3c176ac6aa391945e0e221b3
    source: https://raw.githubusercontent.com/microsoft/CoCosNet/33f98d092407094a15a08b0555d6f5359490cd3e/util/util.py
  - name: model_files/models/networks/__init__.py
    size: 2676
    checksum: 9f1dae79e5600f33da16268485852627fe12bb62695f2c320abb12852f3232d6e76cfc9745fa5bc04994766d9e488114
    source: https://raw.githubusercontent.com/microsoft/CoCosNet/33f98d092407094a15a08b0555d6f5359490cd3e/models/networks/__init__.py
  - name: model_files/models/networks/architecture.py
    size: 7985
    checksum: 4be0416ec80decdcdc177b31197794c6c683a05e74690b780ec8db85b8f47c3a03dfa8dbfde58e72aa4c6e4a49ed1204
    source: https://raw.githubusercontent.com/microsoft/CoCosNet/33f98d092407094a15a08b0555d6f5359490cd3e/models/networks/architecture.py
  - name: model_files/models/networks/base_network.py
    size: 2466
    checksum: 2bd2cc5d29b71387dc4a756c7e3b8931c019d6a1e765bf71fa28443e34686716dacf77f1b5f58460517886148518332d
    source: https://raw.githubusercontent.com/microsoft/CoCosNet/33f98d092407094a15a08b0555d6f5359490cd3e/models/networks/base_network.py
  - name: model_files/models/networks/correspondence.py
    size: 18453
    checksum: 6a4aef47693a292715f8986ccc994e2e932db5d9d54dea790a3df9be34471ed7645f0fff6d1cbde87a26831a7b339c39
    source: https://raw.githubusercontent.com/microsoft/CoCosNet/33f98d092407094a15a08b0555d6f5359490cd3e/models/networks/correspondence.py
  - name: model_files/models/networks/generator.py
    size: 10874
    checksum: 24a4fe9c52345aba6c161930bda8d27692ad511f00711b62c2aef97157d36a648c2439c27d2e15d52271ae87f5d1f339
    source: https://raw.githubusercontent.com/microsoft/CoCosNet/33f98d092407094a15a08b0555d6f5359490cd3e/models/networks/generator.py
  - name: model_files/models/networks/normalization.py
    size: 11279
    checksum: 6b95b80690a0ff4f79f72669132763876c855631b662a0f9a089ffde1597341a1e3f823ea90ba6b7be963272378b295c
    source: https://raw.githubusercontent.com/microsoft/CoCosNet/33f98d092407094a15a08b0555d6f5359490cd3e/models/networks/normalization.py
  - name: model_files/models/__init__.py
    size: 1417
    checksum: 307d0718d8268d5f27dc5b394a756d7910f9f2f36792d78e718295966208bdaed0055e3ca224db506baab7c847857a9a
    source: https://raw.githubusercontent.com/microsoft/CoCosNet/33f98d092407094a15a08b0555d6f5359490cd3e/models/__init__.py
  - name: model_files/models/networks/sync_batchnorm/__init__.py
    size: 507
    checksum: e5e64b8365cbfbb1c1dc5379cd6230ae468c38cde59c294e67e0103e4add0744ed658ac7f246efcc7abfc601463bc29b
    source: https://raw.githubusercontent.com/vacancy/Synchronized-BatchNorm-PyTorch/5768ead395820b8a625cbe0da0bb9f949748a5dd/sync_batchnorm/__init__.py
  - name: model_files/models/networks/sync_batchnorm/batchnorm.py
    size: 15944
    checksum: 8a282cac42d4a9e970c26deb8251c7e7ea30bc55ffbcba13f1a0e02cb78763a6b993c6c91e1ed6a90074ca6899242136
    source: https://raw.githubusercontent.com/vacancy/Synchronized-BatchNorm-PyTorch/5768ead395820b8a625cbe0da0bb9f949748a5dd/sync_batchnorm/batchnorm.py
  - name: model_files/models/networks/sync_batchnorm/replicate.py
    size: 3226
    checksum: 9f662572ba39a396b98116ee8a4fe1b08fb5905fb2ba88cef3965a0827f6917409e7f25a5d1dcbf06acc986acea87d56
    source: https://raw.githubusercontent.com/vacancy/Synchronized-BatchNorm-PyTorch/5768ead395820b8a625cbe0da0bb9f949748a5dd/sync_batchnorm/replicate.py
  - name: model_files/models/networks/sync_batchnorm/comm.py
    size: 4449
    checksum: 985fb49fbc665ecef6de44ba10c8e547b27733a2301d10ce47da78c7152dd14c78645baae5cd6c042a987bad59ec86dc
    source: https://raw.githubusercontent.com/vacancy/Synchronized-BatchNorm-PyTorch/5768ead395820b8a625cbe0da0bb9f949748a5dd/sync_batchnorm/comm.py
  - name: model_files/ckpt/latest_net_Corr.pth
    size: 237624725
    checksum: f756f61b5b4d7ca0e23b7a3208ec8c8d5307fd834cef0dbeea7b7d8bc051eda9ecee2b71a378a2ecc5086a769242fc9a
    original_source:
      $type: google_drive
      id: 1yNCapBY7YqMoKeyVWwTwceqrEKHpUzYN
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2022.1/cocosnet/model_files/ckpt/latest_net_Corr.pth
  - name: model_files/ckpt/latest_net_G.pth
    size: 387069636
    checksum: 25b790181bbb30c5bd09627756bd70c8bd528431c57c8508ea48f3f352fda987203f19cc129b5706927bd68878d46e0d
    original_source:
      $type: google_drive
      id: 1zVG4SnR1uI8bC8fagZrgxNYCI5GRmJuR
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2022.1/cocosnet/model_files/ckpt/latest_net_G.pth
postprocessing:
  - $type: regex_replace
    file: model_files/models/networks/__init__.py
    pattern: 'from models\.networks\.(ContextualLoss|loss|discriminator) '
    replacement: '# \g<0>'
  - $type: regex_replace
    file: model_files/models/networks/correspondence.py
    pattern: '/ self.opt.down\)'
    replacement: '// self.opt.down)'
  # MO can only convert Squeeze with fixed dimensions
  - $type: regex_replace
    file: model_files/models/networks/correspondence.py
    pattern: '\.squeeze\(\)'
    replacement: '.squeeze(dim=0)'
  # fix deprecated function usage
  - $type: regex_replace
    file: model_files/models/networks/generator.py
    pattern: '\bF\.tanh\b'
    replacement: 'torch.tanh'
  - $type: regex_replace
    file: model_files/util/util.py
    pattern: 'colormap = scio.loadmat\(.\./util/color150.mat.\)\[.colors.\]'
    replacement: "# colormap = scio.loadmat('./util/color150.mat')['colors']"
conversion_to_onnx_args:
  - --model-path=$config_dir
  - --model-path=$dl_dir/model_files
  - --model-name=Pix2PixModel
  - --import-module=model
  - --input-shape=[1,151,256,256],[1,3,256,256],[1,151,256,256]
  - --output-file=$conv_dir/cocosnet.onnx
  - --model-param=corr_weights=r"$dl_dir/model_files/ckpt/latest_net_Corr.pth"
  - --model-param=gen_weights=r"$dl_dir/model_files/ckpt/latest_net_G.pth"
  - --input-names=input_seg_map,ref_image,ref_seg_map
  - --output-names=exemplar_based_output
model_optimizer_args:
  - --input_model=$conv_dir/cocosnet.onnx
  - --input=input_seg_map,ref_image,ref_seg_map
  - --output=exemplar_based_output
  - --mean_values=ref_image[127.5,127.5,127.5]
  - --scale_values=ref_image[127.5,127.5,127.5]
  - --layout=input_seg_map(NCHW),ref_image(NCHW),ref_seg_map(NCHW)
  - --reverse_input_channels
framework: pytorch
license: https://raw.githubusercontent.com/microsoft/CoCosNet/33f98d092407094a15a08b0555d6f5359490cd3e/LICENSE

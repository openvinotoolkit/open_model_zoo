# Copyright (c) 2020 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  The "dla-34" model is one of the DLA <https://arxiv.org/pdf/1707.06484> models designed
  to perform image classification. This model was pre-trained in PyTorch*. All DLA
  (Deep Layer Aggregation) classification models have been pre-trained on the ImageNet
  dataset. For details about this family of models, check out the Code for the CVPR
  Paper "Deep Layer Aggregation" <https://github.com/ucbdrive/dla>.
task_type: classification
files:
  - name: dla.py
    size: 14499
    sha256: cd3ea73af97f3456034f58392cc695fd6961f939adf9c80c1977e721efd7f8bc
    source: https://raw.githubusercontent.com/ucbdrive/dla/master/dla.py
  - name: dataset.py
    size: 1776
    sha256: 6821c636a1a955417fc2beade5d73409a9eceb546ca004c993f913a818cbfb90
    source: https://raw.githubusercontent.com/ucbdrive/dla/master/dataset.py
  - name: ckpt/dla34.pth
    size: 63228658
    sha256: ba72cf86426e6333d9e8c6c7a8cae5549879212e48ae3aaad4bc8a7d009c34e1
    source: http://dl.yf.io/dla/models/imagenet/dla34-ba72cf86.pth
conversion_to_onnx_args:
  - --model-path=$dl_dir
  - --model-name=dla34
  - --import-module=dla
  - --weights=$dl_dir/ckpt/dla34.pth
  - --input-shape=1,3,224,224
  - --input-names=data
  - --output-names=prob
  - --output-file=$conv_dir/dla-34.onnx
model_optimizer_args:
  - --reverse_input_channels
  - --input_shape=[1,3,224,224]
  - --input=data
  - --mean_values=data[123.675,116.28,103.53]
  - --scale_values=data[58.395,57.12,57.375]
  - --output=prob
  - --input_model=$conv_dir/dla-34.onnx
framework: pytorch
quantizable: yes
license: https://raw.githubusercontent.com/ucbdrive/dla/master/LICENSE

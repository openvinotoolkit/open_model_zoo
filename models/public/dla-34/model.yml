# Copyright (c) 2022-2024 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  The "dla-34" model is one of the DLA <https://arxiv.org/pdf/1707.06484> models designed
  to perform image classification. This model was pre-trained in PyTorch*. All DLA
  (Deep Layer Aggregation) classification models have been pre-trained on the ImageNet
  dataset. For details about this family of models, check out the Code for the CVPR
  Paper "Deep Layer Aggregation" <https://github.com/ucbdrive/dla>.
task_type: classification
files:
  - name: dla.py
    size: 14499
    checksum: ceaa3db3e90e5edff2a644738e93a00bf3688499e670dde1e771055362ff4ec0ba087fc0af35bdaf175871f893e54511
    source: https://raw.githubusercontent.com/ucbdrive/dla/master/dla.py
  - name: dataset.py
    size: 1776
    checksum: 4fb6ed8cb467074f7b0229c7a623f7f27c5ec184c8fe5ef2d84ed70168c10f6c6019d228b80fd1022c8884bc5cf8c38c
    source: https://raw.githubusercontent.com/ucbdrive/dla/master/dataset.py
  - name: ckpt/dla34.pth
    size: 63228658
    checksum: 38c035736538b6c67f2539bf1ca1cc1349c3691f41321bd58de9e97aa9eb83ea6f52c4aeef7c4cd54c92b6f8c3f3e89b
    original_source: http://dl.yf.io/dla/models/imagenet/dla34-ba72cf86.pth
    source: https://storage.openvinotoolkit.org/repositories/open_model_zoo/public/2022.1/dla-34/dla34-ba72cf86.pth
conversion_to_onnx_args:
  - --model-path=$dl_dir
  - --model-name=dla34
  - --import-module=dla
  - --weights=$dl_dir/ckpt/dla34.pth
  - --input-shape=1,3,224,224
  - --input-names=data
  - --output-names=prob
  - --output-file=$conv_dir/dla-34.onnx
input_info:
  - name: data
    shape: [1, 3, 224, 224]
    layout: NCHW
model_optimizer_args:
  - --reverse_input_channels
  - --mean_values=data[123.675,116.28,103.53]
  - --scale_values=data[58.395,57.12,57.375]
  - --output=prob
  - --input_model=$conv_dir/dla-34.onnx
framework: pytorch
license: https://raw.githubusercontent.com/ucbdrive/dla/master/LICENSE

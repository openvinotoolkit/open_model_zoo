# Copyright (c) 2022 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

description: >-
  The "robust-video-matting" model is a robust high-resolution human video matting method
  that achieves new state-of-the-art performance that uses a recurrent architecture to exploit
  temporal information in videos and achieves significant improvements in temporal coherence
  and matting quality This model is pre-trained in PyTorch* framework and converted to ONNX* format.
  More details provided in the paper <https://arxiv.org/abs/2108.11515>.
  For details see the repository <https://github.com/DmitriySidnev/RobustVideoMatting>.
task_type: background_matting
files:
  - name: robust_video_matting_mobilenetv3.onnx
    size: 14981904
    checksum: d6eeb320496d9a7de7d740806f1edf4c7144d97bffec0f279abd2eb3c6c8f3dd9b311eb48f8e70478a1d4e8c172ea720
    source: https://github.com/DmitriySidnev/RobustVideoMatting/raw/master/onnx/robust_video_matting_mobilenetv3.onnx
model_optimizer_args:
  - --input_shape=[1,3,720,1280],[1,16,144,256],[1,20,72,128],[1,40,36,64],[1,64,18,32]
  - --input=src,r1,r2,r3,r4
  - --output=pha,fgr,rr1,rr2,rr3,rr4
  - --scale_values=src[255,255,255]
  - --reverse_input_channels
  - --input_model=$dl_dir/robust_video_matting_mobilenetv3.onnx
framework: onnx
license: https://github.com/DmitriySidnev/RobustVideoMatting/blob/master/LICENSE
